<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Kexin Tang">
    
    <title>
        
            DDIA cookbook - (5)Replication |
        
        Kexin&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/otter-solid.svg">
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"kexintang.xyz","root":"/","language":"en","path":"search.json"}
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":true,"init_open":true},"style":{"primary_color":"#ff9f43","logo":null,"favicon":"/images/otter-solid.svg","avatar":"/images/OtterAvatar.jpg","font_size":null,"font_family":null,"hover":{"shadow":true,"scale":true},"first_screen":{"enable":true,"header_transparent":true,"background_img":"/images/bg.svg","description":"闲云野鹤||A lone cloud","font_color":null,"hitokoto":false},"scroll":{"progress_bar":true,"percent":true}},"local_search":{"enable":true,"preload":true},"code_copy":{},"code_block":{"tools":{"enable":true,"style":"default"},"highlight_theme":"default"},"side_tools":{},"pjax":{"enable":true},"lazyload":{"enable":true},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":false,"auto":false,"custom_label_list":[]},"word_count":{"enable":true,"wordcount":true,"min2read":true},"img_align":"left","copyright_info":false},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original article title","author":"Original article author","link":"Original article link"}
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <i class="pjax-progress-icon fas fa-circle-notch fa-spin"></i>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
            <a class="logo-title" href="/">
               Kexin&#39;s Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tags"
                            >
                                TAGS
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               target="_blank" rel="noopener" href="https://drive.google.com/file/d/13-0bw5teEW1AYoNnH5pRfsbnT48hkBJr/view?usp=drive_link"
                            >
                                RESUME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                ABOUT
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tags">TAGS</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       target="_blank" rel="noopener" href="https://drive.google.com/file/d/13-0bw5teEW1AYoNnH5pRfsbnT48hkBJr/view?usp=drive_link">RESUME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">ABOUT</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">DDIA cookbook - (5)Replication</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/OtterAvatar.jpg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Kexin Tang</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2023-08-26 18:13:00</span>
        <span class="mobile">2023-08-26 18:13</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2023-09-09 02:06:19</span>
    </span>
    
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/System-Design/">System Design</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/DDIA/">DDIA</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><h2 id="Why-need-multiple-machines"><a href="#Why-need-multiple-machines" class="headerlink" title="Why need multiple machines"></a>Why need multiple machines</h2><ul>
<li><strong>Scalability</strong> &rarr; If your data volume, read load, or write load grows bigger than a single machine can handle, you can potentially spread the load across multiple machines.</li>
<li><strong>Fault-tolerance&#x2F;high availability</strong> &rarr; If your application needs to continue working even if one machine goes down, you can use multiple machines to give you redundancy.</li>
<li><strong>Latency</strong> &rarr; If you have users around the world, you might want to have servers at various locations worldwide so that each user can be served from a datacenter that is geographically close to them.</li>
</ul>
<h2 id="Scaling"><a href="#Scaling" class="headerlink" title="Scaling"></a>Scaling</h2><h3 id="Vertical-Scaling"><a href="#Vertical-Scaling" class="headerlink" title="Vertical Scaling"></a>Vertical Scaling</h3><p><strong>Vertical Scaling</strong> or <strong>Scaling up</strong> means upgrade to a more powerful machine.</p>
<p>There are two strategies:</p>
<ul>
<li>shared-memory &rarr; many CPUs use same memory and disk</li>
<li>shared-disk &rarr; many CPUs and memories use same disk</li>
</ul>
<p>But they have several problems:</p>
<ul>
<li>The cost grows faster than linearly, add double hardware doesn’t mean double performance</li>
<li>For shared-memory, it’s limited to a single location</li>
<li>For shared-disk, the overhead of locking limit the scalability</li>
</ul>
<h3 id="Horizontal-scaling"><a href="#Horizontal-scaling" class="headerlink" title="Horizontal scaling"></a>Horizontal scaling</h3><p><strong>Horizontal Scaling</strong> or <strong>Scaling out</strong> treat every machine as node, each node uses its CPUs, RAM, and disks independently. Any coordination between nodes is done at the software level, using a conventional network.</p>
<p>Because every node is independent, so its strategy calls <strong>shared-nothing</strong>. It usually incurs additional complexity for applications and sometimes limits the expressiveness of the data models you can use.</p>
<h2 id="Replication-Vs-Partitioning"><a href="#Replication-Vs-Partitioning" class="headerlink" title="Replication Vs Partitioning"></a>Replication Vs Partitioning</h2><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/7OBsndi.png"
                      alt="Replication and Partitioning"
                ></p>
<ul>
<li><p><strong>Replication</strong> &rarr; Keeping a copy of the same data on several different nodes, potentially in different locations. Replication provides redundancy.</p>
</li>
<li><p><strong>Partitioning</strong> &rarr; Splitting a big database into smaller subsets called partitions so that different partitions can be assigned to different nodes (also known as <strong>sharding</strong>).</p>
</li>
</ul>
<hr>
<h1 id="Leader-Follower"><a href="#Leader-Follower" class="headerlink" title="Leader &amp; Follower"></a>Leader &amp; Follower</h1><p>Each node that stores a copy of the database is called a <strong>replica</strong>. Every write to the database needs to be processed by every replica; otherwise, the replicas would no longer contain the same data. The most common solution for this is called <strong>leader-follower&#x2F;master-slave replication</strong>.</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/kEi1ZVU.png"
                      alt="leader follower replication"
                ></p>
<ol>
<li>One of the replicas is designated the leader (also known as master). When clients want to write to the database, they must send their requests to the leader.</li>
<li>The other replicas are known as followers (slaves or hot standbys). Whenever the leader get writes request, it also sends the data change to all of its followers as part of a replication log or change stream. Each follower takes the log from the leader and updates its local copy of the database accordingly, by applying all writes in the same order as they were processed on the leader.<blockquote>
<p>When a client wants to read from the database, it can query either the leader or any of the followers. However, writes are only accepted on the leader.</p>
</blockquote>
</li>
</ol>
<h2 id="Synchronous-vs-Asynchronous"><a href="#Synchronous-vs-Asynchronous" class="headerlink" title="Synchronous vs Asynchronous"></a>Synchronous vs Asynchronous</h2><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/fWAoGGb.png"
                      alt="sync and async"
                ></p>
<ul>
<li>Sync &rarr; leader waits until follower has confirmed that it received the write before reporting success to the user.</li>
<li>Async &rarr; leader sends the message, but doesn’t wait for a response from the follower.</li>
</ul>
<p>The differences between sync and async are:</p>
<ol>
<li>sync sacrifices high availability to achieve strict consistency</li>
<li>async sacrifices strict consistency to achieve high availability</li>
</ol>
<p>Here are three configurations for different availability and consistency requirements:</p>
<ol>
<li>fully sync &rarr; leader finishes its write after all followers ack</li>
<li>semi sync &rarr; leader finishes its write after some of followers ack</li>
<li>async &rarr; leader finishes its write immediately, no need to wait follower ack</li>
</ol>
<h2 id="Setting-Up-New-Followers"><a href="#Setting-Up-New-Followers" class="headerlink" title="Setting Up New Followers"></a>Setting Up New Followers</h2><p>From time to time, you need to set up new followers—perhaps to increase the number of replicas, or to replace failed nodes.</p>
<p>We cannot directly copy all current data files from other nodes because:</p>
<ol>
<li>client will constantly write new data or update old data, if we only copy current data, it’s inconsistent</li>
<li>if we block client’s write request, we can make all data consistent, but lose high availability</li>
</ol>
<p>The correct apporach is:</p>
<ol>
<li>Take a consistent snapshot of the leader’s database at some point in time.</li>
<li>Copy the snapshot to the new follower node.</li>
<li>The follower connects to the leader and requests all the data changes that have happened since the snapshot was taken. The position of snapshot is sometimes called log sequence number or binlog coordinates.</li>
<li>When the follower has processed the backlog of data changes since the snapshot, we say it has caught up. It can now continue to process data changes from the leader as they happen.</li>
</ol>
<h2 id="Handling-Node-Outage"><a href="#Handling-Node-Outage" class="headerlink" title="Handling Node Outage"></a>Handling Node Outage</h2><h3 id="Follower-catch-up-recovery"><a href="#Follower-catch-up-recovery" class="headerlink" title="Follower: catch-up recovery"></a>Follower: catch-up recovery</h3><p>Each follower keeps a log of the data changes it has received from the leader.</p>
<p>The follower can recover quite easily: from its log, it knows the last transaction that was processed before the fault occurred. Thus, the follower can connect to the leader and request all the data changes that occurred during the time when the follower was disconnected.</p>
<h3 id="Leader-failover"><a href="#Leader-failover" class="headerlink" title="Leader: failover"></a>Leader: failover</h3><h4 id="Failover"><a href="#Failover" class="headerlink" title="Failover"></a>Failover</h4><ol>
<li><p>Determining that the leader has failed. The most common <em><strong>Failure detection algorithm</strong></em> uses <em><strong>timeout</strong></em>.</p>
</li>
<li><p>Choosing a new leader. <em><strong>Leader election algorithm</strong></em> and <em><strong>Consensus algorithm</strong></em>: the leader is chosen by a majority of the remaining replicas and is usually the replica with the most up-to-date data changes from the old leader.</p>
</li>
<li><p>Reconfiguring the system to use the new leader. Clients now need to send their write requests to the new leader. The system needs to ensure that the old leader becomes a follower and recognizes the new leader.</p>
</li>
</ol>
<h4 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h4><ul>
<li><p>If asynchronous replication is used, the new leader may not have received all the writes from the old leader before it failed. If the former leader rejoins the cluster after a new leader has been chosen, the new leader may have received conflicting writes in the meantime. The most common solution is for the old leader’s unreplicated writes to simply be discarded.</p>
</li>
<li><p>Discarding writes is especially dangerous if other storage systems outside of the database need to be coordinated with the database contents.</p>
<blockquote>
<p>For example current system needs to use Redis as cache, and the old leader wrote some primary key into Redis, then it crashed. The new leader also store its auto incremental primary key into Redis, but because its data is not up-to-date, so there may have some primary key already in Redis.</p>
</blockquote>
</li>
<li><p>In certain fault scenarios, it could happen that two nodes both believe that they are the leader.</p>
</li>
<li><p>How to set a reasonable timeout value.</p>
</li>
</ul>
<h2 id="Implementation-of-Replication-Logs"><a href="#Implementation-of-Replication-Logs" class="headerlink" title="Implementation of Replication Logs"></a>Implementation of Replication Logs</h2><h3 id="Statement-based-replication"><a href="#Statement-based-replication" class="headerlink" title="Statement-based replication"></a>Statement-based replication</h3><p><strong>Leader records the SQL statements and send them to followers</strong>. The leader just acts like a client to there followers.</p>
<blockquote>
<p>For example, the log may has record<br><code>SELECT * FROM table WHERE conditions</code><br><code>INSERT properties INTO table VALUES(values)</code></p>
</blockquote>
<p>The disadvantages:</p>
<ul>
<li><p><strong>Nondeterministic</strong> &rarr; functions such as <code>NOW()</code> and <code>RAND()</code> are likely to generate a different value on each replica.</p>
</li>
<li><p><strong>Execution Order</strong> &rarr; if they use autoincrementing column, or if they depend on the existing data in the database, they must be executed in exactly the same order on each replica, or else they may have a different effect.</p>
</li>
<li><p><strong>Side effects</strong> &rarr; like triggers, stored procedures, user-defined functions may result in different side effects occurring on each replica, unless the side effects are absolutely deterministic.</p>
</li>
</ul>
<h3 id="Write-Ahead-Log-WAL"><a href="#Write-Ahead-Log-WAL" class="headerlink" title="Write-Ahead Log (WAL)"></a>Write-Ahead Log (WAL)</h3><p>WAL is used for recovery:</p>
<ul>
<li><p>In the case of a log-structured storage engine, every modification is first written to a write-ahead log so that the memtable can be recovered even the crash happens.</p>
</li>
<li><p>In the case of a B-tree, which overwrites individual disk blocks, every modification is first written to a write-ahead log so that the index can be restored to a consistent state after a crash.</p>
</li>
</ul>
<p>It’s append-only sequence of bytes. The disadvantage is:</p>
<ul>
<li>WAL contains details of which bytes were changed in which disk blocks. This makes replication closely coupled to the storage engine.</li>
</ul>
<p>If the storage engine changes or is incompatible, WAL may cannot allocate the data to certain position.</p>
<h3 id="Logical-Log-binlog-in-MySQL"><a href="#Logical-Log-binlog-in-MySQL" class="headerlink" title="Logical Log (binlog in MySQL)"></a>Logical Log (binlog in MySQL)</h3><p>A log should be decoupled from the storage engine.</p>
<p>A logical log for a relational database is usually a sequence of records describing writes to database tables at the granularity of a row:</p>
<ul>
<li>For an inserted row, the log contains the new values of all columns.</li>
<li>For a deleted row, the log contains enough information to uniquely identify the row that was deleted. (tombstone)</li>
<li>For an updated row, the log contains enough information to uniquely identify the updated row, and the new values of all columns.</li>
<li>For transaction, the log will append a flag to inform the commit of the transaction.</li>
</ul>
<h2 id="Problems-with-Replication-Lag"><a href="#Problems-with-Replication-Lag" class="headerlink" title="Problems with Replication Lag"></a>Problems with Replication Lag</h2><p>If we have multiple followers, we can get:</p>
<ul>
<li>availablity &rarr; tolerate some faults in other machine</li>
<li>scalability &rarr; read can be distributed so we can deal with more requests</li>
<li>low-latency &rarr; request can choose a fast path</li>
</ul>
<p>But the question is: <strong>how to make all replics look the same</strong>.</p>
<p>If we choose sync replication, all problems can be solved except that if some replics crash, the service is blocked to wait for replics recovery, which may cause user complain and is unacceptable.</p>
<p>So the only way is <strong>async replication</strong>. But it may has a problem: some replics may fall behind other replics.</p>
<p>This leads to apparent inconsistencies in the database: if you run the same query on the leader and a follower at the same time, you may get different results, because not all writes have been reflected in the follower.</p>
<p>Good news is this inconsistency is just a temporary state—if you stop writing to the database and wait a while, the followers will eventually catch up and become consistent with the leader. For that reason, this effect is known as <strong>eventual consistency</strong>.</p>
<h3 id="Reading-Your-Own-Writes"><a href="#Reading-Your-Own-Writes" class="headerlink" title="Reading Your Own Writes"></a>Reading Your Own Writes</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/TxwHfKE.png"
                      alt="reading your own writes"
                ></p>
<p>In this situation, we need <strong>read-after-write consistency</strong>. This is a guarantee that if the user reloads the page, they will always see any updates they submitted themselves. It makes no promises about other users: other users’ updates may not be visible until some later time.</p>
<h4 id="Methods"><a href="#Methods" class="headerlink" title="Methods"></a>Methods</h4><ul>
<li>When reading something that the user may have modified, read it from the leader; otherwise, read it from a follower.</li>
<li>Track the time of the last update and, if new requests within certain time threshold, make all reads from the leader.</li>
<li>The client can remember the timestamp of its most recent write—then the system can ensure that the replica serving any reads for that user reflects updates at least until that timestamp.</li>
</ul>
<h4 id="Problems-1"><a href="#Problems-1" class="headerlink" title="Problems"></a>Problems</h4><ul>
<li>Timestamp is very hard to sync for one logic user has multiple physical device.</li>
<li>Replicas are distributed across different datacenters, there is no guarantee that connections from different devices will be routed to the same datacenter.s</li>
</ul>
<h3 id="Monotonic-Reads"><a href="#Monotonic-Reads" class="headerlink" title="Monotonic Reads"></a>Monotonic Reads</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/dwhMyx2.png"
                      alt="monotonic reads"
                ></p>
<p><strong>Monotonic reads</strong> is a guarantee that is a lesser guarantee than strong consistency, but a stronger guarantee than eventual consistency. When you read data, you may see an old value; monotonic reads only means that if one user makes several reads in sequence, they will not see time go backward.</p>
<blockquote>
<p>For example, the old data is 1 &rarr; 2, and right now the newest data is 3, when we send the first read, it may return “2”, then I send several reads, it makes sure that the responses look like “2, 2, 2, …, 3, 3, 3”. “1” will never appear and if we see “3”, “2” will never appear.</p>
</blockquote>
<h4 id="Methods-1"><a href="#Methods-1" class="headerlink" title="Methods"></a>Methods</h4><ul>
<li>each user always makes their reads from the same replica (different users can read from different replicas).</li>
<li>timestamp</li>
</ul>
<h4 id="Difference-with-“Reading-your-own-writes”"><a href="#Difference-with-“Reading-your-own-writes”" class="headerlink" title="Difference with “Reading your own writes”"></a>Difference with “Reading your own writes”</h4><p>“Reading your own writes” guarantees the read order after write, “Monotonic reads” guarantees multiple reads order.</p>
<h3 id="Consistent-Prefix-Reads-Causal"><a href="#Consistent-Prefix-Reads-Causal" class="headerlink" title="Consistent Prefix Reads (Causal)"></a>Consistent Prefix Reads (Causal)</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/C2XKXS7.png"
                      alt="causal"
                ></p>
<p>The reason for inconsistent prefix is <strong>partition</strong>. The order inside one partition is easy to maintain, but inter partition is hard.</p>
<h4 id="Methods-2"><a href="#Methods-2" class="headerlink" title="Methods"></a>Methods</h4><ul>
<li>no partition.</li>
<li>route all causal requests to same partition, but how to detect several requests are causal is hard.</li>
</ul>
<h2 id="Solutions-for-Replication-Lag"><a href="#Solutions-for-Replication-Lag" class="headerlink" title="Solutions for Replication Lag"></a>Solutions for Replication Lag</h2><p><strong>Transaction</strong>!!! We will cover it later.</p>
<hr>
<h1 id="Multi-leaders"><a href="#Multi-leaders" class="headerlink" title="Multi-leaders"></a>Multi-leaders</h1><p>Leader-based replication has one major downside: there is only one leader, and all writes must go through it. So the extension for it is using multiple leaders.</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/MBolpU5.jpg"
                      alt="multi leaders"
                ></p>
<h2 id="Single-leader-vs-Multiple-leaders"><a href="#Single-leader-vs-Multiple-leaders" class="headerlink" title="Single leader vs Multiple leaders"></a>Single leader vs Multiple leaders</h2><table>
<thead>
<tr>
<th></th>
<th>single leader</th>
<th>multiple leaders</th>
</tr>
</thead>
<tbody><tr>
<td>Performance</td>
<td><strong>Every write must go over the internet to the datacenter with the leader</strong>. This can add significant latency to writes.</td>
<td><strong>Every write can be processed in the local datacenter</strong> and is replicated asynchronously to the other datacenters.</td>
</tr>
<tr>
<td>Tolerance of datacenter outages</td>
<td>If the datacenter with the leader fails, failover can promote a follower in another datacenter to be leader, <strong>the whole system needs to wait until new leader starts</strong>.</td>
<td><strong>Each datacenter can continue operating independently of the others</strong>, the failed datacenter can select new leader by their own.</td>
</tr>
<tr>
<td>Tolerance of network problems</td>
<td>It is very <strong>sensitive to public internet</strong> (inter-datacenter link).</td>
<td>A multi-leader configuration with asynchronous replication can usually tolerate network problems better: <strong>a temporary network interruption does not prevent writes being processed</strong>.</td>
</tr>
</tbody></table>
<h2 id="Use-case"><a href="#Use-case" class="headerlink" title="Use case"></a>Use case</h2><ul>
<li>Clients with offline operation - Consider the calendar apps on your mobile phone, your laptop, and other devices. Every device has a local database that acts as a leader (it accepts write requests), and there is an asynchronous multi-leader replication process (sync) between the replicas of your calendar on all of your devices.</li>
<li>Database spanning multiple data centers.</li>
<li>Collaborative editing - Like Google Doc.</li>
</ul>
<h2 id="Downside"><a href="#Downside" class="headerlink" title="Downside"></a>Downside</h2><p>But multi-leaders has a big problem: <strong>the same data may be concurrently modified in two different datacenters, and those write conflicts must be resolved</strong>. So multi-leader is not a universal choice for all situations.</p>
<h2 id="Handling-Write-Conflicts"><a href="#Handling-Write-Conflicts" class="headerlink" title="Handling Write Conflicts"></a>Handling Write Conflicts</h2><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/0jdinGq.png"
                      alt="conflicts"
                ></p>
<h3 id="Conflict-Detection"><a href="#Conflict-Detection" class="headerlink" title="Conflict Detection"></a>Conflict Detection</h3><p>In a single-leader database:</p>
<ol>
<li>the second writer will either block and wait for the first write to complete</li>
<li>abort the second write transaction, forcing the user to retry the write</li>
</ol>
<p>In a multi-leader setup, both writes are successful, and the conflict is only detected asynchronously at some later point in time. At that time, it may be too late to ask the user to resolve the conflict.</p>
<p>In principle, you could make the conflict detection synchronous—i.e., <strong>wait for the write to be replicated to all replicas before telling the user that the write was successful</strong>. However, by doing so, you would lose the main advantage of multi-leader replication: allowing each replica to accept writes independently. If you want synchronous conflict detection, you might as well just use single-leader replication.</p>
<h3 id="Conflict-Avoidance"><a href="#Conflict-Avoidance" class="headerlink" title="Conflict Avoidance"></a>Conflict Avoidance</h3><p>Handle conflicts &rarr; Avoid conflicts.</p>
<p>The core is: <strong>if the application can ensure that all writes for a particular record go through the same leader, then conflicts cannot occur</strong>.</p>
<blockquote>
<p>For example, in an application where a user can edit their own data, you can ensure that requests from a particular user are always routed to the same datacenter and use the leader in that datacenter for reading and writing. Different users may have different “home” datacenters, but from any one user’s point of view the configuration is essentially single-leader.</p>
</blockquote>
<p>The only problem is: if the user changes the datacenter, e.g. move from new york to california or origin datacenter is down, the conflict occurs.</p>
<h3 id="Conflict-Converging-收敛"><a href="#Conflict-Converging-收敛" class="headerlink" title="Conflict Converging (收敛)"></a>Conflict Converging (收敛)</h3><p>A single-leader database applies writes in a sequential order: if there are several updates to the same field, the last write determines the final value of the field. But for multi-leaders, every datacenter may has its own order, it hard to define a universal order.</p>
<p>Convergent &rarr; means that all replicas must arrive at the same final value when all changes have been replicated.</p>
<ul>
<li>Give each write a unique ID (e.g., a timestamp, a long random number, a UUID, or a hash of the key and value), <strong>pick the write with the highest ID as the winner</strong>. (if a timestamp is used, this technique is known as <em><strong>last write wins</strong></em> (LWW))</li>
<li>Give each replica a unique ID, and let writes that originated at <strong>a highernumbered replica always take precedence over writes that originated at a lowernumbered replica</strong>.</li>
<li><strong>Merge</strong> the values together.</li>
<li><strong>Record the conflict information and try to solve it later</strong>.</li>
</ul>
<h3 id="Custom-Conflict-Resolution"><a href="#Custom-Conflict-Resolution" class="headerlink" title="Custom Conflict Resolution"></a>Custom Conflict Resolution</h3><details open>
<summary>On write</summary>

<p>As soon as the database system detects a conflict in the log of replicated changes, it calls the conflict handler (callback function). This handler typically cannot prompt a user—it runs in a background process and it must execute quickly.</p>
</details>

<details open>
<summary>On read</summary>

<p>When a conflict is detected, all the conflicting writes are stored. The next time the data is read, these multiple versions of the data are returned to the application. The application may prompt the user or automatically resolve the conflict, and write the result back to the database.</p>
</details>

<h2 id="Multi-leaders-Replication-Topologies"><a href="#Multi-leaders-Replication-Topologies" class="headerlink" title="Multi-leaders Replication Topologies"></a>Multi-leaders Replication Topologies</h2><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/VDQWLje.png"
                      alt="topology"
                ></p>
<table>
<thead>
<tr>
<th></th>
<th>Circular</th>
<th>Star &#x2F; Tree</th>
<th>All-to-All</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Advantage</strong></td>
<td>Total amount of replication messages is the same as amount of nodes, which is small.</td>
<td></td>
<td>Fault tolerance</td>
</tr>
<tr>
<td><strong>Disadvantage</strong></td>
<td>If just one node fails, it can interrupt the flow of replication messages between other nodes, causing them to be unable to communicate until the node is fixed.</td>
<td>The same as circular.</td>
<td>1. Total amount of replication messages is large <br/> 2. Because it doesn’t have order (no prior node or next node), the variation of latency of network links may cause <strong>causality problem</strong>.</td>
</tr>
</tbody></table>
<blockquote>
<p>For circular &amp; star, to aviod broadcast flooding, each node has a unique identifier, and in the replication log, each write needs to record all nodes it passed through.</p>
</blockquote>
<blockquote>
<p>If the latency of network links are different, the causality problem may occur.<br><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/f7eW0ug.png"
                      alt="causality problem"
                ><br>Because the update depends on the prior insert, so we need to make sure that all nodes process the insert first, and then the update. Simply attaching a timestamp to every write is not sufficient, because clocks sync is difficult. To order these events correctly, a technique called <em><strong>version vectors</strong></em> or <em><strong>vector clock</strong></em>, which is a logical clock. We will talk about that in next chapter.</p>
</blockquote>
<hr>
<h1 id="Leaderless"><a href="#Leaderless" class="headerlink" title="Leaderless"></a>Leaderless</h1><p>In leaderless implementations:</p>
<ol>
<li>the client directly sends its writes to several replicas.</li>
<li>a coordinator node does this on behalf of the client. However, unlike a leader database, that coordinator does not enforce a particular ordering of writes.</li>
</ol>
<h2 id="Writing-to-the-Database-When-a-Node-Is-Down"><a href="#Writing-to-the-Database-When-a-Node-Is-Down" class="headerlink" title="Writing to the Database When a Node Is Down"></a>Writing to the Database When a Node Is Down</h2><p><strong>In a leaderless configuration, failover does not exist</strong> because it doesn’t have leader :).</p>
<p>The client sends the write to all replicas (let’s say <code>n</code> replicas) in parallel, and <code>x</code> available replicas accept the write but the <code>n-x</code> unavailable replicas miss it. We have a threshold <code>h</code> that if at least <code>h</code> replicas reply ok, we think the write is finished and we ignore the remaining <code>n-h</code> replicas. According to following figure, we can think <code>x=2</code>, <code>n=3</code>, <code>h=2</code>.</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/UzMA5ot.png"
                      alt="quorum write"
                ></p>
<p>When a client reads from the database, it doesn’t just send its request to one replica: <strong>read requests are also sent to several nodes in parallel</strong>. The client may get different responses from different nodes; i.e., the up-to-date value from one node and a stale value from another. Version numbers are used to determine which value is newer.</p>
<h3 id="Read-repair-and-anti-entropy-AE"><a href="#Read-repair-and-anti-entropy-AE" class="headerlink" title="Read repair and anti-entropy (AE)"></a>Read repair and anti-entropy (AE)</h3><p>The replication scheme should ensure that eventually all the data is copied to every replica. After an unavailable node comes back online, how does it catch up on the writes that it missed?</p>
<details open>
<summary>Read repair</summary>
When a client makes a read from several nodes in parallel, it can detect any stale responses. When the client sees certain replica has a stale value, it writes the newer value back to that replica. This approach works well for values that are frequently read.
</details>

<details open>
<summary>Anti-entropy</summary>
In addition, some datastores have a background process that constantly looks for differences in the data between replicas and copies any missing data from one replica to another. Unlike the replication log in leader-based replication, this anti-entropy process does not copy writes in any particular order, and there may be a significant delay before data is copied.

<blockquote>
<p>In more basic terms, the AE service identifies missing or inconsistent shards and repairs them (it’s a DIFF process).</p>
<ul>
<li>AE can only perform its heroism when there is at least one copy of the shard still available. </li>
<li>AE will not compare or repair hot shards, meaning that the shard can’t have active writes. Hot shards are more prone to change, and at any given moment, arrival of new data affects AE’s digest comparison.</li>
</ul>
</blockquote>
</details>

<h3 id="Quorums-for-reading-and-writing"><a href="#Quorums-for-reading-and-writing" class="headerlink" title="Quorums for reading and writing"></a>Quorums for reading and writing</h3><p>If there are <code>n</code> replicas, every write must be confirmed by <code>w</code> nodes to be considered successful, and we must query at least <code>r</code> nodes for each read. <strong>As long as <code>w + r &gt; n</code>, we expect to get an up-to-date value when reading</strong>, because at least one of the <code>r</code> nodes we’re reading from must be up to date. Reads and writes that obey these <code>r</code> and <code>w</code> values are called <strong>quorum reads and writes</strong>.</p>
<p>Normally, reads and writes are always sent to all n replicas in parallel. The parameters <code>w</code> and <code>r</code> determine how many nodes we wait for.</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/p9MnS6t.png"
                      alt="quorums"
                ></p>
<p>What’s more, <strong><code>w</code> and <code>r</code> are configurable</strong>, which means if the system is write heavy, we can set smaller <code>w</code> to reduce replication complexity.</p>
<h2 id="Limitations-of-Quorum-Consistency"><a href="#Limitations-of-Quorum-Consistency" class="headerlink" title="Limitations of Quorum Consistency"></a>Limitations of Quorum Consistency</h2><p>Even <code>w + r &gt; n</code>, sometimes READ still gets stale values:</p>
<ol>
<li>If a sloppy quorum is used, the <code>n</code> will change, which break the <code>w + r &gt; n</code> rule.</li>
<li>If two writes occur concurrently, it is not clear which one happened first. If we choose use timestamp to pick the winner, the clock skew will make replicas inconsistent.<blockquote>
<p>in leader-based strategy, leader will decide which is winner then send it to all replicas, but leaderless means every replica can has its own thought.</p>
</blockquote>
</li>
<li>If a write happens concurrently with a read, the write may be reflected on only some of the replicas.</li>
<li>If a write succeeded on some replicas but failed on others and overall succeeded on fewer than w replicas, it is not rolled back on the replicas where it succeeded.</li>
<li>If a node carrying a new value fails, and its data is restored from a replica carrying an old value, the number of replicas storing the new value may fall below w, breaking the quorum condition.</li>
</ol>
<h3 id="Monitoring-staleness"><a href="#Monitoring-staleness" class="headerlink" title="Monitoring staleness"></a>Monitoring staleness</h3><p>Even if your application can tolerate stale reads, you need to be aware of the health of your replication. If it falls behind significantly, it should alert you so that you can investigate the cause.</p>
<p>For leader-based replication, the database typically exposes metrics for the replication lag, which you can feed into a monitoring system. This is possible because <strong>writes are applied to the leader and to followers in the same order, and each node has a position in the replication log (the number of writes it has applied locally)</strong>. By subtracting a follower’s current position from the leader’s current position, you can measure the amount of replication lag.</p>
<p>For leaderless replication, there is no fixed order in which writes are applied, which makes monitoring more difficult. Moreover, if the database only uses read repair (no anti-entropy), there is no limit to how old a value might be — if a value is only infrequently read, the value returned by a stale replica may be ancient.</p>
<blockquote>
<p>For leaderless, we can write only partial replicas, so the write log in one replica cannot represent the actual write order for the whole system.</p>
</blockquote>
<h2 id="Sloppy-Quorums-and-Hinted-Handoff"><a href="#Sloppy-Quorums-and-Hinted-Handoff" class="headerlink" title="Sloppy Quorums and Hinted Handoff"></a>Sloppy Quorums and Hinted Handoff</h2><p>A network interruption can easily cut off a client from a large number of database nodes. Although those nodes are alive, and other clients may be able to connect to them, to a client that is cut off from the database nodes, they might as well be dead. In this situation, it’s likely that fewer than w or r reachable nodes remain, so the client can no longer reach a quorum.</p>
<p>There are two choices:</p>
<ol>
<li>let all write and read fail</li>
<li>accept write for now, but write it to some nodes that are reachable but aren’t among the original <code>n</code> quorum</li>
</ol>
<p>The second choice is called <em><strong>sloppy quorum</strong></em>.</p>
<blockquote>
<p>For example originally we choice 10 nodes from [1, …, 10], and if some machines are not reachable ([1, 2, 3, 4]), we write to [5, …, 10, 11*, 12*, 13*, 14*].</p>
</blockquote>
<p>Sloppy quorums are particularly useful for increasing write availability: as long as any w nodes are available, the database can accept writes. However, this means that even when w + r &gt; n, you cannot be sure to read the latest value for a key, because the latest value may have been temporarily written to some nodes outside of n</p>
<p>Once the network interruption is fixed, any writes that one node temporarily accepted on behalf of another node are sent to the appropriate “home” nodes. This is called <em><strong>hinted handoff</strong></em>.</p>
<blockquote>
<p>For example, when 1, 2, 3, 4 become available, the 11*, 12*, 13*, 14* will quit the quorum and the system still use [1, …, 10] as quorum. But the problem is the [1, …, 4] don’t have up-to-date values. In some systems, 11*-14* may send temporary stored updates back to 1-4 to make the original quorum works like nothing happend.</p>
</blockquote>
<h2 id="Multi-datacenter-operation"><a href="#Multi-datacenter-operation" class="headerlink" title="Multi-datacenter operation"></a>Multi-datacenter operation</h2><p>The number of replicas n includes nodes in all datacenters, and in the configuration you can specify how many of the n replicas you want to have in each datacenter. Each write from a client is sent to all replicas, regardless of datacenter, but the client usually only waits for acknowledgment from a quorum of nodes within its local datacenter so that it is unaffected by delays and interruptions on the cross-datacenter link.</p>
<p>Or keeps all communication between clients and database nodes local to one datacenter, so n describes the number of replicas within one datacenter. Cross-datacenter replication between database clusters happens asynchronously in the background, in a style that is similar to multi-leader replication.</p>
<h2 id="Detecting-Concurrent-Writes"><a href="#Detecting-Concurrent-Writes" class="headerlink" title="Detecting Concurrent Writes"></a>Detecting Concurrent Writes</h2><p>The problem is that events may arrive in a different order at different nodes, due to variable network delays and partial failures. In order to become eventually consistent, the replicas should converge toward the same value.</p>
<h3 id="Last-Write-Wins-LWW"><a href="#Last-Write-Wins-LWW" class="headerlink" title="Last Write Wins (LWW)"></a>Last Write Wins (LWW)</h3><p>Even though the writes don’t have a natural ordering, we can force an arbitrary order on them. For example, we can attach a timestamp to each write, pick the biggest timestamp as the most “recent,” and discard any writes with an earlier timestamp. This conflict resolution algorithm, called last write wins (LWW).</p>
<p>LWW achieves the goal of <strong>eventual convergence</strong>, but at the <strong>cost of durability</strong>: if there are several concurrent writes to the same key, even if they were all reported as successful to the client, only one of the writes will survive and the others will be silently discarded. Moreover, LWW may even drop writes that are not concurrent.</p>
<p><strong>If losing data is not acceptable, LWW is a poor choice for conflict resolution</strong>.</p>
<h3 id="Causality-因果关系-vs-Concurrency"><a href="#Causality-因果关系-vs-Concurrency" class="headerlink" title="Causality (因果关系) vs Concurrency"></a>Causality (因果关系) vs Concurrency</h3><p>An operation A happens before (causality) another operation B if B knows about A, or depends on A, or builds upon A in some way. So two operations are concurrent if neither happens before the other.</p>
<p>If one operation happened before another, the later operation should overwrite the earlier operation, but if the operations are concurrent, we have a conflict that needs to be resolved.</p>
<p>For defining concurrency, exact time doesn’t matter: we simply call two operations concurrent if they are both unaware of each other, regardless of the physical time at which they occurred, because in distributed systems, clock skew cannot be aviod.</p>
<h3 id="Capture-the-causality-relationship"><a href="#Capture-the-causality-relationship" class="headerlink" title="Capture the causality relationship"></a>Capture the causality relationship</h3><p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/aT7yIVT.png"
                      alt="causality"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/U8mt0Va.png"
                      alt="dataflow"
                ></p>
<p>The algorithm is:</p>
<ol>
<li>The server maintains a version number V<sub>i</sub> for every key, increments the version number V<sub>i</sub> &rarr; V<sub>i</sub>+1 every time that key is written, and stores the new version number along with the value written.</li>
<li>When a client reads a key, the server returns all values that have not been overwritten, as well as the latest version number.</li>
<li>When a client writes a key, it must include the version number V<sub>x</sub> from the prior read, and it must merge together all values that it received in the prior read.</li>
<li>When the server receives a write with a particular version number V<sub>x</sub>, it can overwrite all values with that version number or below V &leq; V<sub>x</sub> (since it knows that they have been merged into the new value), but it must keep all values with a higher version number (because those values are concurrent with the incoming write).</li>
<li>If a client writes a key without any version number, add it into current dataset.</li>
</ol>
<h3 id="Merging-concurrently-written-values"><a href="#Merging-concurrently-written-values" class="headerlink" title="Merging concurrently written values"></a>Merging concurrently written values</h3><p>This algorithm ensures that no data is silently dropped, but it unfortunately requires that the clients do some extra work: if several operations happen concurrently, clients have to clean up afterward by merging the concurrently written values. A simple approach is to just pick one of the values based on a version number or timestamp (last write wins), but that implies losing data.</p>
<p>When delete data, we cannot directly delete it, we need to set a tombstone to mark it as unavailable.</p>
<h3 id="Version-vector"><a href="#Version-vector" class="headerlink" title="Version vector"></a>Version vector</h3><p>Use a version number per replica as well as per key. <strong>Each replica increments its own version number when processing a write, and also keeps track of the version numbers it has seen from each of the other replicas</strong>. This information indicates which values to overwrite and which values to keep as siblings. The version vector allows the database to distinguish between overwrites and concurrent writes.</p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/2xARE0g.jpg"
                      alt="lamport timestamp"
                ></p>
<p><img  
                     lazyload
                     alt="image"
                     data-src="https://i.imgur.com/7iFgdXY.jpg"
                      alt="version vector"
                ></p>

            </div>

            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/System-Design/">#System Design</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/DDIA/">#DDIA</a>&nbsp;
                        </li>
                    
                </ul>
            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                               rel="prev"
                               href="/2023/09/09/DDIA-cookbook-6-Partitioning/"
                            >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                                <span class="title flex-center">
                                <span class="post-nav-title-item">DDIA cookbook - (6)Partitioning</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2023/08/25/DDIA-cookbook-4-Encoding/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">DDIA cookbook - (4)Encoding</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Intro"><span class="nav-number">1.</span> <span class="nav-text">Intro</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Why-need-multiple-machines"><span class="nav-number">1.1.</span> <span class="nav-text">Why need multiple machines</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scaling"><span class="nav-number">1.2.</span> <span class="nav-text">Scaling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Vertical-Scaling"><span class="nav-number">1.2.1.</span> <span class="nav-text">Vertical Scaling</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Horizontal-scaling"><span class="nav-number">1.2.2.</span> <span class="nav-text">Horizontal scaling</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Replication-Vs-Partitioning"><span class="nav-number">1.3.</span> <span class="nav-text">Replication Vs Partitioning</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Leader-Follower"><span class="nav-number">2.</span> <span class="nav-text">Leader &amp; Follower</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Synchronous-vs-Asynchronous"><span class="nav-number">2.1.</span> <span class="nav-text">Synchronous vs Asynchronous</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Setting-Up-New-Followers"><span class="nav-number">2.2.</span> <span class="nav-text">Setting Up New Followers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Handling-Node-Outage"><span class="nav-number">2.3.</span> <span class="nav-text">Handling Node Outage</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Follower-catch-up-recovery"><span class="nav-number">2.3.1.</span> <span class="nav-text">Follower: catch-up recovery</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Leader-failover"><span class="nav-number">2.3.2.</span> <span class="nav-text">Leader: failover</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Failover"><span class="nav-number">2.3.2.1.</span> <span class="nav-text">Failover</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Problems"><span class="nav-number">2.3.2.2.</span> <span class="nav-text">Problems</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Implementation-of-Replication-Logs"><span class="nav-number">2.4.</span> <span class="nav-text">Implementation of Replication Logs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Statement-based-replication"><span class="nav-number">2.4.1.</span> <span class="nav-text">Statement-based replication</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Write-Ahead-Log-WAL"><span class="nav-number">2.4.2.</span> <span class="nav-text">Write-Ahead Log (WAL)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Logical-Log-binlog-in-MySQL"><span class="nav-number">2.4.3.</span> <span class="nav-text">Logical Log (binlog in MySQL)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Problems-with-Replication-Lag"><span class="nav-number">2.5.</span> <span class="nav-text">Problems with Replication Lag</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Reading-Your-Own-Writes"><span class="nav-number">2.5.1.</span> <span class="nav-text">Reading Your Own Writes</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Methods"><span class="nav-number">2.5.1.1.</span> <span class="nav-text">Methods</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Problems-1"><span class="nav-number">2.5.1.2.</span> <span class="nav-text">Problems</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Monotonic-Reads"><span class="nav-number">2.5.2.</span> <span class="nav-text">Monotonic Reads</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Methods-1"><span class="nav-number">2.5.2.1.</span> <span class="nav-text">Methods</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Difference-with-%E2%80%9CReading-your-own-writes%E2%80%9D"><span class="nav-number">2.5.2.2.</span> <span class="nav-text">Difference with “Reading your own writes”</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Consistent-Prefix-Reads-Causal"><span class="nav-number">2.5.3.</span> <span class="nav-text">Consistent Prefix Reads (Causal)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Methods-2"><span class="nav-number">2.5.3.1.</span> <span class="nav-text">Methods</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Solutions-for-Replication-Lag"><span class="nav-number">2.6.</span> <span class="nav-text">Solutions for Replication Lag</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Multi-leaders"><span class="nav-number">3.</span> <span class="nav-text">Multi-leaders</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Single-leader-vs-Multiple-leaders"><span class="nav-number">3.1.</span> <span class="nav-text">Single leader vs Multiple leaders</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Use-case"><span class="nav-number">3.2.</span> <span class="nav-text">Use case</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Downside"><span class="nav-number">3.3.</span> <span class="nav-text">Downside</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Handling-Write-Conflicts"><span class="nav-number">3.4.</span> <span class="nav-text">Handling Write Conflicts</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Conflict-Detection"><span class="nav-number">3.4.1.</span> <span class="nav-text">Conflict Detection</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conflict-Avoidance"><span class="nav-number">3.4.2.</span> <span class="nav-text">Conflict Avoidance</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conflict-Converging-%E6%94%B6%E6%95%9B"><span class="nav-number">3.4.3.</span> <span class="nav-text">Conflict Converging (收敛)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Custom-Conflict-Resolution"><span class="nav-number">3.4.4.</span> <span class="nav-text">Custom Conflict Resolution</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multi-leaders-Replication-Topologies"><span class="nav-number">3.5.</span> <span class="nav-text">Multi-leaders Replication Topologies</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Leaderless"><span class="nav-number">4.</span> <span class="nav-text">Leaderless</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Writing-to-the-Database-When-a-Node-Is-Down"><span class="nav-number">4.1.</span> <span class="nav-text">Writing to the Database When a Node Is Down</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Read-repair-and-anti-entropy-AE"><span class="nav-number">4.1.1.</span> <span class="nav-text">Read repair and anti-entropy (AE)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Quorums-for-reading-and-writing"><span class="nav-number">4.1.2.</span> <span class="nav-text">Quorums for reading and writing</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Limitations-of-Quorum-Consistency"><span class="nav-number">4.2.</span> <span class="nav-text">Limitations of Quorum Consistency</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Monitoring-staleness"><span class="nav-number">4.2.1.</span> <span class="nav-text">Monitoring staleness</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sloppy-Quorums-and-Hinted-Handoff"><span class="nav-number">4.3.</span> <span class="nav-text">Sloppy Quorums and Hinted Handoff</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Multi-datacenter-operation"><span class="nav-number">4.4.</span> <span class="nav-text">Multi-datacenter operation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Detecting-Concurrent-Writes"><span class="nav-number">4.5.</span> <span class="nav-text">Detecting Concurrent Writes</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Last-Write-Wins-LWW"><span class="nav-number">4.5.1.</span> <span class="nav-text">Last Write Wins (LWW)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Causality-%E5%9B%A0%E6%9E%9C%E5%85%B3%E7%B3%BB-vs-Concurrency"><span class="nav-number">4.5.2.</span> <span class="nav-text">Causality (因果关系) vs Concurrency</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Capture-the-causality-relationship"><span class="nav-number">4.5.3.</span> <span class="nav-text">Capture the causality relationship</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Merging-concurrently-written-values"><span class="nav-number">4.5.4.</span> <span class="nav-text">Merging concurrently written values</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Version-vector"><span class="nav-number">4.5.5.</span> <span class="nav-text">Version vector</span></a></li></ol></li></ol></li></ol>
    </div>
</div>

            </div>
        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2023</span> -
            
            2023
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">Kexin Tang</a>
            
        </div>
        
            <script async data-pjax
                    src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                
                
                    Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item flex-center toggle-show-toc">
                <i class="fas fa-list"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="close-popup-btn">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>





    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-block.js"></script>




    
<script src="/js/lazyload.js"></script>



<div class="post-scripts pjax">
    
        
<script src="/js/post-helper.js"></script>

        
            
<script src="/js/libs/anime.min.js"></script>

        
        
            
<script src="/js/toc.js"></script>

        
    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>

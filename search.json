[{"title":"DDIA cookbook - (12)The Future of Data System","url":"/2024/01/08/DDIA-cookbook-12-The-Future-of-Data-System/","content":"Data IntegrationAppropriate choice of software tool depends on the circumstances.\nCombining Specialized Tools by Deriving DataAs the number of different representations of the data increases, the integration problem becomes harder.\nReasoning about dataflowsWhen copies of the same data need to be maintained in several storage systems in order to satisfy different access patterns, you need to be very clear about the inputs and outputs.\nLet’s imagine that when a system gets a new input, and the input should be processed to build multiple derived data. If there are multiple clients sending conflicting writes, and the multiple processing parts consume writes in different orders, inconsistency may occur.\nIf it is possible for you to funnel all user input through a single system that decides on an ordering for all writes, it becomes much easier to derive other representations of the data by processing the writes in the same order. This is “Total Order Broadcast”.\nDerived data VS Distributed transactionsThe classic approach for keeping different data systems consistent with each other involves distributed transactions, which decides the order of writes by using lock. And it can ensure the changes take effect only once by atomicity.\nFor derived system, the log-based logic also keeps order, and makes sure the retry can have deterministic output.\nThe biggest difference is that transaction systems usually provide linearizability, which implies useful guarantees such as reading your own writes. On the other hand, derived data systems are often updated asynchronously, and so they do not by default offer the same timing guarantees.\nThe limits of total orderingIn huge system, total ordering has some limits:\n\nIn most cases, constructing a totally ordered log requires all events to pass through a single leader node that decides on the ordering. If the throughput of events is greater than a single machine can handle, you need to partition the log across multiple machines. The order of events in two different partitions is then ambiguous.\nFor geographically distributed datacenters, every center has its own leader, this implies an undefined ordering of events that originate in two different datacenters.\nFor microservices, it’s stateless. When two events originate in different services, there is no order information.\nSome applications support immediately even offline updates on client side. Clients and servers are likely to see events in different orders.\n\nTotal order broadcast is equivalent to consensus, which is designed for situations in which the throughput of a single node is sufficient to process the entire stream of events, and don’t provide a mechanism for multiple nodes to share the work of ordering the events.\nOrdering events to capture causalityIn cases where there is no causal link between events, the lack of a total order is not a big problem, since concurrent events can be ordered arbitrarily. Some other cases are easy to handle: for example, when there are multiple updates of the same object, they can be totally ordered by routing all updates for a particular object ID to the same log partition.\nHowever, things become difficult when there are multiple derived systems (different objects). For example, if the user modify something in system A, then based on that, modify system B. If the causal dependency is not captured, error occurs. One solution is let system A JOIN system B in the modified fields, then make next step. However, things always become difficult:\n\nLogical timestamps can provide total ordering without coordination. However, they still require recipients to handle events that are delivered out of order, and they require additional metadata to be passed around.\nConflict resolution algorithms help with processing events that are delivered in an unexpected order. They are useful for maintaining state, but they do not help if actions have external side effects.\n\nBatch and Stream ProcessingThe goal of data integration is to make sure that data ends up in the right form in all the right places. Doing so requires consuming inputs, transforming, joining, filtering, aggregating, training models, evaluating, and eventually writing to the appropriate outputs. Batch and stream processors are the tools for achieving this goal.\nIn principle, one type of processing can be emulated on top of the other, although the performance characteristics vary.\n\nFor example, Spark can do stream processing based on batch processing core via cut events into microbatches.\n\nMaintaining derived stateIn principle, derived data systems could be maintained synchronously, just like a relational database updates secondary indexes synchronously within the same transaction as writes to the table being indexed.\nHowever, asynchrony is what makes systems based on event logs robust: it allows a fault in one part of the system to be contained locally, whereas distributed transactions abort if any one participant fails, so they tend to amplify failures by spreading them to the rest of the system.\nWhat’s more, secondary indexes often cross-partition boundaries. A partitioned system with secondary indexes either needs to send writes to multiple partitions or send reads to all partitions. Such cross-partition communication is also most reliable and scalable if the index is maintained asynchronously.\nReprocessing dataStream processing allows changes in the input to be reflected in derived views with low delay, whereas batch processing allows large amounts of accumulated historical data to be reprocessed in order to derive new views onto an existing dataset.\nIn particular, reprocessing existing data provides a good mechanism for maintaining a system, evolving it to support new features and changed requirements. For example, add a new column in schema or change the data type and layout.\nDerived views allow gradual evolution. If you want to restructure a dataset, you do not need to perform the migration as a sudden switch. Instead, you can maintain the old schema and the new schema side by side as two independently derived views onto the same underlying data.\nThe lambda architectureThe lambda architecture can combine batch and stream processing (reprocess historical data and process recent updates). The core idea of the lambda architecture is that incoming data should be recorded by appending immutable events to an always-growing dataset, just like event sourcing.\nThe lambda architecture proposes running two different systems in parallel. In the lambda approach, the stream processor consumes the events and quickly produces an approximate update to the view; the batch processor later consumes the same set of events and produces a corrected version of the derived view.\n\nThe reasoning behind this design is that batch processing is simpler and thus less prone to bugs, while stream processors are thought to be less reliable and harder to make fault-tolerant. Moreover, the stream process can use fast approximate algorithms while the batch process uses slower exact algorithms.\n\nHowever, lambda architecture also has its own drawbacks:\n\nHaving to keep both batch and stream processing logics which have the same goal.\nThe output of batch and stream processing need to be merged.\nTo avoid reproduce the whole history, batch processing may need some mechanism to support incremental batches.\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (10)Batch Processing","url":"/2023/12/12/DDIA-cookbook-10-Batch-Processing/","content":"Systems of Record and Derived Data\nSystems of record\n\nA system of record, also known as source of truth, holds the authoritative version of your data. When new data comes in, it is first written here. Each fact is represented exactly once (the representation is typically normalized). If there is any discrepancy between another system and the system of record, then the value in the system of record is the correct one.\n\nDerived data systems\n\nData in a derived system is the result of taking some existing data from another system and transforming or processing it in some way. If you lose derived data, you can recreate it from the original source. Denormalized values, indexes, and materialized views also fall into this category.\nDerived data is redundant, in the sense that it duplicates existing information. However, it is often essential for getting good performance on read queries. It is commonly denormalized. You can derive several different datasets from a single source, enabling you to look at the data from different “points of view”.\n\nThree Different Systems\nServices (online systems)\n\nA service waits for a request or instruction from a client to arrive. When one is received, the service tries to handle it as quickly as possible and sends a response back. Response time is usually the primary measure of performance of a service, and availability is often very important.\n\nBatch processing systems (offline systems)\n\nA batch processing system takes a large amount of input data, runs a job to process it, and produces some output data. Jobs often take a while, so there normally isn’t a user waiting for the job to finish. Instead, batch jobs are often scheduled to run periodically (for example, once a day). The primary performance measure of a batch job is usually throughput.\n\nStream processing systems (near-real-time systems)\n\nStream processing is somewhere between online and offline&#x2F;batch processing. Like a batch processing system, a stream processor consumes inputs and produces outputs. However, a stream job operates on events shortly after they happen, whereas a batch job operates on a fixed set of input data. This difference allows stream processing systems to have lower latency than the equivalent batch systems.\n\nMapReduce and Distributed FilesystemsHadoop Distributed File System (HDFS)Unix tools use stdin and stdout as input and output, MapReduce jobs read and write files on a distributed filesystem, for example Hadoop Distributed File System (HDFS).\nHDFS is based on the shared-nothing principle, in contrast to the shared-disk approach of Network Attached Storage (NAS). HDFS consists of a daemon process running on each machine, exposing a network service that allows other nodes to access files stored on that machine. A central server called the NameNode keeps track of which file blocks are stored on which machine. Thus, HDFS conceptually creates one big filesystem that can use the space on the disks of all machines running the daemon.\n\nIn order to tolerate machine and disk failures, file blocks are replicated on multiple machines.\n\nMapReduce ExecutionA standard MapReduce contains 4 parts:\n\nInput Parser &rarr; Read and parse the input file from HDFS, e.g. break it up to list of records.\nMapper &rarr; Call the mapper function to extract a key and value from each input record.\nShuffle &rarr; Distribute the key-value pairs by key to machines (pairs with similar keys will be assigned in the same machine).\nReducer &rarr; Aggregate key-value pairs to generate output.\n\nDistributed ExecutionMapReduce can parallelize a computation across many machines, without you having to write code to explicitly handle the parallelism.\n\nEach input file is typically hundreds of megabytes in size. The MapReduce scheduler (not shown in the diagram) tries to run each mapper on one of the machines that stores a replica of the input file, provided that machine has enough spare RAM and CPU resources to run the map task. This principle is known as putting the computation near the data: it saves copying the input file over the network, reducing network load and increasing locality.\nThe reduce side of the computation is also partitioned. While the number of map tasks is determined by the number of input file blocks, the number of reduce tasks is configured by the engineer.\n\nIn reality, the mapper and reducer don’t have the application code, so the application code needs two callback functions as mapper and reducer, then send their code to running machines, and wait for the output (or a signal to notify application to get final output).\n\nStorageThe key-value pairs must be sorted, but the dataset is likely too large to be sorted with a conventional sorting algorithm on a single machine. Instead, the sorting is performed in stages. First, each map task partitions its output by reducer, based on the hash of the key. Each of these partitions is written to a sorted file on the mapper’s local disk via technique similar to SSTables and LSM-Trees.\nWhenever a mapper finishes reading its input file and writing its sorted output files, the MapReduce scheduler notifies the reducers that they can start fetching the output files from that mapper. The reducers connect to each of the mappers and download the files of sorted key-value pairs for their partition. The process of partitioning by reducer, sorting, and copying data partitions from mappers to reducers is known as the shuffle.\n\nFor every reducer, it will iterate all mappers, and only download what they need. Because they download files rather than records, so mapper needs to put all related&#x2F;similar records into one or close files, that’s why mapper needs SSTables and LSM-Trees technique.\n\nThe reduce task takes the files from the mappers and merges them together, preserving the sort order. Thus, if different mappers produced records with the same key, they will be adjacent in the merged reducer input.\nThe reducer can use arbitrary logic to process these records, and can generate any number of output records. These output records are written to a file on the distributed filesystem (usually, one copy on the local disk of the machine running the reducer, with replicas on other machines).\nWorkflowsIt is very common for MapReduce jobs to be chained together into workflows, such that the output of one job becomes the input to the next job.\nThe Hadoop MapReduce framework does not have any particular support for workflows, so this chaining is done implicitly by directory name: the first job must be configured to write its output to a designated directory in HDFS, and the second job must be configured to use that same directory name for reading its input. From the MapReduce framework’s point of view, they are two independent jobs.\ndef MapReduceJob(input_file, output_file):    ...job1 = MapReduceJob(&quot;/hdfs/source&quot;, &quot;/tmp/output_1&quot;)job2 = MapReduceJob(&quot;/tmp/output_1&quot;, &quot;/tmp/output_2&quot;)job3 = MapReduceJob(&quot;/tmp/output_2&quot;, &quot;/hdfs/output&quot;)\n\nA batch job’s output is only considered valid when the job has completed successfully (MapReduce discards the partial output of a failed job). Therefore, one job in a workflow can only start when the prior jobs—that is, the jobs that produce its input directories—have completed successfully.\nReduce-Side Joins and GroupingFor batch processing, we always discuss bulk data processing, which means we use full table scan instead of index scan.\n\nImagine we have a task that needs to analyze the top 10 popular websites for every age stages. We have one records describing the things that logged-in users did on a website. And another records for user informations. We need to do JOIN to get the relations between user activities and their ages.\nIn order to achieve good throughput in a batch process, the computation must be (as much as possible) local to one machine. Making random-access requests over the network for every record you want to process is too slow. Moreover, querying a remote database would mean that the batch job becomes nondeterministic, because the data in the remote database might change while the job is running.\nThus, a better approach would be to take a copy of the user database (for example, extracted from a database backup using an ETL process) and to put it in the same distributed filesystem as the log of user activity events. You would then have the user database in one set of files in HDFS and the user activity records in another set of files, and you could use MapReduce to bring together all of the relevant records in the same place and process them efficiently.\nSort-Merge JOINThe logic for sort-merge algorithm is: make every parts sorted, then merge them.\n\nIn leetcode, you may see problem that input are several unordered lists, and the output should be one sorted list containing all numbers from input lists. If we sort every input lists first then do merge, it’s sort-merge algorithm :).\ninput: [[9, 1, 0, 3], [0, 8, 5, 2]]output: [0, 0, 1, 2, 3, 5, 8, 9]\n\n\n\nOne set of mappers would go over the activity events (extracting the user ID as the key and the activity event as the value).\nOne set of mappers would go over the user database (extracting the user ID as the key and the user’s date of birth as the value).\n\nWhen the MapReduce framework partitions the mapper output by key and then sorts the key-value pairs, the effect is that all the activity events and the user record with the same user ID become adjacent to each other in the reducer input.\nThe reducer can then perform the actual join logic easily: the reducer function is called once for every user ID, it can get the date-of-birth record from the user database. The reducer stores the date of birth in a local variable and then iterates over the activity events with the same user ID.\n\nFor MapReduce, we can use mapper to generate different dicts for different properties with the same key (e.g. &#123;user_id: age&#125; and &#123;user_id: [activity]&#125;). Then we JOIN these properties via the the same key (age JOIN activities USING user_id).\n\nHandling skew&#x2F;unbalanceThe pattern of “bringing all records with the same key to the same place” breaks down if there is a very large amount of data related to a single key. Such disproportionately active database records are known as hot keys. Since a MapReduce job is only complete when all of its mappers and reducers have completed, any subsequent jobs must wait for the slowest reducer to complete before they can start.\n\nSkewed Join &rarr; Sample data first to determine which keys are hot, spreads the work of handling the hot key over several reducers. In shuffle phase, the hot keys will be assgined to one of these reducers randomly. For the other input to the join, records relating to the hot key need to be replicated to all reducers handling that key.\n\nMap-Side JoinsThe reduce-side approach has the advantage that you do not need to make any assumptions about the input data: whatever its properties and structure, the mappers can prepare the data to be ready for joining. However, the downside is that all that sorting, copying to reducers, and merging of reducer inputs can be quite expensive.\nMap-side join uses a cutdown MapReduce job in which there are no reducers and no sorting. Instead, each mapper simply reads one input file block from the distributed filesystem and writes one output file to the filesystem—that is all.\nBroadcast hash JOINThe simplest way of performing a map-side join applies in the case where a large dataset is joined with a small dataset. In particular, the small dataset needs to be small enough that it can be loaded entirely into memory in each of the mappers.\nFor the task we described before, let’s assume the user information (user_id with their age) is small enough. In this case, when a mapper starts up, it can first read the user database from the distributed filesystem into an in-memory hash table. Once this is done, the mapper can scan over the user activity events and simply look up the user ID for each event in the hash table.\nFor another very large input file, we can have several map tasks, every task just contain small part of the large input file. That is called broadcast hash join.\n\nThe word broadcast reflects the fact that each mapper for a partition of the large input reads the entirety of the small input (so the small input is effectively “broadcast” to all partitions of the large input), and the word hash reflects its use of a hash table.\n\nPartitioned hash JOINThis approach only works if both of the join’s inputs have the same number of partitions, with records assigned to partitions based on the same key and the same hash function. For example, the hash function uses last digit of user_id, so there are 10 partitions (0~9) for both user age and user activities.\n\nThat’s why it’s also known as bucketed map joins &rarr; partition join’s datasets into buckets, then only join buckets with the same bucket id. It requires for both datasets, they have the same partition key and the same number of buckets (which implies have the same hash function).\n\nIf the partitioning is done correctly, you can be sure that all the records you might want to join are located in the same numbered partition, and so it is sufficient for each mapper to only read one partition from each of the input datasets. This has the advantage that each mapper can load a smaller amount of data into its hash table.\n\nFor example, mapper i only needs to load and join age and activities for user_id ends with number i.\n\nMerge JOINIf the input datasets are not only partitioned in the same way, but also sorted based on the same key, it does not matter whether the inputs are small enough to fit in memory, because a mapper can perform the same merging operation that would normally be done by a reducer.\nMap-side Vs Reduce-side Joins\nThe output of a reduce-side join is partitioned and sorted by the join key.\nThe output of a map-side join is partitioned and sorted in the same way as the large input.\n\nBecause the map-side join needs some assumptions about the input data (e.g. sort, size, partition, etc), so it always be used in the middle or rear of the chain, which means the input data is actually some reducer’s output.\nHadoop Vs Distributed DatabaseThe biggest difference is that distributed databases focus on parallel execution of SQL queries on a cluster of machines, while the combination of MapReduce and a distributed filesystem provides something much more like a general-purpose operating system that can run arbitrary programs.\nDiversity of storageDatabases require you to structure data according to a particular model, whereas files in a distributed filesystem are just byte sequences.\nIn practice, it appears that simply making data available quickly—even if it is in a quirky, difficult-to-use, raw format—is often more valuable than trying to decide on the ideal data model up front. This idea is similar to data warehouse—dump data from various sources locally then do joins or aggregations.\nHadoop has often been used for implementing ETL processes:\n\nData from transaction processing systems is dumped into the distributed filesystem in some raw form.\nMapReduce jobs are written to clean up that data, transform it into a relational form, and import it into an MPP data warehouse for analytic purposes.\n\nData modeling still happens, but it is in a separate step, decoupled from the data collection. This decoupling is possible because a distributed filesystem supports data encoded in any format.\nDiversity of processing modelsMPP databases are monolithic, tightly integrated pieces of software that take care of storage layout on disk, query planning, scheduling, and execution. Moreover, the SQL is also deliberately designed for performance, e.g. predication pushdown, indexing, etc.\nOn the other hand, not all kinds of processing can be sensibly expressed as SQL queries. These kinds of processing are often very specific to a particular application, so they inevitably require writing code (mapper &amp; reducer), not just queries.\nDesigning for frequent faultsIf a node crashes while a query is executing, most MPP databases abort the entire query, and either let the user resubmit the query or automatically run it again. MPP databases also prefer to keep as much data as possible in memory to avoid the cost of reading from disk.\nOn the other hand, MapReduce can tolerate the failure of a map or reduce task without it affecting the job as a whole by retrying work at the granularity of an individual task. It is also very eager to write data to disk, partly for fault tolerance, and partly on the assumption that the dataset will be too big to fit in memory anyway.\n\nThe reason for why MapReduce is designed to tolerate frequent unexpected task termination: it’s not because the hardware is particularly unreliable, it’s because the freedom to arbitrarily terminate processes enables better resource utilization in a computing cluster.\n\n\nBeyond MapReduceMaterialization of Intermediate StateAs discussed previously, every MapReduce job is independent from every other job. The main contact points of a job with the rest of the world are its input and output directories on the distributed filesystem. If you want the output of one job to become the input to a second job, you need to configure the second job’s input directory to be the same as the first job’s output directory, and an external workflow scheduler must start the second job only once the first job has completed.\nIn many cases, you know that the output of one job is only ever used as input to one other job, the files on the distributed filesystem are simply intermediate state: a means of passing data from one job to the next. The process of writing out this intermediate state to files is called materialization.\nDownsides\nA MapReduce job can only start when all tasks in the preceding jobs have completed. Skew or varying load on different machines means that a job often has a few straggler tasks that take much longer to complete than the others. Having to wait until all of the preceding job’s tasks have completed slows down the execution of the workflow as a whole.\nMappers are often redundant: they just read back the same file that was just written by a reducer, and prepare it for the next stage of partitioning and sorting.\nStoring intermediate state in a distributed filesystem means those files are replicated across several nodes.\n\nSolutions - Execution EnginesIn order to fix these problems with MapReduce, several new execution engines for distributed batch computations were developed, the most well known of which are Spark and Flink. There are various differences in the way they are designed, but they have one thing in common: they handle an entire workflow as one job, rather than breaking it up into independent subjobs.\n\nRaw MapReduce is a chain of independent modules, the tunnel between modules is file (reducer write result to a file, which read by next mapper). Execution Engine manages this chain (these modules) to make it efficient.\n\nIn these execution engines, the mapper and reducer are called operators, and the execution engine provides several different options for connecting one operator’s output to another’s input (arrange the operators in a job as a directed acyclic graph (DAG)).\nIt offers several advantages compared to the MapReduce model:\n\nExpensive work such as sorting need only be performed in places where it is actually required, rather than always happening by default between every map and reduce stage.\nThere are no unnecessary map tasks, since the work done by a mapper can often be incorporated into the preceding reduce operator.\nBecause all joins and data dependencies in a workflow are explicitly declared, the scheduler has an overview of what data is required where, so it can make locality optimizations.\nIt is usually sufficient for intermediate state between operators to be kept in memory or written to local disk, which requires less I&#x2F;O than writing it to HDFS (where it must be replicated to several machines and written to disk on each replica).\nOperators can start executing as soon as their input is ready; there is no need to wait for the entire preceding stage to finish before the next one starts.\n\nFault ToleranceAn advantage of fully materializing intermediate state to a distributed filesystem is that it is durable, which makes fault tolerance fairly easy in MapReduce: if a task fails, it can just be restarted on another machine and read the same input again from the filesystem.\nBut materizalizing intermediate state is too expensive, so some take a different approach: if a machine fails and the intermediate state on that machine is lost, it is recomputed from other data that is still available (a prior intermediary stage if possible, or otherwise the original input data, which is normally on HDFS). To enable this recomputation, the framework must keep track of how a given piece of data was computed—which input partitions it used, and which operators were applied to it (e.g. Resilient Distributed Dataset (RDD) in Spark).\nWhen recomputing data, it is important to know whether the computation is deterministic: that is, given the same input data, do the operators always produce the same output? This question matters if some of the lost data has already been sent to downstream operators. The solution in the case of nondeterministic operators is normally to kill the downstream operators as well, and run them again on the new data.\nHigh-level APIsRaw mapper and reducer function in MapReduce is not human-friendly, so some high-level APIs occur to solve these problems.\nThese dataflow APIs generally use relational-style building blocks to express a computation: joining datasets on the value of some field; grouping tuples by key; filtering by some condition; and aggregating tuples by counting, summing, or other functions. Internally, these operations are implemented using the various join and grouping algorithms that we discussed earlier in this chapter.\nThese high-level interfaces not only make the humans using the system more productive, but they also improve the job execution efficiency at a machine level.\nThe move toward declarative query languagesMapReduce and its dataflow successors are very different from the fully declarative query model of SQL. MapReduce was built around the idea of function callbacks: which means programmer can assign any functions, packages, modules and classes to mapper and reducer. They have clear instructions about how to run the code step-by-step.\n\n\ndeclarative language &rarr; what should be done, like SQL, only give the purpose;\nimperative language &rarr; how to do, like Python, C++, give the step-by-step code.\n\n\nHowever, declarative query language has its own advantages: the framework can analyze the properties of the inputs and commands, and automatically decide what is the best algorithm to optimize the processing.\n\nFor example, in SQL JOIN, execution engine can apply “predication pushdown”, or iter the smaller table first then iter the bigger one.\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (2)Data Models and Query Languages","url":"/2023/08/10/DDIA-cookbook-2-Data-Models-and-Query-Languages/","content":"Data ModelA data model is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities.\nMorden applications are built by layering one data model on top of another. Each layer hides the complexity of the layers below it by providing a data model.\n\nRelational Vs Document ModelOne-to-Many\nFor relational model, is hard to represent One-to-Many relationship, like one person may have 0 to infinite work experience.\n\nRelational &rarr; create multiple table to store company info, school info, then use foreign key to JOIN several tables\nDocument &rarr; can use JSON-like structure, easy to read by human, and better locality (store these info in one place)\n\nMany-to-One &amp; Many-to-ManyWhen we store the region, we use ID rather than pure text. This is because ID has no meaning, it never needs to change. For example, if we want to update “Greater Seattle Area” to “Seattle”, we just need to modify the text in region_table.\nDocument model is good at One-to-Many because you can imagine it as a tree, but it’s not good at Many-to-X, because it looks like a graph.\nIf document model doesn’t support JOIN, then we need to use iteration to mock JOIN in application level. Even if it supports JOIN, we still need to use document reference (just like foreign key), which is similar to relational model.\nlocalityFor document database, it always store the whole document as a single object.\nFor read, it need to load the whole document from disk to memory, so if we need most of parts inside the document, it’s fine; otherwise, its performance is poor.\nFor write, it also need to rewrite the whole document from memory to disk, and only modifications that don’t change the total encoded size of a document can easily be performed in place; otherwise, system need to assign new space for new document.\nschema-on-read vs schema-on-writeDocument Database is not schemaless. Actually, it has implicit constrain, like when we write service code to read something from DB, we assume we can get some fields, so schema-on-read is a more accurate term.\n\n\n    schema-on-read\n    check when we READ\n    poor efficiency, cuz we cannot do any optimizations when we write it\n\n\n    schema-on-write\n    check when we WRITE\n    good efficiency cuz we can check the type then do optimization\n\n\n\nSummary\n\n\n\ndocument\nrelation\n\n\n\nrelation map\ntree, one-to-many\ncan use foreign key to achieve many-to-X\n\n\nJOIN\n:(\n:)\n\n\nflexibility\nflexible, can add fields easily\nschema, hard to change\n\n\nlocality\nif operate the whole doc, performance is good; but if only operate partial doc, performance is not good\nscatter in tables\n\n\n\nQuery LanguageDeclarative vs Imperative Language\n\n\n\nDeclarative\nImperative\n\n\n\nConcept\ndeclare the logic rather than actual execution\ndefine the execution plan\n\n\nExample\nSQL, CSS\nC++, Python, …\n\n\nAbstraction\nhigh\nlow\n\n\nParallel\ngood, cuz we let system do the optimization\npoor, cuz we already defined the steps\n\n\n\nWhat u want?\nHow to do that?\n\n\nHere are some advantages for declarative language:\n\nMore concise and easily use\nHide implementation details\nGood support for parallelism\n\nMapReduce QueryMapReduce is neither a declarative language nor a imperative language.\n\n\ndeclarative &rarr; we don’t need to specify how to iter or shuffle dataset\nimperative &rarr; we need to implement map and reduce functions\n\n\nIt requires the map and reduce are pure function, which means they only use input data, they cannot do anything else like query database.\nAnd they cannot have any side effects, which means no matter when we run the function for a given input, the output should be the same.\nWhat’s more, mapreduce is a very low-level model for distributed execution, so engineers can implement higher-level query language base it, like SQL can be implemented as a pipeline of mapreduce.\n\nGraph Data ModelSuitable for Many-to-Many relationships.\n\nvertice &#x2F; node\nedge &#x2F; relation\nattribute\n\nGraph can store both homogeneous and heterogeneous data. For example, node can represents people, city, animal, activity, etc.\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (1)Reliable, Scalable, and Maintainable Application","url":"/2023/08/10/DDIA-cookbook-1-Reliable-Scalable-and-Maintainable-Application/","content":"IntroCPU is no longer the bottle neck. New problems are amount of data, complexity of data and the speed of changing. We call it data-intensive.\n\nStorage - Database\nSpeed - Cache\nSearch - Indexing\nUnkonwn size, continuous, asynchronous - Stream Processing\nAccumulated data - Batch Processing\n\nRight now, single tool is hard to meet requirements. And new tools are designed to optimize for variety of use cases, the boundary between category is blurred.\n\nReliabilityWhat is correct? It’s hard to define, but we can simply consider:\n\nThe App performs what user expected\nThe App can tolerate some mistakes or using it in unexpected ways\nThe App is good enough under certain load and data volume\nThe App prevents any abuse or unauthorized access\n\nThen we can define reliable means “continuing to work correctly, even bad things happend”.\nThe bad things are called faults, a reliable system should be fault-tolerant.\n\nfault vs failure\n\nfault - system deviates from original design\nfailure - system cannot work (crush)\n\nWe should design fault-tolerance mechanisms to prevent faults from causing failure\n\nHardware FaultsMorden hardware system will use RAID to add redundancy to reduce the fault rate.\nHardware faults are random and independent for most of the cases.\nSoftware ErrorsSoftware errors are sometimes correlated. And these bugs may hide for a long time until we trigger it.\n\nScalabilityScalability is used to describe a system’s ability to cope with increased load or changed resources.\nLoadRemember use case is always the key. Load can be:\n\nrequest per second\nread &#x2F; write ratio\nhit rate on cache\n…\n\nWhen we consider the load, the first thing is make the use case clear. There isn’t best solution, there is only suitable solution.\nPerformanceThere have two situations:\n\nIf load increases, and we keep the resource unchanged, how the performance changes?\nIf load increases, how many resources we need to change to keep the performance unchanged?\n\nTo solve these, we need to measure performance.\nThere are two key term: \n\nthroughput &rarr; the number of tasks we can process per second\nresponse time &rarr; the time between client sending request and receiving response\n\n\nlatency vs response time\n\nlatency &rarr; duration for a request waitting to be handled\nresponse time &rarr; user aspect, I send a request, how long it takes until I get response, it may include network delay, queuing delay, processing time, etc\n\n\nPercentileIf we run a request multiple times, the response time is not a fixed number, it has distribution. So average response time is p50 (50% percent).\nFor most of the response time, it looks good, so we always pay attention to tail latencies (high percentile), like p99 (90%) or p999 (99.9%). These response time is always very large and affect user’s experience.\nSLO SLAService Level Objectives &amp; Service Level Agreements are contracts that define the expected performance and avaliability of a service.\nFor example, some SLAs may define “p50 &lt; 50ms, p99 &lt; 100ms”.\nQueuing Delay &amp; HoLQueuing delay is one of the most significant reason for tail latency, because limited resource can only handle limited things in parallel.\nIf we have many requests, they will form a queue. Even the following 99% requests are fast, if the first 1% requests are slow, it will block the queue, and make the total execution time increasing. It’s called Head-of-Line block.\nApproaches for coping with loadScale up &rarr; vertical scale, means build more powerful machine\nScale out &rarr; horizontal scale, means distribute total load into several small machines\nElastic &rarr; autoscale, means this system can detect load changing, and automatically scale to keep performance\n\nMaintainability\nOperability - make it easy for operation team to keep the system running smoothly\nSimplicity - make new engineer can understand the system easily\nEvolvability - make it easy for adding new features\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (4)Encoding","url":"/2023/08/25/DDIA-cookbook-4-Encoding/","content":"CompatibilityMorden software development will use rolling upgrade or staged rollout, which means deploying the new version to a few nodes at a time, checking whether the new version is bug free or not, then gradually upgrade all nodes.\nAnd also we need to consider that our client may not install new version for some time.\nSo the new and old data formats, codes, policies will coexist in our system.\n\nBackward compatibility &rarr; newer data can read data that written by older code\nForward compatibility &rarr; older data can read data that written by newer code\n\n\nEncodingIn memory, we have various data structures like hash map, dictionary, vector, etc. But when we want to write data to a file or send it over network, we have to transform the complex data structure to simple sequence of bytes.\nThe process to transform data structure to bytes called encoding &#x2F; serialization; the process to translate bytes to data structure called decoding &#x2F; deserialization.\nThe problems are:\n\nhow can we encode &#x2F; decode data to save time and space\nhow can we make the format be compatible\n\nthrift and protobufThey are binary encoding libraries that are based on the same principle. Both Thrift and Protocol Buffers require a schema for any data that is encoded.\nstruct Person &#123;    1: required string userName,    2: optional i64 favoriteNumber,    3: optional list&lt;string&gt; interests &#125;\n\nmessage Person &#123;    required string user_name = 1;    optional int64 favorite_number = 2;    repeated string interests = 3;&#125;\n\n\nNote: this format called Interface Defination Language(IDL).\n\nField tags and schema evolutionEach field is identified by its tag number (the numbers 1, 2, 3 in the sample schemas) and annotated with a datatype (like int64, string, etc). You can change the name of a field in the schema, since the encoded data never refers to field names, but you cannot change a field’s tag, since that would make all existing encoded data invalid.\nYou can add new fields to the schema, provided that you give each field a new tag number and make it optional or has default value.\n\n\nforward: If old code (which doesn’t know about the new tag numbers you added) tries to read data written by new code, including a new field with a tag number it doesn’t recognize, it can simply ignore that field. The datatype annotation allows the parser to determine how many bytes it needs to skip\nbackward: The new code can always read old data, because the tag numbers still have the same meaning. The only detail is that if you add a new field, you cannot make it required. If you were to add a field and make it required, that check would fail if new code read data written by old code, because the old code will not have written the new field that you added.\n\n\nRemoving a field is just like adding a field, you can only remove a field that is optional and you can never use the same tag number again.\nThe merits of schemas\nThey can be much more compact than the various “binary JSON” variants, since they can omit field names from the encoded data.s\nThe schema is a valuable form of documentation, and because the schema is required for decoding, you can be sure that it is up to date.\nKeeping a database of schemas allows you to check forward and backward compatibility of schema changes, before anything is deployed.\nFor users of statically typed programming languages, the ability to generate code from the schema is useful, since it enables type checking at compile time.\n\n\nModes of DataflowDataflow through DatabasesFor database, it may be accessed by several processes, some requests are old, some are new, so compatibility is very important. Sometimes DBMS may alter the table schema to add or delete fields, which may cause problem:\n\ndifferent values written at different timesIn database, you may have some values that were written five milliseconds ago, and some values that were written five years ago. When you change your service code (e.g. change the encoding policy), the five-year-old data will still be there, in the original encoding, unless you have explicitly rewritten it since then. This observation is sometimes summed up as data outlives code.\nRewriting (migrating) data into a new schema is certainly possible, but it’s an expensive thing to do on a large dataset.\nMost relational databases allow simple schema changes, such as adding a new column with a null default value, without rewriting existing data. When an old row is read, the database fills in nulls for any columns that are missing from the encoded data on disk.\narchive dataWhen you take a snapshot of your database from time to time, say for backup purposes or for loading into a data warehouse. In this case, the data dump will typically be encoded using the latest schema, even if the original encoding in the source database contained a mixture of schema versions from different eras.\n\nSince you’re copying the data anyway, you might as well encode the copy of the data consistently.\n\nDataflow through service callsMicroservices &rarr; make the application easier to change and maintain by making services independently deployable and evolvable.\n\nFor example, each service should be owned by one team, and that team should be able to release new versions of the service frequently, without having to coordinate with other teams. In other words, we should expect old and new versions of servers and clients to be running at the same time.\n\nRESTfulREST (Representational state transfer) is not a protocol, but rather a design philosophy that builds upon the principles of HTTP.\nTL;DR &rarr; use URL to locate resources, use HTTP verbs to describe actions, use HTTP status codes to indicate results\n\nwww.myblog.com/introduce is a webpage related to introduce myself; www.myblog.com/blog/python/python_intro is a blog to introduce python\n\n\nGET means fetch data from server, POST means submit form from client, DELETE means delete resources in server, etc (although POST can also be achieved by GET, but we need to clarify our actions)\n\nReference &rarr; What is RESTful API\nUniform interfaceIt indicates that the server transfers information in a standard format. The formatted resource is called a representation in REST. This format can be different from the internal representation of the resource on the server application. For example, the server can store data as text but send it in an HTML representation format.\nUniform interface imposes four architectural constraints:\n\nRequests should identify resources. They do so by using a uniform resource identifier (URI).\nClients have enough information in the resource representation to modify or delete the resource if they want to. The server meets this condition by sending metadata that describes the resource further.\nClients receive information about how to process the representation further. The server achieves this by sending self-descriptive messages that contain metadata about how the client can best use them.\nClients receive information about all other related resources they need to complete a task. The server achieves this by sending hyperlinks in the representation so that clients can dynamically discover more resources.\n\nStatelessnessIn REST architecture, statelessness refers to a communication method in which the server completes every client request independently of all previous requests. Clients can request resources in any order, and every request is stateless or isolated from other requests. This REST API design constraint implies that the server can completely understand and fulfill the request every time. \nLayered systemIn a layered system architecture, the client can connect to other authorized intermediaries between the client and server, and it will still receive responses from the server. Servers can also pass on requests to other servers. You can design your RESTful web service to run on several servers with multiple layers such as security, application, and business logic, working together to fulfill client requests. These layers remain invisible to the client.\nCacheabilityRESTful web services support caching, which is the process of storing some responses on the client or on an intermediary to improve server response time. For example, suppose that you visit a website that has common header and footer images on every page. Every time you visit a new website page, the server must resend the same images. To avoid this, the client caches or stores these images after the first response and then uses the images directly from the cache. RESTful web services control caching by using API responses that define themselves as cacheable or noncacheable.\nCode on demandIn REST architectural style, servers can temporarily extend or customize client functionality by transferring software programming code to the client. For example, when you fill a registration form on any website, your browser immediately highlights any mistakes you make, such as incorrect phone numbers. It can do this because of the code sent by the server.\nRPCProblems\nA local function call is predictable and either succeeds or fails, depending only on parameters that are under your control. RPC is unpredictable: the request or response may be lost due to a network problem, or the remote machine may be slow or unavailable, and such problems are entirely outside of your control.\nA local function call either returns a result, or throws an exception, or never returns. RPC has another possible outcome: it may return without a result, due to a timeout.\nIf you retry a failed network request, it could happen that the requests are actually getting through, and only the responses are getting lost. In that case, retrying will cause the action to be performed multiple times.\nEvery time you call a local function, it normally takes about the same time to execute. A network request is much slower than a function call, and its latency is also wildly variable.\nWhen you call a local function, you can efficiently pass it references (pointers) to objects in local memory. When you make a network request, all those parameters need to be encoded into a sequence of bytes that can be sent over the network.\nThe client and the service may be implemented in different programming languages.\n\nEvolutionFor services dataflow, it is reasonable to assume that all the servers will be updated first, and all the clients second. Thus, we only need backward compatibility on requests, and forward compatibility on responses.\nService compatibility is made harder by the fact that RPC is often used for communication across organizational boundaries, so the provider of a service often has no control over its clients and cannot force them to upgrade.\nFor RESTful APIs, common approaches are to use a version number in the URL or in the HTTP Accept header.\nDataflow through asynchronous message passing\nService &rarr; one process sends a request over the network to another process and expects a response as quickly as possible\nDatabase &rarr; one process writes encoded data, and another process reads it again sometime in the future\n\nThe asynchronous message-passing systems, which are somewhere between RPC and databases.\nThey are similar to RPC in that a client’s request (usually called a message) is delivered to another process with low latency. They are similar to databases in that the message is not sent via a direct network connection, but goes via an intermediary called a message broker (a.k.a. message queue), which stores the message temporarily.\n\none database &rarr; store message in queue + two RPC &rarr; sender with queue, queue with receiver\n\nUsing a message broker has several advantages compared to direct RPC:\n\nIt can act as a buffer if the recipient is unavailable or overloaded, and thus improve system reliability.\nIt can automatically redeliver messages to a process that has crashed, and thus prevent messages from being lost.\nIt avoids the sender needing to know the IP address and port number of the recipient.\nIt allows one message to be sent to several recipients.\nIt logically decouples the sender from the recipient because the sender just publishes messages and doesn’t care who consumes them.\n\nHowever, a difference compared to RPC is that message-passing communication is usually one-way: a sender normally doesn’t expect to receive a reply to its messages. This communication pattern is asynchronous: the sender doesn’t wait for the message to be delivered, but simply sends it and then forgets about it.\nmessage brokerMessage brokers are used as follows: one process sends a message to a named queue or topic, and the broker ensures that the message is delivered to one or more consumers of or subscribers to that queue or topic.\n\nseveral consumers share one topic (mutual exclusive)\nevery consumer own its topic\n\nA topic provides only one-way dataflow. However, a consumer may itself publish messages to another topic like a chain, or to a reply queue that is consumed by the sender of the original message. So by combining several topics together, we can achieve complex topology.\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (3)OLTP, OLAP and Columnar Store","url":"/2023/08/21/DDIA-cookbook-3-OLTP-OLAP-and-Columnar-Store/","content":"OLTP &amp; OLAPOLTP &rarr; Online Transaction Processing.\nOLAP &rarr; Online Analytics Processing.\nA transaction needn’t have ACID. Transation processing just means allowing client to make low-latency reads and writes, which is opposed to batch processing.\nCompare\n\n\nProperty\nOLTP\nOLAP\n\n\n\nread\nsmall number of records per query, fetched by key\naggregate large amount of records\n\n\nwrite\nrandom access, low-latency\nbulk ELT or streaming\n\n\nprimary used by\nuesr, client\ninternal analyst for decision making\n\n\nwhat data represents\nlatest data state\nhistory of events that happened over time\n\n\ndata size\nsmall or medium\nlarge\n\n\nData Warehouse\nWarehouse will Extract-Transform-Load (ELT) data from multiple TP database and keep a read-only version data, so that when run AP in data warehouse, there is no inference with TP’s tasks.\nStars &#x2F; Snowflakes ModelStars model &rarr; center is the main table, and connect with several second level tables via foreign key\nSnowflakes model &rarr; similar to star model, but it may have more levels like third or fourth level to represent more detailed information\n\nColumn-orientedStorage Layout\nFor data warehouse, its main table may have 100+ even 1000+ columns, but for certain query, we just need roughly 2 ~ 3 columns for calculation. If we use row-oriented storage layout, it needs to fetch one row with 1000+ fields, then get only 2 ~ 3 data, then iter to next row. It has bad performance.\nIf we use column-oriented storage layout, it just need to fetch the required columns from disk and do aggregations.\nCompressionAnother advantage of column-oriented storage is: it can be compressed.\n\nfor column, it represents the same concept, so its domain may be small, for example, if column represents country, then it can only have 200 or 300 possible values\nfor column, it always has the same data type, like integer column, string column or boolean column, etc\n\nDue to these two properties, we can compress column via compression algorithm, e.g. Bitmask for bool, Run Length Encoding, etc.\nMemory bandwidthBecause column can be compressed, and for query we just fetch required columns without any useless fields, we can utilize memory bandwidth efficiently.\nVectorized processingSingle-Instruction-Multi-Data (a.k.a SIMD) technology can achieve vectorized processing, especially for bitwise operator, such as AND, OR, etc.\nv1 = [&quot;tom&quot;, &quot;bob&quot;, &quot;jack&quot;]bitmask = 0b010v1 SIMD bitmask = [None, &quot;bob&quot;, None]\n\nSort in column storage\nMost cases, we focus on aggregation of certain column, so the order is unnecessary\nSome cases, order can help us compress the column and do aggregation\nFor example, if we sort “age” column, then we can store the column as “(18, 100), (20, 50)” which means 100 rows have age&#x3D;18, 50 rows have age&#x3D;20.\n\n\nIt wouldn’t make sense to sort each column independently, because we will lose the information about which fields are in the same row\nDifferent queries benefit from different sort orders, so it can store the same data sorted in several ways\nFor example, in a cluster we have 3 machines, all of them can provide service. Then we can store data sorted by age in machine 1, sorted by name in machine 2, sorted by sex in machine 3.\n\n\n\nWriting to Column StorageAn update-in-place approach, like B-trees use, is not possible with compressed columns.\nWe can use LSM-Tree like method: All writes first go to an in-memory store, where they are added to a sorted structure and prepared for writing to disk. It doesn’t matter whether the in-memory store is row-oriented or column-oriented. When enough writes have accumulated, they are merged with the column files on disk and written to new files in bulk.\nAggregation: Data Cube &amp; Materialized ViewData warehouse queries often involve aggregations, such as COUNT, SUM, AVG, MIN, or MAX in SQL. If the same aggregates are used by many different queries, it can be wasteful to crunch through the raw data every time. So we can cache some of the counts or sums that queries use most often in disk.\nThe concept to persistent store something from memory into disk called materialize.\nThe materialized view is an actual copy of the query results, written to disk. When the underlying data changes, a materialized view needs to be updated, because it is a denormalized copy of the data.\nA common special case of a materialized view is known as a data cube, which is a grid of aggregates grouped by different dimensions.\n\n\nColumn familiy &ne; Column storageColumn family is a new concept for some databases like HBase and Cassandra.\nIts schema may looks like\n\n    \n        Id\n        Name\n        Work\n        Personal\n    \n    \n        Work.Phone\n        Work.Address\n        Personal.Phone\n        Personal.Address\n    \n    \n        1\n        Tom\n        xxx-xxx-xxxx\n        xxxx\n        yyy-yyy-yyyy\n        yyyy\n    \n    \n        2\n        Bob\n        xxx-xxx-xxxx\n        xxxx\n        yyy-yyy-yyyy\n        yyyy\n    \n\n\nThe column family means the Work.Phone and Work.Address are under Work family, the storage still uses row-oriented.\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (5)Replication","url":"/2023/08/26/DDIA-cookbook-5-Replication/","content":"IntroWhy need multiple machines\nScalability &rarr; If your data volume, read load, or write load grows bigger than a single machine can handle, you can potentially spread the load across multiple machines.\nFault-tolerance&#x2F;high availability &rarr; If your application needs to continue working even if one machine goes down, you can use multiple machines to give you redundancy.\nLatency &rarr; If you have users around the world, you might want to have servers at various locations worldwide so that each user can be served from a datacenter that is geographically close to them.\n\nScalingVertical ScalingVertical Scaling or Scaling up means upgrade to a more powerful machine.\nThere are two strategies:\n\nshared-memory &rarr; many CPUs use same memory and disk\nshared-disk &rarr; many CPUs and memories use same disk\n\nBut they have several problems:\n\nThe cost grows faster than linearly, add double hardware doesn’t mean double performance\nFor shared-memory, it’s limited to a single location\nFor shared-disk, the overhead of locking limit the scalability\n\nHorizontal scalingHorizontal Scaling or Scaling out treat every machine as node, each node uses its CPUs, RAM, and disks independently. Any coordination between nodes is done at the software level, using a conventional network.\nBecause every node is independent, so its strategy calls shared-nothing. It usually incurs additional complexity for applications and sometimes limits the expressiveness of the data models you can use.\nReplication Vs Partitioning\n\nReplication &rarr; Keeping a copy of the same data on several different nodes, potentially in different locations. Replication provides redundancy.\n\nPartitioning &rarr; Splitting a big database into smaller subsets called partitions so that different partitions can be assigned to different nodes (also known as sharding).\n\n\n\nLeader &amp; FollowerEach node that stores a copy of the database is called a replica. Every write to the database needs to be processed by every replica; otherwise, the replicas would no longer contain the same data. The most common solution for this is called leader-follower&#x2F;master-slave replication.\n\n\nOne of the replicas is designated the leader (also known as master). When clients want to write to the database, they must send their requests to the leader.\nThe other replicas are known as followers (slaves or hot standbys). Whenever the leader get writes request, it also sends the data change to all of its followers as part of a replication log or change stream. Each follower takes the log from the leader and updates its local copy of the database accordingly, by applying all writes in the same order as they were processed on the leader.\nWhen a client wants to read from the database, it can query either the leader or any of the followers. However, writes are only accepted on the leader.\n\n\n\nSynchronous vs Asynchronous\n\nSync &rarr; leader waits until follower has confirmed that it received the write before reporting success to the user.\nAsync &rarr; leader sends the message, but doesn’t wait for a response from the follower.\n\nThe differences between sync and async are:\n\nsync sacrifices high availability to achieve strict consistency\nasync sacrifices strict consistency to achieve high availability\n\nHere are three configurations for different availability and consistency requirements:\n\nfully sync &rarr; leader finishes its write after all followers ack\nsemi sync &rarr; leader finishes its write after some of followers ack\nasync &rarr; leader finishes its write immediately, no need to wait follower ack\n\nSetting Up New FollowersFrom time to time, you need to set up new followers—perhaps to increase the number of replicas, or to replace failed nodes.\nWe cannot directly copy all current data files from other nodes because:\n\nclient will constantly write new data or update old data, if we only copy current data, it’s inconsistent\nif we block client’s write request, we can make all data consistent, but lose high availability\n\nThe correct apporach is:\n\nTake a consistent snapshot of the leader’s database at some point in time.\nCopy the snapshot to the new follower node.\nThe follower connects to the leader and requests all the data changes that have happened since the snapshot was taken. The position of snapshot is sometimes called log sequence number or binlog coordinates.\nWhen the follower has processed the backlog of data changes since the snapshot, we say it has caught up. It can now continue to process data changes from the leader as they happen.\n\nHandling Node OutageFollower: catch-up recoveryEach follower keeps a log of the data changes it has received from the leader.\nThe follower can recover quite easily: from its log, it knows the last transaction that was processed before the fault occurred. Thus, the follower can connect to the leader and request all the data changes that occurred during the time when the follower was disconnected.\nLeader: failoverFailover\nDetermining that the leader has failed. The most common Failure detection algorithm uses timeout.\n\nChoosing a new leader. Leader election algorithm and Consensus algorithm: the leader is chosen by a majority of the remaining replicas and is usually the replica with the most up-to-date data changes from the old leader.\n\nReconfiguring the system to use the new leader. Clients now need to send their write requests to the new leader. The system needs to ensure that the old leader becomes a follower and recognizes the new leader.\n\n\nProblems\nIf asynchronous replication is used, the new leader may not have received all the writes from the old leader before it failed. If the former leader rejoins the cluster after a new leader has been chosen, the new leader may have received conflicting writes in the meantime. The most common solution is for the old leader’s unreplicated writes to simply be discarded.\n\nDiscarding writes is especially dangerous if other storage systems outside of the database need to be coordinated with the database contents.\n\nFor example current system needs to use Redis as cache, and the old leader wrote some primary key into Redis, then it crashed. The new leader also store its auto incremental primary key into Redis, but because its data is not up-to-date, so there may have some primary key already in Redis.\n\n\nIn certain fault scenarios, it could happen that two nodes both believe that they are the leader.\n\nHow to set a reasonable timeout value.\n\n\nImplementation of Replication LogsStatement-based replicationLeader records the SQL statements and send them to followers. The leader just acts like a client to there followers.\n\nFor example, the log may has recordSELECT * FROM table WHERE conditionsINSERT properties INTO table VALUES(values)\n\nThe disadvantages:\n\nNondeterministic &rarr; functions such as NOW() and RAND() are likely to generate a different value on each replica.\n\nExecution Order &rarr; if they use autoincrementing column, or if they depend on the existing data in the database, they must be executed in exactly the same order on each replica, or else they may have a different effect.\n\nSide effects &rarr; like triggers, stored procedures, user-defined functions may result in different side effects occurring on each replica, unless the side effects are absolutely deterministic.\n\n\nWrite-Ahead Log (WAL)WAL is used for recovery:\n\nIn the case of a log-structured storage engine, every modification is first written to a write-ahead log so that the memtable can be recovered even the crash happens.\n\nIn the case of a B-tree, which overwrites individual disk blocks, every modification is first written to a write-ahead log so that the index can be restored to a consistent state after a crash.\n\n\nIt’s append-only sequence of bytes. The disadvantage is:\n\nWAL contains details of which bytes were changed in which disk blocks. This makes replication closely coupled to the storage engine.\n\nIf the storage engine changes or is incompatible, WAL may cannot allocate the data to certain position.\nLogical Log (binlog in MySQL)A log should be decoupled from the storage engine.\nA logical log for a relational database is usually a sequence of records describing writes to database tables at the granularity of a row:\n\nFor an inserted row, the log contains the new values of all columns.\nFor a deleted row, the log contains enough information to uniquely identify the row that was deleted. (tombstone)\nFor an updated row, the log contains enough information to uniquely identify the updated row, and the new values of all columns.\nFor transaction, the log will append a flag to inform the commit of the transaction.\n\nProblems with Replication LagIf we have multiple followers, we can get:\n\navailablity &rarr; tolerate some faults in other machine\nscalability &rarr; read can be distributed so we can deal with more requests\nlow-latency &rarr; request can choose a fast path\n\nBut the question is: how to make all replics look the same.\nIf we choose sync replication, all problems can be solved except that if some replics crash, the service is blocked to wait for replics recovery, which may cause user complain and is unacceptable.\nSo the only way is async replication. But it may has a problem: some replics may fall behind other replics.\nThis leads to apparent inconsistencies in the database: if you run the same query on the leader and a follower at the same time, you may get different results, because not all writes have been reflected in the follower.\nGood news is this inconsistency is just a temporary state—if you stop writing to the database and wait a while, the followers will eventually catch up and become consistent with the leader. For that reason, this effect is known as eventual consistency.\nReading Your Own Writes\nIn this situation, we need read-after-write consistency. This is a guarantee that if the user reloads the page, they will always see any updates they submitted themselves. It makes no promises about other users: other users’ updates may not be visible until some later time.\nMethods\nWhen reading something that the user may have modified, read it from the leader; otherwise, read it from a follower.\nTrack the time of the last update and, if new requests within certain time threshold, make all reads from the leader.\nThe client can remember the timestamp of its most recent write—then the system can ensure that the replica serving any reads for that user reflects updates at least until that timestamp.\n\nProblems\nTimestamp is very hard to sync for one logic user has multiple physical device.\nReplicas are distributed across different datacenters, there is no guarantee that connections from different devices will be routed to the same datacenter.s\n\nMonotonic Reads\nMonotonic reads is a guarantee that is a lesser guarantee than strong consistency, but a stronger guarantee than eventual consistency. When you read data, you may see an old value; monotonic reads only means that if one user makes several reads in sequence, they will not see time go backward.\n\nFor example, the old data is 1 &rarr; 2, and right now the newest data is 3, when we send the first read, it may return “2”, then I send several reads, it makes sure that the responses look like “2, 2, 2, …, 3, 3, 3”. “1” will never appear and if we see “3”, “2” will never appear.\n\nMethods\neach user always makes their reads from the same replica (different users can read from different replicas).\ntimestamp\n\nDifference with “Reading your own writes”“Reading your own writes” guarantees the read order after write, “Monotonic reads” guarantees multiple reads order.\nConsistent Prefix Reads (Causal)\nThe reason for inconsistent prefix is partition. The order inside one partition is easy to maintain, but inter partition is hard.\nMethods\nno partition.\nroute all causal requests to same partition, but how to detect several requests are causal is hard.\n\nSolutions for Replication LagTransaction!!! We will cover it later.\n\nMulti-leadersLeader-based replication has one major downside: there is only one leader, and all writes must go through it. So the extension for it is using multiple leaders.\n\nSingle leader vs Multiple leaders\n\n\n\nsingle leader\nmultiple leaders\n\n\n\nPerformance\nEvery write must go over the internet to the datacenter with the leader. This can add significant latency to writes.\nEvery write can be processed in the local datacenter and is replicated asynchronously to the other datacenters.\n\n\nTolerance of datacenter outages\nIf the datacenter with the leader fails, failover can promote a follower in another datacenter to be leader, the whole system needs to wait until new leader starts.\nEach datacenter can continue operating independently of the others, the failed datacenter can select new leader by their own.\n\n\nTolerance of network problems\nIt is very sensitive to public internet (inter-datacenter link).\nA multi-leader configuration with asynchronous replication can usually tolerate network problems better: a temporary network interruption does not prevent writes being processed.\n\n\nUse case\nClients with offline operation - Consider the calendar apps on your mobile phone, your laptop, and other devices. Every device has a local database that acts as a leader (it accepts write requests), and there is an asynchronous multi-leader replication process (sync) between the replicas of your calendar on all of your devices.\nDatabase spanning multiple data centers.\nCollaborative editing - Like Google Doc.\n\nDownsideBut multi-leaders has a big problem: the same data may be concurrently modified in two different datacenters, and those write conflicts must be resolved. So multi-leader is not a universal choice for all situations.\nHandling Write Conflicts\nConflict DetectionIn a single-leader database:\n\nthe second writer will either block and wait for the first write to complete\nabort the second write transaction, forcing the user to retry the write\n\nIn a multi-leader setup, both writes are successful, and the conflict is only detected asynchronously at some later point in time. At that time, it may be too late to ask the user to resolve the conflict.\nIn principle, you could make the conflict detection synchronous—i.e., wait for the write to be replicated to all replicas before telling the user that the write was successful. However, by doing so, you would lose the main advantage of multi-leader replication: allowing each replica to accept writes independently. If you want synchronous conflict detection, you might as well just use single-leader replication.\nConflict AvoidanceHandle conflicts &rarr; Avoid conflicts.\nThe core is: if the application can ensure that all writes for a particular record go through the same leader, then conflicts cannot occur.\n\nFor example, in an application where a user can edit their own data, you can ensure that requests from a particular user are always routed to the same datacenter and use the leader in that datacenter for reading and writing. Different users may have different “home” datacenters, but from any one user’s point of view the configuration is essentially single-leader.\n\nThe only problem is: if the user changes the datacenter, e.g. move from new york to california or origin datacenter is down, the conflict occurs.\nConflict Converging (收敛)A single-leader database applies writes in a sequential order: if there are several updates to the same field, the last write determines the final value of the field. But for multi-leaders, every datacenter may has its own order, it hard to define a universal order.\nConvergent &rarr; means that all replicas must arrive at the same final value when all changes have been replicated.\n\nGive each write a unique ID (e.g., a timestamp, a long random number, a UUID, or a hash of the key and value), pick the write with the highest ID as the winner. (if a timestamp is used, this technique is known as last write wins (LWW))\nGive each replica a unique ID, and let writes that originated at a highernumbered replica always take precedence over writes that originated at a lowernumbered replica.\nMerge the values together.\nRecord the conflict information and try to solve it later.\n\nCustom Conflict Resolution\nOn write\n\nAs soon as the database system detects a conflict in the log of replicated changes, it calls the conflict handler (callback function). This handler typically cannot prompt a user—it runs in a background process and it must execute quickly.\n\n\n\nOn read\n\nWhen a conflict is detected, all the conflicting writes are stored. The next time the data is read, these multiple versions of the data are returned to the application. The application may prompt the user or automatically resolve the conflict, and write the result back to the database.\n\n\nMulti-leaders Replication Topologies\n\n\n\n\nCircular\nStar &#x2F; Tree\nAll-to-All\n\n\n\nAdvantage\nTotal amount of replication messages is the same as amount of nodes, which is small.\n\nFault tolerance\n\n\nDisadvantage\nIf just one node fails, it can interrupt the flow of replication messages between other nodes, causing them to be unable to communicate until the node is fixed.\nThe same as circular.\n1. Total amount of replication messages is large  2. Because it doesn’t have order (no prior node or next node), the variation of latency of network links may cause causality problem.\n\n\n\nFor circular &amp; star, to aviod broadcast flooding, each node has a unique identifier, and in the replication log, each write needs to record all nodes it passed through.\n\n\nIf the latency of network links are different, the causality problem may occur.Because the update depends on the prior insert, so we need to make sure that all nodes process the insert first, and then the update. Simply attaching a timestamp to every write is not sufficient, because clocks sync is difficult. To order these events correctly, a technique called version vectors or vector clock, which is a logical clock. We will talk about that in next chapter.\n\n\nLeaderlessIn leaderless implementations:\n\nthe client directly sends its writes to several replicas.\na coordinator node does this on behalf of the client. However, unlike a leader database, that coordinator does not enforce a particular ordering of writes.\n\nWriting to the Database When a Node Is DownIn a leaderless configuration, failover does not exist because it doesn’t have leader :).\nThe client sends the write to all replicas (let’s say n replicas) in parallel, and x available replicas accept the write but the n-x unavailable replicas miss it. We have a threshold h that if at least h replicas reply ok, we think the write is finished and we ignore the remaining n-h replicas. According to following figure, we can think x=2, n=3, h=2.\n\nWhen a client reads from the database, it doesn’t just send its request to one replica: read requests are also sent to several nodes in parallel. The client may get different responses from different nodes; i.e., the up-to-date value from one node and a stale value from another. Version numbers are used to determine which value is newer.\nRead repair and anti-entropy (AE)The replication scheme should ensure that eventually all the data is copied to every replica. After an unavailable node comes back online, how does it catch up on the writes that it missed?\n\nRead repair\nWhen a client makes a read from several nodes in parallel, it can detect any stale responses. When the client sees certain replica has a stale value, it writes the newer value back to that replica. This approach works well for values that are frequently read.\n\n\n\nAnti-entropy\nIn addition, some datastores have a background process that constantly looks for differences in the data between replicas and copies any missing data from one replica to another. Unlike the replication log in leader-based replication, this anti-entropy process does not copy writes in any particular order, and there may be a significant delay before data is copied.\n\n\nIn more basic terms, the AE service identifies missing or inconsistent shards and repairs them (it’s a DIFF process).\n\nAE can only perform its heroism when there is at least one copy of the shard still available. \nAE will not compare or repair hot shards, meaning that the shard can’t have active writes. Hot shards are more prone to change, and at any given moment, arrival of new data affects AE’s digest comparison.\n\n\n\n\nQuorums for reading and writingIf there are n replicas, every write must be confirmed by w nodes to be considered successful, and we must query at least r nodes for each read. As long as w + r &gt; n, we expect to get an up-to-date value when reading, because at least one of the r nodes we’re reading from must be up to date. Reads and writes that obey these r and w values are called quorum reads and writes.\nNormally, reads and writes are always sent to all n replicas in parallel. The parameters w and r determine how many nodes we wait for.\n\nWhat’s more, w and r are configurable, which means if the system is write heavy, we can set smaller w to reduce replication complexity.\nLimitations of Quorum ConsistencyEven w + r &gt; n, sometimes READ still gets stale values:\n\nIf a sloppy quorum is used, the n will change, which break the w + r &gt; n rule.\nIf two writes occur concurrently, it is not clear which one happened first. If we choose use timestamp to pick the winner, the clock skew will make replicas inconsistent.\nin leader-based strategy, leader will decide which is winner then send it to all replicas, but leaderless means every replica can has its own thought.\n\n\nIf a write happens concurrently with a read, the write may be reflected on only some of the replicas.\nIf a write succeeded on some replicas but failed on others and overall succeeded on fewer than w replicas, it is not rolled back on the replicas where it succeeded.\nIf a node carrying a new value fails, and its data is restored from a replica carrying an old value, the number of replicas storing the new value may fall below w, breaking the quorum condition.\n\nMonitoring stalenessEven if your application can tolerate stale reads, you need to be aware of the health of your replication. If it falls behind significantly, it should alert you so that you can investigate the cause.\nFor leader-based replication, the database typically exposes metrics for the replication lag, which you can feed into a monitoring system. This is possible because writes are applied to the leader and to followers in the same order, and each node has a position in the replication log (the number of writes it has applied locally). By subtracting a follower’s current position from the leader’s current position, you can measure the amount of replication lag.\nFor leaderless replication, there is no fixed order in which writes are applied, which makes monitoring more difficult. Moreover, if the database only uses read repair (no anti-entropy), there is no limit to how old a value might be — if a value is only infrequently read, the value returned by a stale replica may be ancient.\n\nFor leaderless, we can write only partial replicas, so the write log in one replica cannot represent the actual write order for the whole system.\n\nSloppy Quorums and Hinted HandoffA network interruption can easily cut off a client from a large number of database nodes. Although those nodes are alive, and other clients may be able to connect to them, to a client that is cut off from the database nodes, they might as well be dead. In this situation, it’s likely that fewer than w or r reachable nodes remain, so the client can no longer reach a quorum.\nThere are two choices:\n\nlet all write and read fail\naccept write for now, but write it to some nodes that are reachable but aren’t among the original n quorum\n\nThe second choice is called sloppy quorum.\n\nFor example originally we choice 10 nodes from [1, …, 10], and if some machines are not reachable ([1, 2, 3, 4]), we write to [5, …, 10, 11*, 12*, 13*, 14*].\n\nSloppy quorums are particularly useful for increasing write availability: as long as any w nodes are available, the database can accept writes. However, this means that even when w + r &gt; n, you cannot be sure to read the latest value for a key, because the latest value may have been temporarily written to some nodes outside of n\nOnce the network interruption is fixed, any writes that one node temporarily accepted on behalf of another node are sent to the appropriate “home” nodes. This is called hinted handoff.\n\nFor example, when 1, 2, 3, 4 become available, the 11*, 12*, 13*, 14* will quit the quorum and the system still use [1, …, 10] as quorum. But the problem is the [1, …, 4] don’t have up-to-date values. In some systems, 11*-14* may send temporary stored updates back to 1-4 to make the original quorum works like nothing happend.\n\nMulti-datacenter operationThe number of replicas n includes nodes in all datacenters, and in the configuration you can specify how many of the n replicas you want to have in each datacenter. Each write from a client is sent to all replicas, regardless of datacenter, but the client usually only waits for acknowledgment from a quorum of nodes within its local datacenter so that it is unaffected by delays and interruptions on the cross-datacenter link.\nOr keeps all communication between clients and database nodes local to one datacenter, so n describes the number of replicas within one datacenter. Cross-datacenter replication between database clusters happens asynchronously in the background, in a style that is similar to multi-leader replication.\nDetecting Concurrent WritesThe problem is that events may arrive in a different order at different nodes, due to variable network delays and partial failures. In order to become eventually consistent, the replicas should converge toward the same value.\nLast Write Wins (LWW)Even though the writes don’t have a natural ordering, we can force an arbitrary order on them. For example, we can attach a timestamp to each write, pick the biggest timestamp as the most “recent,” and discard any writes with an earlier timestamp. This conflict resolution algorithm, called last write wins (LWW).\nLWW achieves the goal of eventual convergence, but at the cost of durability: if there are several concurrent writes to the same key, even if they were all reported as successful to the client, only one of the writes will survive and the others will be silently discarded. Moreover, LWW may even drop writes that are not concurrent.\nIf losing data is not acceptable, LWW is a poor choice for conflict resolution.\nCausality (因果关系) vs ConcurrencyAn operation A happens before (causality) another operation B if B knows about A, or depends on A, or builds upon A in some way. So two operations are concurrent if neither happens before the other.\nIf one operation happened before another, the later operation should overwrite the earlier operation, but if the operations are concurrent, we have a conflict that needs to be resolved.\nFor defining concurrency, exact time doesn’t matter: we simply call two operations concurrent if they are both unaware of each other, regardless of the physical time at which they occurred, because in distributed systems, clock skew cannot be aviod.\nCapture the causality relationship\n\nThe algorithm is:\n\nThe server maintains a version number Vi for every key, increments the version number Vi &rarr; Vi+1 every time that key is written, and stores the new version number along with the value written.\nWhen a client reads a key, the server returns all values that have not been overwritten, as well as the latest version number.\nWhen a client writes a key, it must include the version number Vx from the prior read, and it must merge together all values that it received in the prior read.\nWhen the server receives a write with a particular version number Vx, it can overwrite all values with that version number or below V &leq; Vx (since it knows that they have been merged into the new value), but it must keep all values with a higher version number (because those values are concurrent with the incoming write).\nIf a client writes a key without any version number, add it into current dataset.\n\nMerging concurrently written valuesThis algorithm ensures that no data is silently dropped, but it unfortunately requires that the clients do some extra work: if several operations happen concurrently, clients have to clean up afterward by merging the concurrently written values. A simple approach is to just pick one of the values based on a version number or timestamp (last write wins), but that implies losing data.\nWhen delete data, we cannot directly delete it, we need to set a tombstone to mark it as unavailable.\nVersion vectorUse a version number per replica as well as per key. Each replica increments its own version number when processing a write, and also keeps track of the version numbers it has seen from each of the other replicas. This information indicates which values to overwrite and which values to keep as siblings. The version vector allows the database to distinguish between overwrites and concurrent writes.\n\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (6)Partitioning","url":"/2023/09/09/DDIA-cookbook-6-Partitioning/","content":"IntroThe main reason for wanting to partition data is scalability. Different partitions can be placed on different nodes in a shared-nothing cluster. Thus, a large dataset can be distributed across many disks, and the query load can be distributed across many processors.\nFor queries that operate on a single partition, each node can independently execute the queries for its own partition, so query throughput can be scaled by adding more nodes.\n\nPartition &amp; ReplicationPartitioning is usually combined with replication so that copies of each partition are stored on multiple nodes. This means that, even though each record belongs to exactly one partition, it may still be stored on several different nodes for fault tolerance.\n\nEach partition’s leader is assigned to one node, and its followers are assigned to other nodes. Each node may be the leader for some partitions and a follower for other partitions.\n\nPartitioning of Key-Value DataThe goal of partition is to evenly distribute dataset among machines. If the partitioning is unfair, so that some partitions have more data or queries than others, we call it skewed. A partition with disproportionately high load is called a hot spot.\nPartitioning by Key RangeOne way of partitioning is to assign a continuous range of keys to each partition.\n\nFor example, ‘a’-‘c’ in machine1, ‘d’-‘f’ in machine2, and so on.\n\nThe ranges of keys are not necessarily evenly spaced, because your data may not be evenly distributed. In order to distribute the data evenly, the partition boundaries need to adapt to the data.\n\nFor example, if ‘a’ and ‘e’ have more data, we can let ‘a’ in machine1, ‘b’-‘d’ in machine2, ‘e’ in machine3, and so on.\n\n\nAdvantage\nThe advantage of partitioning by key range is we can keep keys in sorted order (just like in SSTable). This has the advantage that range scans are easy, and you can treat the key as a concatenated index in order to fetch several related records in one query (just like yyyy-mm-dd).\n\n\n\nDisadvantage\nHowever, the downside of key range partitioning is that certain access patterns can lead to hot spots (because the order). For example, it we store the timestamp, and we always care about up-to-date value, then the machine stores new values will be hot spot.\n\n\nPartitioning by HashBecause of this risk of skew and hot spots, many distributed datastores use a hash function to determine the partition for a given key. A good hash function takes skewed data and makes it uniformly distributed.\nOnce you have a suitable hash function for keys, you can assign each partition a range of hashes (rather than a range of keys), and every key whose hash falls within a partition’s range will be stored in that partition.\nThe partition boundaries can be evenly spaced, or they can be chosen pseudorandomly (in which case the technique is sometimes known as consistent hashing).\n\nDownside\nUnfortunately however, by using the hash of the key for partitioning we lose a nice property of key-range partitioning: the ability to do efficient range queries.\n\n\n\nCassandra achieves a compromise between the two partitioning strategies. A table in Cassandra can be declared with a compound primary key consisting of several columns. Only the first part of that key is hashed to determine the partition, but the other columns are used as a concatenated index for sorting the data in Cassandra’s SSTables.\n\nSkewed Workloads and Relieving Hot SpotsIn the extreme case where all reads and writes are for the same key, you still end up with all requests being routed to the same partition. (for example, on a social media site, a celebrity user with millions of followers may cause a storm of activity when they do something)\nA simple way to solve this problem is: if one key is known to be very hot, a simple technique is to add a random number to the beginning or end of the key. Just a two-digit decimal random number would split the writes to the key evenly across 100 different keys, allowing those keys to be distributed to different partitions.\nHowever, having split the writes across different keys, any reads now have to do additional work, as they have to read the data from all 100 keys and combine it. You also need some way of keeping track of which keys are being split.\n\nPartitioning and Secondary IndexesA secondary index usually doesn’t identify a record uniquely but rather is a way of searching for occurrences of a particular value. The problem with secondary indexes is that they don’t map neatly to partitions.\nDocument Index (local)\nIn this indexing approach, each partition is completely separate: each partition maintains its own secondary indexes, covering only the documents in that partition. It doesn’t care what data is stored in other partitions.\n\nAdvantage &rarr; when write, just add the seconday index in local partition.\nDisadvantage &rarr; when read, because we only konw the local state, so need to iter all partitions to gather same seconday index information.\n\nTerm Index (global)\nRather than each partition having its own secondary index, we can construct a global index that covers data in all partitions. However, we can’t just store that index on one node, since it would likely become a bottleneck and defeat the purpose of partitioning. A global index must also be partitioned, but it can be partitioned differently from the primary key index.\n\nAdvantage &rarr; when read, just read one partition.\nDisadvantage &rarr; when write, a write to a single document may now affect multiple partitions of the index (every term in the document might be on a different partition, on a different node).\n\n\nRebalancing PartitionsThe process of moving load from one node in the cluster to another is called rebalancing.\nThe requirements are:\n\nAfter rebalancing, the load (data storage, read and write requests) should be shared fairly between the nodes in the cluster.\nWhile rebalancing is happening, the database should continue accepting reads and writes.\nNo more data than necessary should be moved between nodes, to make rebalancing fast and to minimize the network and disk I&#x2F;O load.\n\nStrategies for RebalancingThe simplest way to do partition is hash by mod n, which means key % N &#x3D; partition id. But the problem is: when we do rebalancing due to some nodes fail or change, the N will change, and most of the keys will need to be moved.\nFixed number of partitionsCreate many more partitions than there are nodes, and assign several partitions to each node.\n\nFor example, we have 10 nodes and 100 partitions, then every node stores 10 partitions.\n\nOnly entire partitions are moved between nodes. The number of partitions does not change, nor does the assignment of keys to partitions (we don’t change content of the partition, we just move it as a whole group). The only thing that changes is the assignment of partitions to nodes.\n\nThis change of assignment is not immediate, so the old assignment of partitions is used for any reads and writes that happen while the transfer is in progress.\nIn this configuration, the number of partitions is fixed when the database is first set up and not changed afterward. Although in principle it’s possible to split and merge partitions (see the next section), a fixed number of partitions is operationally simpler. Thus, the number of partitions configured at the outset is the maximum number of nodes you can have (make sure every nodes have at least more than one partition).\n\nDisadvantage &rarr; You need to choose the fixed number high enough to accommodate future growth (because the number cannot be changed). However, each partition also has management overhead, so it’s counterproductive to choose too high a number. It’s pretty hard to configure in advance especially when the data may change drasticly.\n\nDynamic partitioningWhen a partition grows to exceed a configured size, it is split into two partitions so that approximately half of the data ends up on each side of the split. Conversely, if lots of data is deleted and a partition shrinks below some threshold, it can be merged with an adjacent partition.\nEach partition is assigned to one node, and each node can handle multiple partitions, like in the case of a fixed number of partitions. After a large partition has been split, one of its two halves can be transferred to another node in order to balance the load.\n\nAdvantage &rarr; The number of partitions adapts to the total data volume.\n\nDisadvantage &rarr; An empty database starts off with a single partition, since there is no a priori information about where to draw the partition boundaries. So all read and write will hit the same node while other nodes are idle.\n\n\nPartitioning proportionally to nodes (Consistent Hash)For fixed partition, the size of each partition is proportional to the size of the dataset. For dynamic partition, the the number of partitions is proportional to the size of the dataset. In both of these cases, the number of partitions is independent of the number of nodes.\nA third option is to make the number of partitions proportional to the number of nodes—in other words, to have a fixed number of partitions per node. In this case, the size of each partition grows proportionally to the dataset size while the number of nodes remains unchanged, but when you increase the number of nodes, the partitions become smaller again. Since a larger data volume generally requires a larger number of nodes to store, this approach also keeps the size of each partition fairly stable.\nWhen a new node joins the cluster, it randomly chooses a fixed number of existing partitions to split, and then takes ownership of one half of each of those split partitions while leaving the other half of each partition in place. The randomization can produce unfair splits, but when averaged over a larger number of partitions, the new node ends up taking a fair share of the load from the existing nodes.\n\nPicking partition boundaries randomly requires that hash-based partitioning is used.\n\nWhen an old node leave the cluster, it also rebalances its partitions to other nodes, and do partition merging process.\nOperations: Automatic or Manual RebalancingFully automated rebalancing can be convenient, because there is less operational work to do for normal maintenance. However, it can be unpredictable. Rebalancing is an expensive operation, because it requires rerouting requests and moving a large amount of data from one node to another. If it is not done carefully, this process can overload the network or the nodes and harm the performance of other requests while the rebalancing is in progress.\nFor that reason, it can be a good thing to have a human in the loop for rebalancing. It’s slower than a fully automatic process, but it can help prevent operational surprises.\n\nRequest RoutingWhen a client wants to make a request, how does it know which node to connect to? As partitions are rebalanced, the assignment of partitions to nodes changes.\nThis is an instance of a more general problem called service discovery. There are several ways:\n\nAllow clients to contact any node. If that node coincidentally owns the partition to which the request applies, it can handle the request directly; otherwise, it forwards the request to the appropriate node, receives the reply, and passes the reply along to the client.\n\nSend all requests from clients to a routing tier first, which determines the node that should handle each request and forwards it accordingly. This routing tier does not itself handle any requests; it only acts as a partition-aware load balancer.\n\nRequire that clients be aware of the partitioning and the assignment of partitions to nodes. In this case, a client can connect directly to the appropriate node, without any intermediary.\n\n\nIn all cases, the key problem is: how does the component making the routing decision (which may be one of the nodes, or the routing tier, or the client) learn about changes in the assignment of partitions to nodes?\nMany distributed data systems rely on a separate coordination service such as ZooKeeper to keep track of this cluster metadata. Each node registers itself in ZooKeeper, and ZooKeeper maintains the authoritative mapping of partitions to nodes. Other actors, such as the routing tier or the partitioning-aware client, can subscribe to this information in ZooKeeper. Whenever a partition changes ownership, or a node is added or removed, ZooKeeper notifies the routing tier so that it can keep its routing information up to date.\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (3)B-Tree and LSM-Tree","url":"/2023/08/17/DDIA-cookbook-3-B-Tree-and-LSM-Tree/","content":"LogHere, we define log as an append-only sequence of records.\n\nIndexIndex is an additional data structure, which doesn’t affect the contents of database, but affect the operation performance.\nIndex can speed up the read, but slow down the write cuz we need to maintain the index.\nHash IndexKey-Value StoreHash index is commonly used in Key-Value Storage. We can keep an in-memory hash map where every key is mapped to a offset in the data file. And we also store the k-v in log file which locates in disk. Every time we write a new k-v pair, we append the k-v in log file (notice log file in disk), and modify the index in memory. \nHowever, it may run out of disk space. A good way to solve this problem is Compaction.\nCompaction\nWe can store the index information in the segment, when the segment reach its size limitation, we make subsequent write in new segment. Then we can perform compaction process for these frozen segments. If same key appears many times in these segment, we just keep the newest value. It will generate the new compacted segments in new files and delete old segments to save space.\nThe whole process can happen in background thread, so it will not affect the service.\nTo find a value for a key, we just check the most recent segment, if the key is not present, then second-most-recent and so on.\nConsiderations\nDeleting Records &rarr; we need to keep the delete operation in logs (sometimes use special mark called tombstone)\nto mark the pervious operations for this key are useless, so if there is no new record for this key, this key shouldn’t appear in compacted segment.\nCrash Recovery &rarr; when database is restarted, in-memory hashmap is erased. We can iter all segment k-v info to rebuild the hashmap, but it’s costy. We can choose to store the k-v info and snapshots of the in-memory hashmap on disk, so that we just load the snapshots to rebuild hashmap.\nConcurrency Control &rarr; as writes are appended to the log in a strictly sequential order, a common implementation choice is to have only one writer thread. Data file segments are append-only and otherwise immutable, so they can be read concurrently by multiple threads.\n\nlog-structured vs update-in-placelog-structured &gt; update-in-place\n\nappend (sequential access) is always more efficient than random access\nconcurrency control and crash recovery are simpler &rarr; thanks for immutable log (or say it’s append-only)\ncompaction can reduce fragment problem\n\nlog-structured &lt; update-in-place\n\nkey must in memory\nkey is good for point searching but is bad for range searching\n\nSSTable &amp; LSM-TreeIf we let the key are sorted in segment, we call it Sorted String Table or SSTable.\nWhy SSTable is useful?\n\nMerging&#x2F;Compacting segments is simple and efficient. It use merge sort algorithm to achieve high efficiency. If one key appears in multiply segments, just use the most up-to-date segment value.\n\n\n\nSparse index. We don’t need to keep all keys in memory, instead, just keep sparse index.\nFor example, create key for “A”, and key for “C”, then key “B” must between these two.\n\n\nCompression. Since read requests need to scan over several key-value pairs in the requested range, it’s possible to group those records into a block and compress it before writing it to disk.\n\nConstruct and maintain SSTable\nWhen write comes in, add it to a in-memory data structure (red-black tree, AVL tree, etc). This in-memory tree is called memtable.\nThis data structure can insert unordered data, and dump ordered data, for simplicity, just imagine binary search tree, we can insert data in any order, then read them via pre-order traversal to get ordered output.\n\n\nWhen the memtable reachs its threshold, dump it into disk as a new SSTable (the data structure ensures when dump, it must be ordered). After SSTable is being written in disk, writes can continue to a new memtable.\nWhen read comes in, it check memtable first, then the most up-to-date SSTable, and so on.\nFrom time to time, a background process is running for compacting.\n\nThe only problem is: if crash happens, the memtable will lose all fresh data. To deal with it, we can add a log file in disk for memtable, if crash happens, just recover it from log file; if memtable dumps to disk, then delete the log file cuz it’s useless.\nMaking LSM-TreeLog-Structured Merge Tree is based on SSTable and memtable priciple. It will compact SSTable according to level or size.\n\nOptimization\nBloom Filter to aviod not exist keys.\nsize-tiered and level-tiered compaction.\n\n\nBloom Filter &rarr; it can judege that an element must not exist or possible exist\nFor a given input x, apply multiple hash functions to map its output in different place (you can imagine we have a vector&lt;bool&gt;), e.g. hash1(x), hash2(x), hash3(x). Then when we have a new input y, if hash1(y), hash2(y) and hash3(y) all have value (true in vector), which means y is possible exist; if any of these output don’t have value (false in vector), which means y must miss.\n\nThe basic idea of LSM Tree is: keeping a cascade of ordered SSTables that are merged in the background.\nBecause the data is sorted and sparse index can narrow the possible range, range query is also efficient, cuz you can use like binary search to boost query speed.\nB-TreeDifferent with LSM Tree who uses variable size of segments, B Tree breaks the database down into fixed size block or page, which aligns with disk design. So for any operations, the B-Tree uses page as unit.\nFor read, it’s just like find a value in binary search tree, whereas here is N-ary search tree, and the N called branching factor.\nFor update, it needs to load the whole page, update, then write the whole page back.\nFor write and delete, it may need to split &#x2F; merge node to make sure the tree is balanced.\nMaking tree reliableFor LSM Tree, the modifications will not change data in-place, instead, it will append new data and write to new place when compaction happens. But for B Tree, it wants to modify data in-place, which means modification doesn’t change the location of page.\nWhen the tree structure is adjusted, many pages may be modified in cascade. For example, after a leaf node is split, two new leaf nodes and a parent node need to be written (updating the leaf pointer).\n\ncrash &rarr; WAL (write ahead log), which means write the operation in log before execute it\nconcurrency control &rarr; latch (lighweight lock)\n\nOptimization\nInstead of WAL, use Copy-On-Write mechanism &rarr; instead of write page back to original place, create a new page in new place and modify parent’s pointer\nInstead of keep entire key, we can share prefix &rarr; for example, if the key is YYYYMMDD, the parent keeps YYYY, then its children keep MM, then DD. When we query, we must start from root, which means from left to right for key\nAdd pointers between leaf nodes to boost range query\n\nLSM-Tree vs B-TreeWrite Amplification &rarr; one write in database resulting in multiple writes to the disk.\nFor SSD, if there is a “delete” for some data, system cannot delete it immediately, system will give it a marker to indicate it’s useless. Remember for disk, the operation unit is page (or you can imagine it’s an area which contains many data), so when we execute a write:\n\nmove all useful data out of the page, and store them in somewhere\nerase all data in this page\nmove useful data back and add new data\n\nIt’s obviously writing more data than what we actually want, and this is the amplification.\n| | B-Tree | LSM-Tree || — | — | — | — || R&#x2F;W | read faster | write faster || Write Amplification | 1. data + WAL  2. massive data may cover different pages | 1. data + WAL  2. compaction needs to write in a new file || Write Throughput | low &rarr; random access | high &rarr; lower amplification; sequential access; compression makes smaller SSTable || Storage performance | lots of fragments | compaction save space || Bandwidth | predictable | compaction will take some bandwidth, which may infer service || Storage Amplification | some pages have unused space due to alignment | the same key exist in multiple segments || Concurrency | can add latch in parent nodes | one key exist in many places &rarr; MVCC |\nOther IndexPrimary vs Secondary| Id | Name | Age || --------------- || 1  | Tom  | 18  || 2  | Bob  | 18  || ...             |\n\nPrimary Index &rarr; index key is unique (such as primary key in MySQL), such as idSecondary Index &rarr; index key may be mapped to several values, such as age\nCluster vs Non-Cluster| Id | Name | Age || --------------- || 1  | Tom  | 18  || 2  | Bob  | 18  || ...             |\n\nCluster &rarr; index value is data, such as index[id=1] -&gt; &#123;id: 1, name: &quot;Tom&quot;, age: 18&#125;Non-Cluster &rarr; index value is pointer of data, such as index[age=18] -&gt; [id=1, id=2]\n\nFor MySQL\n\nprimary index is always cluster index &rarr; the leaf node of B-Tree is &lt;primary_key, row&gt;\nsecondary index is always non-cluster index &rarr; the leaf node of B-Tree is &lt;secondary_index, primary_key&gt;\n\n\n\nIn-Memory DBThe basic property for memory is: its data will lose after we restart the system. (except Non-Volatile Memory, aka NVM)\nWe can categorize in-memory DB into two categories:\n\nCache only &rarr; no persistency\nPersistency &rarr; use WAL, snapshot, replica for recovery and reload, but execute all operations in memory\n\nWhy in-memory DB is so efficient? Many people may think the biggest reason is it doesn’t need to communicate with disk. However, the truth is in-memory DB doesn’t need to decode&#x2F;encode data structures to fit into disk.\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (8)The Trouble with Distributed Systems","url":"/2023/11/01/DDIA-cookbook-8-The-Trouble-with-Distributed-Systems/","content":"Faults and Partial FailuresFor single computer system, it is usually either fully functional or entirely broken. System prefers to crash completely rather than return some “error message”.\nIn a distributed system, there may well be some parts of the system that are broken in some unpredictable way, even though other parts of the system are working fine. This is known as a partial failure. The key of distributed system is nondeterministic.\nSupercomputingSupercomputing (high-performance computing, HPC) &rarr; focus on intensive scientific computing tasks with the help of thousands of CPUs and powerful machines.\nIn a supercomputer, a job typically checkpoints the state of its computation to durable storage from time to time. If one node fails, a common solution is to simply stop the entire cluster workload. After the faulty node is repaired, the computation is restarted from the last checkpoint. Thus, a supercomputer is more like a single-node computer than a distributed system: it deals with partial failure by letting it escalate into total failure—if any part of the system fails, just let everything crash.\nCloud ComputingCloud computing &rarr; focus on multi-tenant datacenters, commodity computers connected with an IP network and elastic&#x2F;on-demand resource allocation.\nIf we want to make distributed systems work, we must accept the possibility of partial failure and build fault-tolerance mechanisms into the software.\n\nUnreliable NetworksIn distributed systems, we always use shared-nothing architecture, so the network is the only way those machines can communicate.\nThe internet and most internal networks in datacenters are asynchronous packet networks. In this kind of network, one node can send a message (a packet) to another node, but the network gives no guarantees as to when it will arrive, or whether it will arrive at all.\n\nYour request may have been lost;\nYour request may be waiting in queue;\nRemote node may have failed;\nRemote node may have processed your request, but the response has been lost;\nRemote node may have processed your request, but the response has been delayed due to traffic;\n\nThe usual way of handling this issue is a timeout: after some time you give up waiting and assume that the response is not going to arrive. However, when a timeout occurs, you still don’t know whether the remote node got your request or not.\nTimeout and Unbounded DelaysThere are two metrics:\n\nAccuracy &rarr;  every detected failure corresponds to a crashed process (no mistakes)\nCompleteness &rarr; every process failure is eventually detected (no misses)\n\nA short timeout detects faults faster, it has high completeness, but carries a higher risk of incorrectly declaring a node dead when in fact it has only suffered a temporary slowdown, which means it has low accuracy. Vice versa for a long timeout.\nIf we predict for a system\n\nthe maximum delay for packets — every packet is either delivered within some time d or it’s lost.\nthe maximum processing time for service — a non-failed node always handles a request within some time r.\n\nThen the reasonable timeout value is 2d+r. But the prerequisites are impossible: we cannot guarantee any bound for a system, this called unbounded delays.\nPossible Problems\nWhen a node is declared dead, its responsibilities need to be transferred to other nodes, which places additional load on other nodes and the network. If the system is already struggling with high load, declaring nodes dead prematurely can make the problem worse. In particular, it could happen that the node actually wasn’t dead but only slow to respond due to overload; transferring its load to other nodes can cause a cascading failure.\nPrematurely declaring a node dead is problematic: if the node is actually alive and in the middle of performing some action, and another node takes over, the action may end up being performed twice.\n\nUnbounded DelaysThere are 4 network delays:\n\nQueuing Delay &rarr; If several different nodes simultaneously try to send packets to the same destination, the network switch must queue them up and feed them into the destination network link one by one;\nProcessing Delay &rarr; The amount of time it takes processors to process the packet;\nTransmission Delay &rarr; If the request is very large, sender will chop it into several packets, it will take time to put all of these packets into network;\nPropagation Delay &rarr; Time taken for a single bit to traverse the physical medium from one end to the other;\n\nSync Vs AsyncIn sync network, it’s just like the circuit for telephone, we have bounded delays (e.g. known maximum round-trip time, no queuing delays).\n\nEven as data passes through several routers, it does not suffer from queueing, because the 16 bits of space for the call have already been reserved in the next hop of the network.\n\nIn async network, the unbounded delays occur.\nWhy distributed system doesn’t use circuit (sync network) logic? Because distributed system has bursty traffic (we don’t know how many bandwidth should be allocated). A circuit is good for an audio or video call, which needs to transfer a fairly constant number of bits per second for the duration of the call. On the other hand, requesting a web page, sending an email, or transferring a file doesn’t have any particular bandwidth requirement—we just want it to complete as quickly as possible. TCP is good at dynamic allocation, so we choose TCP over circuit.\n\nTCP has traffic and congestion control, it dynamically adapts the rate of data transfer to the available network capacity.\n\n\nUnreliable Physical ClocksClocks and time are import:\n\nHas the request timeout yet?\nWhat’s the 99th percentile response time?\nHow may QPS?\nWhen does the cache expire?\nWhat is the timestamp for logging?\n\nIn a distributed system, time is a tricky business, because communication is not instantaneous: it takes time for a message to travel across the network from one machine to another. What’s more, some machines maybe faster or slower than other machines.\nMonotonic Vs Time-of-Day Clocks\nTime-of-Day &rarr; return the difference with 1970-1-1 00:00:00, the value is meaningful, but due to clock skew in different clusters, the value may not be accurate.\nMonotonic &rarr; the single value is meaningless, but we can get two values then calculate its difference to get the elapsed time, it doesn’t assume any synchronization between different nodes’ clocks and is not sensitive to slight inaccuracies of measurement.\n\nClock Sync and AccuracyClock Sync is a pretty hard task:\n\nThe quartz clock in a computer is not very accurate: it drifts (runs faster or slower than it should).\nIf a computer’s clock differs too much from an NTP server, it may refuse to synchronize, or the local clock will be forcibly reset, which may influence ongoing tasks.\nIf a node is accidentally firewalled off from NTP servers, the misconfiguration may go unnoticed for some time.\nNTP synchronization can only be as good as the network delay.\n…\n\nRelying on Sync ClocksIf you use software that requires synchronized clocks, it is essential that you also carefully monitor the clock offsets between all the machines. Any node whose clock drifts too far from the others should be declared dead and removed from the cluster.\nLast write wins (LWW)It is widely used in both multi-leader replication and leaderless databases. Its logic is: if there is conflict of multiple writes, keep the write with maximum timestamp, it represents the newest (last) write, and will overwrite old (previous) writes.\nBut it still has some problems:\n\nDatabase writes can mysteriously disappear: a node with a lagging clock is unable to overwrite values previously written by a node with a fast clock until the clock skew between the nodes has elapsed.\nLWW cannot distinguish between writes that occurred sequentially in quick succession or concurrent.\nCausality tracking mechanisms, such as version vectors, are needed in order to prevent violations of causality.\n\nConfidence IntervalThe most common implementation of snapshot isolation requires a monotonically increasing transaction ID. However, when a database is distributed across many machines, potentially in multiple datacenters, a global, monotonically increasing transaction ID (across all partitions) is difficult to generate, because it requires coordination.\nCan we use timestamp? Yes! But it requires materialized design.\nSo instead of treating Time-of-Day value as a precise value, we can treat it as a range of time, just like [minimum possible timestamp, maximum possible timestamp], this is called confidence interval.\nGoogle Spanner use this “confidence interval” concept to implement its distributed transaction semantics, because Spanner depends on Google’s well-designed clock system!\n\nKnowledge, Truth and LiesQuorumA distributed system cannot exclusively rely on a single node, because a node may fail at any time, potentially leaving the system stuck and unable to recover. Instead, many distributed algorithms rely on a quorum, that is, voting among the nodes: decisions require some minimum number of votes from several nodes in order to reduce the dependence on any one particular node.\nFencing Tokens\nLet’s assume that every time the lock server grants a lock or lease, it also returns a fencing token, which is a number that increases every time a lock is granted (e.g., incremented by the lock service). We can then require that every time a client sends a write request to the storage service, it must include its current fencing token. This mechanism requires the resource itself to take an active role in checking tokens by rejecting any writes with an older token than one that has already been processed.\nByzantine FaultsByzantine fault &rarr; a node may claim to have received a particular message when in fact it didn’t.\nA system is Byzantine fault-tolerant if it continues to operate correctly even if some of the nodes are malfunctioning and not obeying the protocol, or if malicious attackers are interfering with the network. This concern is relevant in certain specific circumstances.\nMost Byzantine fault-tolerant algorithms require a supermajority of more than twothirds of the nodes to be functioning correctly.\nSystem ModelSystem model &rarr; formalize the kinds of faults that we expect to happen in a system.\n\nSync\nSynchronous model &rarr; The synchronous model assumes bounded network delay, bounded process pauses, and bounded clock error. This does not imply exactly synchronized clocks or zero network delay; it just means you know that network delay, pauses, and clock drift will never exceed some fixed upper bound.\nPartially synchronous model &rarr; Partial synchrony means that a system behaves like a synchronous system most of the time, but it sometimes exceeds the bounds for network delay, process pauses, and clock drift.\nAsynchronous model &rarr; In this model, an algorithm is not allowed to make any timing assumptions—in fact, it does not even have a clock.\nFaults\nCrash-stop faults &rarr; Node may suddenly stop responding at any moment, and thereafter that node is gone forever—it never comes back.\nCrash-recovery faults &rarr; Nodes may crash at any moment, and perhaps start responding again after some unknown time.\nByzantine (arbitrary) faults &rarr; Nodes may do absolutely anything, including trying to trick and deceive other nodes.\n\nSafety &amp; Liveness\nSafety &rarr; Nothing bad happens, for example: transaction with smaller timestamp should happens before transaction with larger timestamp.\nLiveness &rarr; Something good eventually happens.\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (11)Stream Processing","url":"/2023/12/15/DDIA-cookbook-11-Stream-Processing/","content":"IntroFor batch processing, the key is that the data is bounded, i.e. of a known and finite size so the batch process knows when it has finished reading inputs. In reality, a lot of data is unbounded because it arrives gradually over time, you have no idea about when to stop reading. Thus, batch processors must artificially divide the data into chunks of fixed duration. For stream processor, the data is incrementally made available over time.\n\nTransmitting Event StreamsIn batch processing, the inputs and outputs are files (chunks of data). In stream processing, the inputs are events.\n\nActually event is just a small, self-contained, immutable object containing the details of something that happended at some point in time. An event usually contains a timestamp indicating when it happened according to a time-of-day clock.\n\nIn batch processing, a file is written once and then potentially read by multiple jobs. And a filename indentifies a set of related records. \nIn streaming terminology, an event is generated once by a producer (also known as a publisher or sender), and then potentially processed by multiple consumers (subscribers or recipients). And related events are grouped together into a topic.\nMessaging SystemsThe most significant change for stream processing system is: the consumers only consume topics or events when they are notified.\nA common approach for notifying consumers about new events is to use a messaging system: a producer sends a message containing the event, which is then pushed to consumers, via communication channels like TCP. But the problem is: TCP is one-to-one, while stream processing needs one-to-many or many-to-many. We call it publish&#x2F;subscribe model.\nProblems\nWhat happens if the producers send messages faster than the consumers can process them?\ndrop messages\nbuffer messages in a queue &rarr; does the system crash if the queue no longer fits in memory, or does it write messages to disk?\nbackpressure (flow control)\n\n\nWhat happens if nodes crash or temporarily go offline—are any messages lost?\n\nA nice property of the batch processing systems is that batch processing systems provide a strong reliability guarantee: failed tasks are automatically retried, and partial output from failed tasks is automatically discarded. This means the output is the same as if no failures had occurred, which helps simplify the programming model.\nDirect messaging from producers to consumersA number of messaging systems use direct network communication between producers and consumers without going via intermediary nodes. It’s pretty simple and straight forward.\nHowever, these methods generally require the application code to be aware of the possibility of message loss. And the faults they can tolerate are quite limited: even if the protocols detect and retransmit packets that are lost in the network, they generally assume that producers and consumers are constantly online.\nMessage brokers &#x2F; Message queueIt runs as a server, with producers and consumers connecting to it as clients. Producers write messages to the broker, and consumers receive them by reading them from the broker.\nBy centralizing the data in the broker, these systems can more easily tolerate clients that come and go (connect, disconnect, and crash), and the question of durability is moved to the broker instead (broker can be configured how to tolerate message loss, application codes can ignore message loss).\n\nAsynchronous &rarr; when a producer sends a message, it normally only waits for the broker to confirm that it has buffered the message and does not wait for the message to be processed by consumers. The delivery to consumers will happen at some undetermined future point in time.\n\nCompared to databases\nDatabases usually keep data until it is explicitly deleted, whereas most message brokers automatically delete a message when it has been successfully delivered to its consumers.\nMost message brokers assume that their working set is fairly small—i.e., the queues are short.\nDatabases often support secondary indexes and various ways of searching for data, while message brokers often support some way of subscribing to a subset of topics matching some pattern.\nWhen querying a database, the result is typically based on a point-in-time snapshot of the data. By contrast, message brokers do not support arbitrary queries, but they do notify clients when data changes.\n\nMultiple consumers\n\nLoad balancing &rarr; multiple consumers share the broker\nFan-out &rarr; each message is delivered to all of the consumers\n\nAnd these two patterns can be combined: for example, two separate groups of consumers may each subscribe to a topic, such that each group collectively receives all messages, but within each group only one of the nodes receives each message.\nAcknowledgments and redeliveryConsumers may crash at any time, so it could happen that a broker delivers a message to a consumer but the consumer never processes it, or only partially processes it before crashing. In order to ensure that the message is not lost, message brokers use acknowledgments: a client must explicitly tell the broker when it has finished processing a message so that the broker can remove it from the queue.\n\nReordering is a problem when consider load balancing + redelivery. For example, if m3 crashed in consumer2, then we redeliver m3 to consumer1. The final order becomes [m2, m4, m3, m5] rather than [m2, m3, m4, m5].\nLog-based MessagingDifference between database with traditional brokerEverything that is written to a database is normally expected to be recorded in logs first (WAL). However, for message brokers that durably write messages to disk will quickly delete them again after they have been delivered to consumers, because they are built around a transient messaging mindset.\n\nIf a new consumer is added to a messaging system, it can only read messages that sent after the time it was registered, while in database system, it can retrive historical records.\n\nThis difference has a big impact on how derived data is created. A key feature of batch processes, is that you can run them repeatedly. This is not the case with messaging: receiving a message is destructive if the acknowledgment causes it to be deleted from the broker, so you cannot run the same consumer again and expect to get the same result.\nSolutionlog-based message broker is a hybrid, combining the durable storage approach of databases with the low-latency notification facilities of messaging. Because it has durable log (historical data), we can also do some operations like batch processing, for example, get all messages from yesterday.\n\nA log is simply an append-only sequence of records on disk.\n\nA producer sends a message by appending it to the end of the log, and a consumer receives messages by reading the log sequentially. If a consumer reaches the end of the log, it waits for a notification that a new message has been appended.\nFor scalability, logs can be partioned. A topic can then be defined as a group of partitions that all carry messages of the same type.\n\nWithin each partition, the broker assigns a monotonically increasing sequence number, or offset, to every message. Such a sequence number makes sense because a partition is append-only, so the messages within a partition are totally ordered. There is no ordering guarantee across different partitions.\nSince partitioned logs typically preserve message ordering only within a single partition, all messages that need to be ordered consistently need to be routed to the same partition.\nConsumer offsetsConsuming a partition sequentially makes it easy to tell which messages have been processed: all messages with an offset less than a consumer’s current offset have already been processed, and all messages with a greater offset have not yet been seen. Thus, the broker doesn’t need to wait for all acknowledgements.\n\nFor example, if broker stores message #1 to #10, and it receives ack for #8, which means #1-#8 already been consumed, it can delete message #1 to #8, and wait for ack number that greater than 8.\n\nIf a consumer fails, another idle node can be assigned to consume this partition, and starts at the last recorded offset. When the failed consumer recovers, it continues to consume according to the offset.\n\nThis is similar to log sequence number in single-leader replication. It allows a follower to reconnect to a leader after it has become disconnected, and resume replication without skipping any writes.\n\nWhen consumers cannot keep up with producersThe log is actually divided into segments, and from time to time old segments are deleted or moved to archive storage (common implementation includes ring buffer). If a slow consumer cannot keep up with the rate of messages, and it falls so far behind that its consumer offset points to a deleted segment, it will miss some of the messages.\nYou can monitor how far a consumer is behind, and raise an alert to ask some human operations.\nThe good news is: the slow consumer only affects its own partition, it doesn’t disrupt other consumers. When a consumer is shut down or crashes, it stops consuming resources—the only thing that remains is its consumer offset.\n\nDatabases and StreamsLog-based message broker uses some database logics in stream system. On the other hand, database can also use some logics of steam system.\nKeeping Systems in SyncIf periodic full database dumps are too slow (for example, dump whole data to build index and cache), an alternative that is sometimes used is dual writes, in which the application code explicitly writes to each of the systems when data changes.\ndb.run_sql(&quot;SQL COMMAND&quot;)if check_state(db):  # only run multiple operations when data changes    update_cache(db)    build_index(db)\n\nProblems @ Dual Writes\nConcurrency &rarr; in the database, X is first set to A and then to B, while at the search index the writes arrive in the opposite order.\n\n\n\nFault-tolerance &rarr; in the database, building index succeeds, but buding cache fails.\n\nChange Data CaptureThe problem with most databases’ replication logs is that they have long been considered to be an internal implementation detail of the database, not a public API. Clients are supposed to query the database through its data model and query language, not parse the replication logs and try to extract data from them.\nChange data capture (CDC), which is the process of observing all data changes written to a database and extracting them in a form in which they can be replicated to other systems. CDC is especially interesting if changes are made available as a stream, immediately as they are written.\n\n“Writing data in database” is the event, and “log in disk” is the message. The search index and any other derived data systems are just consumers of the change stream (log change as message broker).\nChange data capture is a mechanism for ensuring that all changes made to the system of record are also reflected in the derived data systems so that the derived systems have an accurate copy of the data.\n\nSystem of record is the groud truth, derived data system is another representation of the groud truth. CDC means: if the groud truth has change, then map this change to other representations.\n\nImplementing CDCssentially, change data capture makes one database the leader (the one from which the changes are captured), and turns the others into followers. A log-based message broker is well suited for transporting the change events from the source database to the derived systems, since it preserves the ordering of messages.\n\nCDC sounds like TRIGGER in DB, but TRIGGER is hard to use and has significant performance overheads, because TRIGGER will focus on data itself. While CDC mainly analyzes logs rather than data.\n\nSnapshot and Log compactionFor database replication, it has log sequence number to record the snapshot, if the database is crushed, then it will recover from the snapshot rather than from the very begining. It’s the same for CDC, it will only copy the changes after the snapshot to derived systems.\n\nFor example, if the system of record system has the following records:\n99  set A = 0100 set A = 1 &lt;- snapshot / LSN in database101 set A = 2102 set B = A103 set B = B + 1\nThen CDC can just use record number greater than 100 to build derived data.\n\nFor key-value structured system, it can compact its log by using new value to overwrite old value for the same key. For CDC, the log can only keeps the newest values, and when build derived systems, they can just use these newest values.\n\nFor example, if the system of record system has the following records:\n99  set A = 0100 set A = 1101 set A = 2102 set B = A103 set B = B + 1\nThen CDC can just keep compacted logs to build derived data.\nset A = 2set B = 3\n\n\nProcessing StreamsStreams can work as pipe: a stream processor consumes input streams in a read-only fashion and writes its output to a different location in an append-only fashion.\nThe partitioning, parallelization, mapping operations like transforming and filtering are the same as MapReduce (batch processing).\nThe one crucial difference to batch jobs is that a stream never ends:\n\nSort doesn’t make sense &rarr; unbound dataset cannot be sorted\nFault tolerance mechanisms changes &rarr; batch processing can be restarted, but stream processing is endless\n\nUses of Stream Processing\nComplex event processing (CEP) &rarr; It is an approach developed for analyzing event streams, especially geared toward the kind of application that requires searching for certain event patterns, for example, to find invalid operations in a long-term transaction.\nStream analytics &rarr; Usually be used to do aggregations and statistical metrics over a large number of events, for example, calculate statistics in a live TV show.\nMaintaining materialized views &rarr; A stream of changes to a database can be used to keep derived data systems, such as caches, search indexes, and data warehouses, up to date with a source database. Use stream processing can maintain these materialized views for efficient calculations and queries.\n\nReasoning About TimeFor batch processing, timing is not a huge problem. Because batch processing only processes historical data, so the requirements are always like “the average between 01&#x2F;01&#x2F;2023 and 12&#x2F;31&#x2F;2023”. There is no point in looking at the system clock of the machine running the batch process, it only use the timestamp in the record &#x2F; dataset.\nHowever, for stream processing, the requirements are like “the average over the last 30 seconds”, it touches the log timestamp and the system clock of running machine, where the lag and drift may occur.\nEvent time Vs Processing timeProcessing may be delayed by queuing, network failing, etc, and can also lead to unpredictable ordering of messages.\nConfusing event time and processing time leads to bad data. For example, say you have a stream processor that measures the rate of requests (counting the number of requests per second). If you redeploy the stream processor, it may be shut down for a minute and process the backlog of events when it comes back up. If you measure the rate based on the processing time, it will look as if there was a sudden anomalous spike of requests while processing the backlog, when in fact the real rate of requests was steady.\n\nKnowing when you’re readyA tricky problem when defining windows in terms of event time is that you can never be sure when you have received all of the events for a particular window, or whether there are some events still to come.\nFor example, say you’re grouping events into one-minute windows so that you can count the number of requests per minute. You can time out and declare a window ready after you have not seen any new events for that window in a while. However, it could still happen that some events were buffered on another machine somewhere, delayed due to a network interruption. You need to be able to handle such straggler events that arrive after the window has already been declared complete.\n\nIgnore the straggler events, as they are probably a small percentage of events in normal circumstances. You can track the number of dropped events as a metric, and alert if you start dropping a significant amount of data.\nPublish a correction, an updated value for the window with stragglers included. You may also need to retract the previous output.\n\nWhose clock are you using?Imagine the event can be buffer in mobile phone, PC, server and other devices. Different devices have different clocks, which may cause drift or skew. Whose clock are correct?\nTo adjust for incorrect device clocks, one approach is to log three timestamps:\n\nThe time at which the event occurred, according to the device clock\nThe time at which the event was sent to the server, according to the device clock\nThe time at which the event was received by the server, according to the server clock\n\nBy subtracting the second timestamp from the third, you can estimate the offset between the device clock and the server clock. You can then apply that offset to the event timestamp, and thus estimate the true time at which the event actually occurred.\nTypes of windowsOnce you know how the timestamp of an event should be determined, the next step is to decide how windows over time periods should be defined. The window can then be used for aggregations, for example to count events, or to calculate the average of values within the window. Several types of windows are in common use:\n\nTumbling window\n\nA tumbling window has a fixed length, and every event belongs to exactly one window. For example, if you have a 1-minute tumbling window, all the events with timestamps between 10:03:00 and 10:03:59 are grouped into one window, events between 10:04:00 and 10:04:59 into the next window, and so on. You could implement a 1-minute tumbling window by taking each event timestamp and rounding it down to the nearest minute to determine the window that it belongs to.\n\nHopping window\n\nA hopping window also has a fixed length, but allows windows to overlap in order to provide some smoothing. For example, a 5-minute window with a hop size of 1 minute would contain the events between 10:03:00 and 10:07:59, then the next window would cover events between 10:04:00 and 10:08:59, and so on. You can implement this hopping window by first calculating 1-minute tumbling windows, and then aggregating over several adjacent windows.\n\nSliding window\n\nA sliding window contains all the events that occur within some interval of each other. For example, a 5-minute sliding window would cover events at 10:03:39 and 10:08:12, because they are less than 5 minutes apart (note that tumbling and hopping 5-minute windows would not have put these two events in the same window, as they use fixed boundaries). A sliding window can be implemented by keeping a buffer of events sorted by time and removing old events when they expire from the window.\n\nSession window\n\nUnlike the other window types, a session window has no fixed duration. Instead, it is defined by grouping together all events for the same user that occur closely together in time, and the window ends when the user has been inactive for some time (for example, if there have been no events for 30 minutes). Sessionization is a common requirement for website analytics.\nStream JOINsNew events can appear anytime on a stream makes joins on streams more challenging than in batch jobs.\nStream-stream JOIN (window JOIN)For example, in a website, we have two streams:\n\nwhen user search a keyword, record an event that contains the keyword and its results.\nwhen user click one URL, record an event.\n\nIn order to calculate the click-through rate for each URL in the search results, you need to bring together the events for the search action and the click action, which are connected by having the same session ID.\n\nWhy not just record the URL when we click? Why JOIN? Because the click may never come if the user abandons their search, and even if it comes, the time between the search and the click may be highly variable.\nFor example, the user searched 10 times, but only clicked 5 times. If we just record the URL when user clicks, we only have information like “the user searched and clicked 5 times”, while if we do recording then JOIN, we will have “the user searched 10 but clicked 5, 5 still missing”.\nNote that record the details of the search in the click event is not equivalent to joining the events: doing so would only tell you about the cases where the user clicked a search result, not about the searches where the user did not click any of the results. In order to measure search quality, you need accurate click-through rates, for which you need both the search events and the click events.\n\nTo implement this type of join, a stream processor needs to maintain state: for example, all the events that occurred in the last hour, indexed by session ID. Whenever a search event or click event occurs, it is added to the appropriate index, and the stream processor also checks the other index to see if another event for the same session ID has already arrived. If there is a matching event, you emit an event saying which search result was clicked. If the search event expires without you seeing a matching click event, you emit an event saying which search results were not clicked.\nStream-table JOIN (stream enrichment)For example, one user continously change his profile, e.g. modifying his username, password, address and payment method. It’s a stream. And all of his information is in a database table. This JOIN just use the stream events to modify table values.\nTable-table JOIN (materialized view maintenance)Just like JOIN in database, the goal is to get up-to-date materialized view after stream events modifying the database tables.\nFault ToleranceIf a task in batch processing fails, it can simply be started again on another machine, and the output of the failed task is discarded.\nIt’s harder in stream processing because the task is endless.\nMicrobatching and checkpointingMicrobatchingBreak the stream into small blocks, and treat each block like a miniature batch process. This is used in Spark Streaming. The batch size is typically around one second, which is the result of a performance compromise: smaller batches incur greater scheduling and coordination overhead, while larger batches mean a longer delay before results of the stream processor become visible.\nMicrobatching also implicitly provides a tumbling window equal to the batch size (windowed by processing time, not event timestamps); any jobs that require larger windows need to explicitly carry over state from one microbatch to the next.\nCheckpointIn Apache Flink, is to periodically generate rolling checkpoints of state and write them to durable storage. If a stream operator crashes, it can restart from its most recent checkpoint and discard any output generated between the last checkpoint and the crash. The checkpoints are triggered by barriers in the message stream, similar to the boundaries between microbatches, but without forcing a particular window size.\nDisadvantageWithin the confines of the stream processing framework, the microbatching and checkpointing approaches provide the same exactly-once semantics as batch processing. However, as soon as output leaves the stream processor (for example, by writing to a database, sending messages to an external message broker, or sending emails), the framework is no longer able to discard the output of a failed batch. In this case, restarting a failed task causes the external side effect to happen twice, and microbatching or checkpointing alone is not sufficient to prevent this problem.\nAtomic commit revisitedIn order to give the appearance of exactly-once processing in the presence of faults, we need to ensure that all outputs and side effects of processing an event take effect if and only if the processing is successful.\nThose things either all need to happen atomically, or none of them must happen, but they should not go out of sync with each other. These implementations do not attempt to provide transactions across heterogeneous technologies, but instead keep the transactions internal by managing both state changes and messaging within the stream processing framework. The overhead of the transaction protocol can be amortized by processing several input messages within a single transaction.\nIdempotence (依赖幂等性)An idempotent operation is one that you can perform multiple times, and it has the same effect as if you performed it only once.\n\nFor example, SET X = 1 is idempotent, while X++ is not.\n\nEven if an operation is not naturally idempotent, it can often be made idempotent with a bit of extra metadata.\n\nFor example, when consuming messages from Kafka, every message has a persistent, monotonically increasing offset. When writing a value to an external database, you can include the offset of the message that triggered the last write with the value. Thus, you can tell whether an update has already been applied, and avoid performing the same update again.\n\nRebuilding state after a failureAny stream process that requires state—for example, any windowed aggregations (such as counters, averages, and histograms) and any tables and indexes used for joins—must ensure that this state can be recovered after a failure.\n\nKeep the state in a remote datastore and replicate it, although having to query a remote database for each individual message can be slow.\n\nKeep state local to the stream processor, and replicate it periodically. Then, when the stream processor is recovering from a failure, the new task can read the replicated state and resume processing without data loss.\n\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (9)Linearizability","url":"/2023/11/03/DDIA-cookbook-9-Linearizability/","content":"CAP Theorem\nConsistency &rarr; Every read receives the most recent write or an error\nAvailability &rarr; Every request receives a (non-error) response, without the guarantee that it contains the most recent write\nPartition tolerance &rarr; The system continues to operate despite an arbitrary number of messages being dropped (or delayed) by the network between nodes\n\nConsistency GuaranteesMost replicated databases provide at least eventual consistency, which means that if you stop writing to the database and wait for some unspecified length of time, then eventually all read requests will return the same value. The inconsistency is temporary. It’s also called convergence. However, this is a very weak guarantee—it doesn’t say anything about when the replicas will converge. Until the time of convergence, reads could return anything or nothing.\nFor stranger guarantees, they are easy to understand and implement. But they may have worse performance or be less fault-tolerant than systems with weaker guarantees.\n\nDistributed consistency is pretty similar to transaction isolation. But there are some difference: transaction isolation is primarily about avoiding race conditions due to concurrently executing transactions, whereas distributed consistency is mostly about coordinating the state of replicas in the face of delays and faults.\n\n\nLinearizabilityLinearizability (aka atomic consistency, strong consistency, immediate consistency, or external consistency) &rarr; make a system appear as if there were only one copy of the data, and all operations on it are atomic.\nIn a linearizable system, as soon as one client successfully completes a write, all clients reading from the database must be able to see the value just written. Maintaining the illusion of a single copy of the data means guaranteeing that the value read is the most recent, up-to-date value, and doesn’t come from a stale cache or replica.\nWhat makes a system linearizable?In a linearizable system, once a new value has been written or read, all subsequent reads see the value that was written, until it is overwritten again.\n\nIn this example, we imagine that there must be some point in time (between the start and end of the write operation) at which the value of x atomically flips from 0 to 1. Thus, if one client’s read returns the new value 1, all subsequent reads must also return the new value, even if the write operation has not yet completed. Client A is the first to read the new value, 1. Just after A’s read returns, B begins a new read. Since B’s read occurs strictly after A’s read, it must also return 1, even though the write by C is still ongoing.\nA more precise definition for linearizability is: it is possible (though computationally expensive) to test whether a system’s behavior is linearizable by recording the timings of all requests and responses, and checking whether they can be arranged into a valid sequential order.\n\nLinearizability Vs Serializability\n\nSerializability &rarr; an isolation property of transaction, where every transaction may read and write multiple objects (rows, documents, records). It guarantees that transactions behave the same as if they had executed in some serial order. It is okay for that serial order to be different from the order in which transactions were actually run.\nLinearizability &rarr; a recency guarantee on reads and writes of a register (an individual object). It doesn’t group operations together into transactions, so it does not prevent problems such as write skew.\n\n\nA database that provides both serialiability and linearizability is called strict serializability.\nImplementations of serializability based on 2PL or actual serial execution are typically linearizable.\n\nObviously the serializable snapshot isolation is not linearizable, because it uses snapshot which doesn’t include writes in other transactions that are more recent than the premise.\n\nRelying on linarizabilityWhen is the linearizability useful?\n\nLocking and leader election\nConstraints and uniqueness guarantees &rarr; generating auto-incremental primary key\nCross-channel timing dependencies\nThis is one example for cross-channel. Ideally, after the full-size image being stored in the storage system, we run the message queue task. However, if the storage process is slow, then we may run message queue task first, which tries to resize “existing” full-size image.\n\n\n\nImplementationThe most common approach to making a system fault-tolerant is to use replication.\n\n\n    Single-leader replication (potentially linearizable)\n\n\n    Using the leader for reads relies on the assumption that you know for sure who the leader is. It is quite possible for a node to think that it is the leader, when in fact it is not—and if the delusional leader continues to serve requests, it is likely to violate linearizability. With asynchronous replication, failover may even lose committed writes, which violates both durability and linearizability.\n\n\n\n\n\nMulti-leader replication (not linearizable)\n\n\n    Systems with multi-leader replication are generally not linearizable, because they concurrently process writes on multiple nodes and asynchronously replicate them to other nodes. For this reason, they can produce conflicting writes that require resolution. Such conflicts are an artifact of the lack of a single copy of the data.\n\n\n\n\n\n    Leaderless replication (probably not linearizable)\n\n\n    For systems with leaderless replication, people sometimes claim that you can obtain \"strong consistency\" by requiring quorum reads and writes (w + r > n).\n\n\n    \"Last write wins\" conflict resolution methods based on time-of-day clocks are almost certainly nonlinearizable, because clock timestamps cannot be guaranteed to be consistent with actual event ordering due to clock skew. Sloppy quorums also ruin any chance of linearizability. Even with strict quorums, nonlinearizable behavior is possible.\n\n\n    Why quorums cannot provide linearizability?\n\n\n\n    According to the figure, n = 3, w = 3, r = 2, which meet the quorum requirement. However, this execution is nevertheless not linearizable: B’s request begins after A’s request completes, but B returns the old value.\n\n\n\n\n\n    Consensus algorithms (linearizable)\n\n\n    Some consensus algorithms bear a resemblance to single-leader replication. However, consensus protocols contain measures to prevent split brain and stale replicas. Thanks to these details, consensus algorithms can implement linearizable storage safely.\n\n\n\nCost of linearizability\nA network interruption forcing a choice between linearizability and availability.\n\nImagine that we use single-leader replication, and the network partition split leader with some followers.Because all writes happens in leader, so if we continue to serve client, then some clients that connect to isolated followers will get out-of-date value, which violate the linearizability.On the other hand, if we choose to let the reads wait until the network restart working, then we lose availability.\n\n“Either Consistent or Available when Partitioned”CAP is sometimes presented as Consistency, Availability, Partition tolerance: pick 2 out of 3. Actually, it’s wrong!\nAt times when the network is working correctly, a system can provide both consistency (linearizability) and total availability. When a network fault occurs, you have to choose between either linearizability or total availability.\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (7)Transactions","url":"/2023/09/17/DDIA-cookbook-7-Transactions/","content":"Concept of TransactionA transaction is a way for an application to group several reads and writes together into a logical unit. Conceptually, all the reads and writes in a transaction are executed as one operation: either the entire transaction succeeds (commit) or it fails (abort, rollback).\nNot every application needs transactions, and sometimes there are advantages to weakening transactional guarantees or abandoning them entirely (for example, to achieve higher performance or higher availability).\nACIDAtomicityFor a group of operations, if no fault occurs, then execute all operations and change the state (commit); otherwise, no operation will be executed, keep original state (abort).\n\nDifferent with atomic in multi-threaded.\nIn multi-threaded programming, if one thread executes an atomic operation, that means there is no way that another thread could see the half-finished result of the operation. The system can only be in the state it was before the operation or after the operation, not something in between.\nFor ACID, it does not describe what happens if several processes try to access the same data at the same time.\n\nConsistencyThe idea of ACID consistency is that you have certain statements about your data (invariants) that must always be true, if a transaction starts with a database that is valid according to these invariants, and any writes during the transaction preserve the validity, then you can be sure that the invariants are always satisfied.\n\nThis idea of consistency depends on the application’s notion of invariants, and it’s the application’s responsibility to define its transactions correctly so that they preserve consistency. This is not something that the database can guarantee.\n\n\nThis consistency is not the same as consistency in distributed systems (called CAP). ACID consistency is a user-defined rule, while CAP consistency is “request to any nodes will get the same response”.\n\nIsolationAny read or write in the same transaction will not be affected by other transactions.\nFor details, please refer to “Concurrent Operations &amp; Isolation Levels” section.\nPossible Problems\n\nDirty Read &rarr; A Dirty read is a situation when a transaction reads data that has not yet been committed.\nNon Repeatable read &rarr; Non Repeatable read occurs when a transaction reads the same row twice and gets a different value each time.\nPhantom Read &rarr; Phantom Read occurs when two same queries are executed, but the rows retrieved by the two, are different.\n\n\nDifference between non repeatable and phantom is: non repeatable focus on certain row, and the returned value of that row; phantom focus on same query and the returned set.\n\nIsolation levelsLevels from loose to strict:\n\nRead Uncommitted (no isolation) &rarr; In this level, one transaction may read not yet committed changes made by other transactions, thereby allowing dirty reads.\nRead Committed &rarr; This isolation level guarantees that any data read is committed at the moment it is read. Thus it does not allow dirty read. The transaction holds a read or write lock on the current row, and thus prevents other transactions from reading, updating, or deleting it.\nRepeatable Read &rarr; The transaction holds read locks on all rows it references and writes locks on referenced rows for update and delete actions. Since other transactions cannot read, update or delete these rows, consequently it avoids non-repeatable read.\nSerializable (purely like ordered transactions) &rarr; A serializable execution is guaranteed to be serializable. Serializable execution is defined to be an execution of operations in which concurrently executing transactions appears to be serially executing.\n\nDurabilityDurability is the promise that once a transaction has committed successfully, any data it has written will not be forgotten, even if there is a hardware fault or the database crashes.\n\nsingle-node &rarr; write data into disk or WAL for recovery.\nmulti-nodes &rarr; data has been successfully copied to some number of nodes.\n\nBASESystems that do not meet the ACID criteria are sometimes called BASE, which stands for Basically Available, Soft state, and Eventual consistency.\nSingle-Object &amp; Multi-Object Operationssingle-object writesSingle object modification means multiple threads may access the same value (row, table, etc). Atomicity can be implemented using a log for crash recovery and isolation can be implemented using a lock on each object.\n\nAtomicity for single object may be hard to understand because only one operation happens, you can imagine it like “write a very large data chunk into disk”, there are two outcomes: (1) all data in disk; (2) no data in disk.\n\nSome databases also provide more complex atomic operations, such as an increment operation, which removes the need for a read-modify-write cycle. Similarly popular is a compare-and-set operation, which allows a write to happen only if the value has not been concurrently changed by someone else. We will cover this later.\nThese single-object operations are useful, as they can prevent lost updates when several clients try to write to the same object concurrently. However, they are not transactions in the usual sense of the word, because transaction means we operate more than one objects.\nmulti-object transactionsSome distributed databases abandon multi-object transactions because it’s difficult to implement across partitions and may influent performance and availability.\nBut there are some situations that still require multi-object transactions, for example:\n\nforeign key constrain\nsecondary index\n\nHandling errors and abortsACID databases are based on this philosophy: if the database is in danger of violating its guarantee of atomicity, isolation, or durability, it would rather abandon the transaction entirely than allow it to remain half-finished.\nNot all systems follow that philosophy, though. In particular, datastores with leaderless replication work much more on a “best effort” basis, which could be summarized as “the database will do as much as it can, and if it runs into an error, it won’t undo something it has already done”—so it’s the application’s responsibility to recover from errors.\nRetrying an aborted transaction is a simple and effective error handling mechanism, it isn’t perfect:\n\nIf the transaction success but the network fails to response to client, then retry may execute same transaction twice.\nIf the error is due to overload, then retry will make the problem worse.\nIt’s only worth retrying after transient errors, like deadlock, temporary network break, etc. For permanent error such as constraint violation, retrying is meaningless.\nIf the transaction has side effect, then even transaction failed, the side effect may affect other part already.\nIf the client fails while retrying, then everything is lost.\n\n\nWeak Isolation LevelsRead CommittedDirty ReadNo dirty read &rarr; When reading from the database, you will only see data that has been committed.\nWhy need to avoid dirty read?\n\nIf a transaction needs to update several objects, a dirty read means that another transaction may see some of the updates but not others.\nFor example, the user sees the new unread email but not the updated counter. This is a dirty read of the email. Seeing the database in a partially updated state is confusing to users and may cause other transactions to take incorrect decisions.\n\n\nIf a transaction aborts, any writes it has made need to be rolled back. If the database allows dirty reads, that means a transaction may see data that is later rolled back.\n\nDirty WriteNo dirty write &rarr; When writing to the database, you will only overwrite data that has been committed.\nWe normally assume that the later write overwrites the earlier write. However, what happens if the earlier write is part of a transaction that has not yet committed, so the later write overwrites an uncommitted value? This is called a dirty write.\nImplement Read CommittedMost commonly, databases prevent dirty writes by using row-level locks: when a transaction wants to modify a particular object (row or document), it must first acquire a lock on that object. It must then hold that lock until the transaction is committed or aborted. Only one transaction can hold the lock for any given object; if another transaction wants to write to the same object, it must wait until the first transaction is committed or aborted before it can acquire the lock and continue.\nWhat about preventing dirty reads?\n\nOne option is use the same read lock, but it’s not a good idea, because one long-running write transaction can force many read-only transactions to wait until the long-running transaction has completed. This harms the response time of read-only transactions and is bad for operability.\nAnother option is keeping both committed and uncommitted values.  For every object that is written, the database remembers both the old committed value and the new value set by the transaction that currently holds the write lock. While the transaction is ongoing, any other transactions that read the object are simply given the old value. Only when the new value is committed do transactions switch over to reading the new value.\n\nSnapshot Isolation and Repeatable Read\nThis is called non repeatable read.\nSnapshot isolation is the most common solution to this problem. The idea is that each transaction reads from a consistent snapshot of the database—that is, the transaction sees all the data that was committed in the database at the start of the transaction. Even if the data is subsequently changed by another transaction, each transaction sees only the old data from that particular point in time.\nImplement Snapshot Isolation (MVCC)Like read committed isolation, implementations of snapshot isolation typically use write locks to prevent dirty writes.\nHowever, reads do not require any locks. From a performance point of view, a key principle of snapshot isolation is readers never block writers, and writers never block readers. This allows a database to handle long-running read queries on a consistent snapshot at the same time as processing writes normally, without any lock contention between the two.\nThe database must potentially keep several different committed versions of an object, because various in-progress transactions may need to see the state of the database at different points in time. Because it maintains several versions of an object side by side, this technique is known as multiversion concurrency control (MVCC).\n\nEach row in a table has a created_by field, containing the ID of the transaction that inserted this row into the table.\nMoreover, each row has a deleted_by field, which is initially empty. If a transaction deletes a row, the row isn’t actually deleted from the database, but it is marked for deletion by setting the deleted_by field to the ID of the transaction that requested the deletion. At some later time, when it is certain that no transaction can any longer access the deleted data, a garbage collection process in the database removes any rows marked for deletion and frees their space.\nAn update is internally translated into a delete and a create.\nVisibility rulesWhen a transaction reads from the database, transaction IDs are used to decide which objects it can see and which are invisible.\n\nAt the start of each transaction, the database makes a list of all the other transactions that are in progress (not yet committed or aborted) at that time. Any writes that those transactions have made are ignored, even if the transactions subsequently commit.\nAny writes made by aborted transactions are ignored.\nAny writes made by transactions with a later transaction ID (i.e., which started after the current transaction started) are ignored, regardless of whether those transactions have committed.\nAll other writes are visible to the application’s queries.\n\nIn other words, an object is visible if both of the following conditions are true:\n\nAt the time when the reader’s transaction started, the transaction that created the object had already committed.\nThe object is not marked for deletion, or if it is, the transaction that requested deletion had not yet committed at the time when the reader’s transaction started.\n\nIndexes\nThe index simply point to all versions of an object and require an index query to filter out any object versions that are not visible to the current transaction. When garbage collection removes old object versions that are no longer visible to any transaction, the corresponding index entries can also be removed.\nUse an append-only&#x2F;copy-on-write variant that does not overwrite pages of the tree when they are updated, but instead creates a new copy of each modified page. Parent pages, up to the root of the tree, are copied and updated to point to the new versions of their child pages.\n\nPreventing Lost UpdatesThere are several interesting kinds of conflicts that can occur between concurrently writing transactions. The best known of these is the lost update problem.\n\nThe lost update problem can occur if an application reads some value from the database, modifies it, and writes back the modified value (a read-modify-write cycle). If two transactions do this concurrently, one of the modifications can be lost, because the second write does not include the first modification.\nAtomic write operaitonsMany databases provide atomic update operations, which remove the need to implement read-modify-write cycles in application code.\n\nThis means a new operation always happens after the old operation finishing.\n\nAtomic operations are usually implemented by taking an exclusive lock on the object when it is read so that no other transaction can read it until the update has been applied. Another option is to simply force all atomic operations to be executed on a single thread.\nUnfortunately, object-relational mapping frameworks make it easy to accidentally write code that performs unsafe read-modify-write cycles instead of using atomic operations provided by the database.\n\nAlthough DB provide threading-safe SQL commands, user may use the DB in a wrong way and violate the atomicity :(.\n# threading-safeMyDB.execute(&quot;UPDATE counters SET value = value + 1 WHERE key = &#x27;foo&#x27;;&quot;)# violate atomicityvalue = MyDB.execute(&quot;SELECT value FROM counters WHERE key = &#x27;foo&#x27;;&quot;)new_value = value + 1MyDB.execute(&quot;UPDATE counters SET value = new_value WHERE key = &#x27;foo&#x27;;&quot;)\n\nExplicit lockingAdd lock in your own code.\nwith resource.get_lock() as re:    do_something()\n\nAutomatically detecting lost updatesAllow to run operations in parallel, if the transaction manager detects a lost update, abort the transaction and force it to retry its read-modify-write cycle.\nCompare and SetCompare-and-set operation is to avoid lost updates by allowing an update to happen only if the value has not changed since you last read it. If the current value does not match what you previously read, abort the update, and the read-modify-write cycle must be retried.\nConflict resolution and replicationLocks and compare-and-set operations assume that there is a single up-to-date copy of the data. However, databases with multi-leader or leaderless replication usually allow several writes to happen concurrently and replicate them asynchronously, so they cannot guarantee that there is a single up-to-date copy of the data. Thus, techniques based on locks or compare-and-set do not apply in this context.\nSolution &rarr; allow concurrent writes to create several conflicting versions of a value (also known as siblings), and to use application code or special data structures to resolve and merge these versions after the fact.\nWrite Skew and PhantomsWrite SkewIt is neither a dirty write nor a lost update, because the two transactions are updating two different objects.\nYou can think of write skew as a generalization of the lost update problem. Write skew can occur if two transactions read the same objects, and then update some of those objects (different transactions may update different objects). In the special case where different transactions update the same object, you get a dirty write or lost update anomaly.\nPhantomsA write in one transaction changes the result of a search query in another transaction, is called a phantom. Snapshot isolation avoids phantoms in read-only queries, but in read-write transactions, phantoms can lead to particularly tricky cases of write skew.\nThe general steps that cause phantoms are:\n\nA SELECT query checks whether some requirement is satisfied by searching for rows that match some search condition.\nDepending on the result of the first query, the application code decides how to continue\nIf the application decides to go ahead, it makes a write (INSERT, UPDATE, or DELETE) to the database and commits the transaction\n\nMaterializing conflictsMaterializing conflicts &rarr; takes a phantom and turns it into a lock conflict on a concrete set of rows that exist in the database.\nIt can be hard and error-prone to figure out how to materialize conflicts, and it’s ugly to let a concurrency control mechanism leak into the application data model.\n\nSerializabilitySerializable isolation is usually regarded as the strongest isolation level. It guarantees that even though transactions may execute in parallel, the end result is the same as if they had executed one at a time, serially, without any concurrency.\nMost databases that provide serializability today use one of three techniques:\n\nactual serial execution\ntwo-phase locking\nconcurrency control\n\nActual Serial ExecutionThe simplest way of avoiding concurrency problems is to remove the concurrency entirely: to execute only one transaction at a time, in serial order, on a single thread.\n\nIt seems very straight forward, why this appears only recently?\n\nRAM became cheap enough that for many use cases is now feasible to keep the entire active dataset in memory.\nOLTP transactions are usually short and only make a small number of reads and writes. For long-running analytics quries, they are typically read-heavy and can use snapshot.\n\n\nA system designed for single-threaded execution can sometimes perform better than a system that supports concurrency, because it can avoid the coordination overhead of locking.\nHowever, its throughput is limited to that of a single CPU core. In order to make the most of that single thread, transactions need to be structured differently from their traditional form.\nEncapsulating transactions in stored proceduresIf a database transaction needs to wait for input from a user, the database needs to support a potentially huge number of concurrent transactions, most of them idle. Most databases cannot do that efficiently, and so almost all OLTP applications keep transactions short by avoiding interactively waiting for a user within a transaction.\nIn this interactive style of transaction, a lot of time is spent in network communication between the application and the database. If you were to disallow concurrency in the database and only process one transaction at a time, the throughput would be dreadful because the database would spend most of its time waiting for the application to issue the next query for the current transaction.\n\nSystems with single-threaded serial transaction processing don’t allow interactive multi-statement transactions. Instead, the application must submit the entire transaction code to the database ahead of time, as a stored procedure.\n\nNormal process is running multiple queries one by one, which looks like execute multiple commands in console;Stored procedure is packing multiple queries together and send this batch via network, which looks like running script.\n\nPros and cons of stored proceduresSome cons:\n\nEach database vendor has its own language for stored procedures\nHard to debug, monitor, test, version control, etc\nA badly written stored procedures in the database may cause much more trouble than bad code in applications, because one database may be used by several applications\n\nSome pros:\n\nWith stored procedures and in-memory data, executing all transactions on a single thread becomes feasible. As they don’t need to wait for I&#x2F;O and they avoid the overhead of other concurrency control mechanisms, they can achieve quite good throughput on a single thread.\nSome database use stored procedures for replication: instead of copying a transaction’s writes from one node to another, they execute the same stored procedure on each replica. (no need to transfer data, just transfer the script or “how to get these data”)\n\nPartitioningExecuting all transactions serially makes concurrency control much simpler, but limits the transaction throughput of the database to the speed of a single CPU core on a single machine. Read-only transactions may execute elsewhere, using snapshot isolation, but for applications with high write throughput, the single-threaded transaction processor can become a serious bottleneck.\nIn order to scale to multiple CPU cores, and multiple nodes, you can potentially partition your data.\n\nIf you can find a way of partitioning your dataset so that each transaction only needs to read and write data within a single partition, then each partition can have its own transaction processing thread running independently from the others. In this case, you can give each CPU core its own partition, which allows your transaction throughput to scale linearly with the number of CPU cores.\nHowever, for any transaction that needs to access multiple partitions, the database must coordinate the transaction across all the partitions that it touches. The stored procedure needs to be performed in lock-step across all partitions to ensure serializability across the whole system.\n\nSummarySerial execution of transactions has become a viable way of achieving serializable isolation within certain constraints:\n\nEvery transaction must be small and fast, because we only have one tread, low-speed transaction will block following tasks.\nIt is limited to use cases where the active dataset can fit in memory so that no need to wait to load data from disk.\nWrite throughput must be low enough to be handled on a single CPU core.\nRare cross-partition transations.\n\nTwo-Phase Locking (2PL)NOTE: TWO-PHASE LOCKING IS DIFFERENT WITH TWO-PHASE COMMIT!!!\nSeveral transactions are allowed to concurrently read the same object as long as nobody is writing to it. But as soon as anyone wants to write (modify or delete) an object, exclusive access is required:\n\nIf transaction A has read an object and transaction B wants to write to that object, B must wait until A commits or aborts before it can continue.\nIf transaction A has written an object and transaction B wants to read that object, B must wait until A commits or aborts before it can continue.\n\nImplementationThere are 2 lock types: shared lock (read lock) and exclusive lock (write lock).\n\nReaders &rarr; acquire and hold shared lock, multiple readers can share the lock on the same object. If the object already has an exclusive lock, then readers need to wait.\nWriter &rarr; acquires and holds exclusive lock. One object can only has one exclusive lock, so if there is any existing lock on the object, the transaction must wait.\nLock Upgrade &rarr; If a transaction first reads and then writes an object, it may upgrade its shared lock to an exclusive lock.\nAfter a transaction has acquired the lock, it must continue to hold the lock until the end of the transaction (commit or abort).\n\n\nOne of the problem of 2PL is deadlock. The most common solution is detecting the deadlocks between transactions then aborting one of them to break the tie.\n\nPerformanceWhy 2PL is not a ultimate solution? The transaction throughput and response times of queries are significantly worse under two-phase locking than under weak isolation.\n\nThe overhead of acquiring and releasing all those locks.\nReduce the concurrency. Some transactions need to wait other to finish first.\nDeadlock. If we choose to abort some transations, the redo processes are costy.\n\nLocksThere are several choices for locks, they have different granularities.\nRow-based locksThis lock will lock the certain rows. It has the finest granularity, but the performance is not good, because there may exist lots of locks.\nCondition-based locks (Predicate locks)It works similarly to the shared&#x2F;exclusive lock described earlier, but rather than belonging to a particular object (e.g., one row in a table), it belongs to all objects that match some search condition.\nThe key idea here is that a predicate lock applies even to objects that do not yet exist in the database, but which might be added in the future (phantoms). If two-phase locking includes predicate locks, the database prevents all forms of write skew and other race conditions, and so its isolation becomes serializable.\nThe problem of predicate locks is its performance: if there are many locks by active transactions, checking for matching locks becomes time-consuming.\nIndex-based locksFor example, if you have a predicate lock for bookings of room 123 between noon and 1 p.m., you can approximate it by locking bookings for room 123 at any time, or you can approximate it by locking all rooms (not just room 123) between noon and 1 p.m.\n\nImagine it has index for time and for room, so the index-range lock will lock the whole index (time or room).\n\nIt’s not very precise, but since it has much lower overheads, it’s a good compromise.\nConcurrency ControlThere are two types of Concurrency Control policy:\n\nPessimistic &rarr; if anything might possibly go wrong, it’s better to wait until the situation is safe again before doing anything.\nOptimistic &rarr; instead of blocking if something potentially dangerous happens, transactions continue anyway, in the hope that everything will turn out all right. When a transaction wants to commit, the database checks whether anything bad happened.\n\nSerializable Snapshot Isolation (SSI) is one of the most famous optimistic algorithm. It based on snapshot, every transaction runs in its own snapshot, then before committing, checking the conflicts.\n\nWhy wait until committing? Why not abort transaction immediately when the conflict is detected?Because if other transaction aborted, then no conflict exist, or current transaction is read-only.\n\nWe call the snapshot in the start of transaction as premise. Because a typical transaction is read-modify-write, and we use snapshot to isolate changes in other transactions, so the premise maybe out-of-date when we commit this transaction (for example, other transaction modified some values and committed before this transaction).\nAny changes to the results of the read or query may invalidate the writes in the transaction. That is, the database must know that the writes in this transaction are based on an outdated premise, and then abort the transaction.\nHow does the database know whether the query results may have changed? There are two situations to consider.\n\nWhen the transaction wants to commit, the database checks whether any of the ignored writes have now been committed. If so, the transaction must be aborted, because this transaction based on an outdated (changed) premise.\nIn this example, Tx 42 modified the “Alice” but not yet commit, so in the view of Tx 43, this modification is ignored, it still treat “Alice” &#x3D; true. Then Tx 43 makes its changes in “Bob”. After Tx 42 is committed, the premise for Tx 42 is outdated (“Alice” from true to false), so any writes in Tx 43 are invalid (because any writes in Tx 43 are based on its premise, the premise has changed, so the writes maybe invalid).\n\nIn this example, the premises for Tx 42 and Tx 43 are the same. After Tx 42 modified “Alice”, Tx 43 also wants to modify “Bob”. Because no Tx is committed, so Tx 42 and 43 are modifying different premises (snapshots), no conflict. When Tx 42 commits, the premise doesn’t change, so it is approved. When Tx 43 commits, the premise is outdated (“Alice” from true to false), so it is rejected.\nPerformanceCompared to 2PL, the big advantage of SSI is that one transaction doesn’t need to block waiting for locks held by another transaction. Like under snapshot isolation, writers don’t block readers, and vice versa. This design principle makes query latency much more predictable and less variable. In particular, read-only queries can run on a consistent snapshot without requiring any locks, which is very appealing for read-heavy workloads.\nCompared to serial execution, SSI is not limited to the throughput of a single CPU core. Even though data may be partitioned across multiple machines, transactions can read and write data in multiple partitions while ensuring serializable isolation.\nThe rate of aborts significantly affects the overall performance of SSI. For example, a transaction that reads and writes data over a long period of time is likely to run into conflicts and abort, so SSI requires that read-write transactions be fairly short (long-running read-only transactions may be okay).\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (9)Ordering","url":"/2023/11/03/DDIA-cookbook-9-Ordering/","content":"Ordering and CausalityCausality imposes an ordering on events: cause comes before effect; a message is sent before that message is received; the question comes before the answer. And, like in real life, one thing leads to another: one node reads some data and then writes something as a result, another node reads the thing that was written and writes something else in turn, and so on.\nCausal order &ne; Total orderTotal order &rarr; ordering by time, every pair of events can be placed in some order.\nCausal ordering is only a partial order - sometimes events happen with order, sometimes are concurrently.\n\nIn a linearizable system, we have a total order of operations: if the system behaves as if there is only a single copy of the data, and every operation is atomic, this means that for any two operations we can always say which one happened first. It’s just like there is a single timeline along which all operations are totally ordered.\n\nIt maybe very hard to understand the difference. Let’s use twitter as an example. If you post a twitte, then A, B and C comment your post.\n\nCausal order (some events have causality restriction &#x2F; time order, but some may be concurrent, which leads to unkonwn time order)\nABC need to see your post first, then comment, so “your post” is the cause, and “comments from A, B and C” is the effect (can be either concurrent or sequential).\nCausal order only guarantees “post&rarr;A comment”, “post&rarr;B comment” and “post&rarr;C comment”.\nThat means in A’s phone, maybe the comments order is ABC, but in B’s phone, the comments order is BCA.\n\n\nTotal order (in any nodes&#x2F;views, events have the same time order, no need to have causality)\nIt only guarantees that in ABC’s phones, all events have the same order, even they aren’t reasonable.\nFor example, the events are “A comment&rarr;C comment&rarr;post&rarr;B comment”.\n\n\n\nCausal ordering doesn’t imply total ordering, and total ordering doesn’t imply causal ordering as well.\n\nLinearizability is stronger than causal consistencyLinearizability implies causality.\nLinearizability is not the only way of preserving causality. A system can be causally consistent without incurring the performance hit of making it linearizable. In fact, causal consistency is the strongest possible consistency model that does not slow down due to network delays, and remains available in the face of network failures.\n\nIn order to maintain causality, you need to know which operation happened before which other operation. This is a partial order: concurrent operations may be processed in any order, but if one operation happened before another, then they must be processed in that order on every replica. Thus, when a replica processes an operation, it must ensure that all causally preceding operations (all operations that happened before) have already been processed.\n\n\nSequence Number OrderingAlthough causality is an important theoretical concept, actually keeping track of all causal dependencies can become impracticable. In many applications, clients read lots of data before writing something, and then it is not clear whether the write is causally dependent on all or only some of those prior reads. Explicitly tracking all the data that has been read would mean a large overhead.\nWe can use sequence numbers or logic timestamps to order events. These sequence numbers also provide total order: because every event has its own sequence number, so we can compare any two of them.\nLamport timestamps\nEach node has a unique identifier, and each node keeps a counter of the number of operations it has processed. The Lamport timestamp is then simply a pair of (counter, node ID). Two nodes may sometimes have the same counter value, but by including the node ID in the timestamp, each timestamp is made unique.\nA Lamport timestamp bears no relationship to a physical time-of-day clock, but it provides total ordering: if you have two timestamps, the one with a greater counter value is the greater timestamp; if the counter values are the same, the one with the greater node ID is the greater timestamp.\nLamport timestamps vs Version vectorAlthough there are some similarities, they have a different purpose:\n\nVersion vectors can distinguish whether two operations are concurrent or whether one is causally dependent on the other\nLamport timestamps always enforce a total ordering\n\nFrom the total ordering of Lamport timestamps, you cannot tell whether two operations are concurrent or whether they are causally dependent. The advantage of Lamport timestamps over version vectors is that they are more compact.\nTimestamp ordering is not sufficientThe problem here is that the total order of operations only emerges after you have collected all of the operations. If another node has generated some operations, but you don’t yet know what they are, you cannot construct the final ordering of operations: the unknown operations from the other node may need to be inserted at various positions in the total order.\nIn order to implement something meet uniqueness constraint, it’s not sufficient to have a total ordering of operations—you also need to know when that order is finalized. This idea of knowing when your total order is finalized is captured in the topic of total order broadcast.\n\nTotal Order BroadcastTotal order broadcast is usually described as a protocol for exchanging messages between nodes. Informally, it requires that two safety properties always be satisfied:\n\nReliable delivery &rarr; No messages are lost: if a message is delivered to one node, it is delivered to all nodes.\nTotally ordered delivery &rarr; Messages are delivered to every node in the same order.\n\n\nA correct algorithm for total order broadcast must ensure that the reliability and ordering properties are always satisfied, even if a node or the network is faulty. Of course, messages will not be delivered while the network is interrupted, but an algorithm can keep retrying so that the messages get through when the network is eventually repaired.\n\nUse caseTotal order broadcast is exactly what you need for database replication: if every message represents a write to the database, and every replica processes the same writes in the same order, then the replicas will remain consistent with each other.\nSimilarly, total order broadcast can be used to implement serializable transactions: if every message represents a deterministic transaction to be executed as a stored procedure, and if every node processes those messages in the same order, then the partitions and replicas of the database are kept consistent with each other.\nAn important aspect of total order broadcast is that the order is fixed at the time the messages are delivered, a node is not allowed to retroactively insert a message into an earlier position in the order if subsequent messages have already been delivered. This fact makes total order broadcast stronger than timestamp ordering.\nImplementing linearizable storage using total order broadcastImagine we have a system for register unique username. For every possible username, you can have a linearizable register with an atomic compare-and-set operation.\nYou can implement such a linearizable compare-and-set operation as follows by using total order broadcast as an append-only log:\n\nAppend a message to the log, tentatively indicating the username you want to claim.\nTotal order broadcast, and wait for the message you appended to be delivered back to you.\nCheck for any messages claiming the username that you want. If the first message for your desired username is your own message, then you are successful: you can commit the username claim (perhaps by appending another message to the log) and acknowledge it to the client. If the first message for your desired username is from another user, you abort the operation.\n\nBecause messages are delivered to all nodes in the same order (total order broadcast), if there are several concurrent writes, all nodes will agree on which one came first (who get the username).\n\nImagine A, B and C wants to use username “hello world”. No matter who sends the message first, because we use total order broadcast, so if the total order is B-&gt;A-&gt;C, then all nodes will have the same order, then B wins.\n\nImplementing total order broadcast using linearizable storageThe algorithm is simple: for every message you want to send through total order broadcast, you increment-and-get the linearizable integer, and then attach the value you got from the register as a sequence number to the message. You can then send the message to all nodes (resending any lost messages), and the recipients will deliver the messages consecutively by sequence number.\nNote that unlike Lamport timestamps, the numbers you get from incrementing the linearizable register form a sequence with no gaps. Thus, if a node has delivered message 4 and receives an incoming message with a sequence number of 6, it knows that it must wait for message 5 before it can deliver message 6. The same is not the case with Lamport timestamps—in fact, this is the key difference between total order broadcast and timestamp ordering.\n\nBecause the linearizable storage is no gap, so if I receive message 4 and message 6, which means message 5 also be used by someone else, but I havn’t receive it, I need to wait message 5 then deliver message 6.\n\n","tags":["System Design","DDIA"]},{"title":"Unittest in python - Mock","url":"/2023/07/27/Unittest-in-python-Mock/","content":"IntroMock is a very useful package for unittest in python. It can replace some classes or functions and change their behaviors, it can also use some built-in methods to help you assert whether pytest calls certain part of your code.\n\nMock() &amp; MagicMock()\nFor simplicity, let’s use Mock for example. In most cases, Mock and MagicMock are the same :)\n\nMock is a class that create all attributes and methods as you access them and store details of how they have been used.\nWhat’s more, you can set anything to a Mock, it will treat them as new Mock (sub Mock).\n# set an undefined method to a Mockm = Mock()              # &lt;Mock name=&quot;mock&quot;&gt;m.undefined_function()  # &lt;Mock name=&quot;mock.undefined_function()&quot;&gt;# use mock as a argumentclass Object:    def func(self, args):        args.do_something()o = Object()m = Mock()o.func(m)m.do_something()    # &lt;Mock name=&quot;mock.do_something()&quot;&gt;\n\nreturn_valueBy setting some methods or functions as Mock, then setting return_value can change original logic: I don’t care about what you write in the function, just return what I want!\nclass Object:    def __init__(self, x):        self.x = x        def func(self):        return self.xobj = Object(1)# method 1obj.func = Mock(return_value = 1024)# # method 2# obj.func = Mock()# obj.func.return_value = 1024obj.func()  # return 1024 rather than 1\n\nThis is always useful in unittest, like:\n\nI don’t want to send a real request via network, just let the requester &#x2F; dispatcher return what I want;\nI don’t want to access a real DB, just tell me what data you have;\n\nclass MySvc:    def __init__(self, db):        self.db = db        ...    def myRequest(self, req):        ...        results = self.db.fetch(req)        return resultsdef test_db(req):    db = MyDB()    db.fetch = Mock(return_value = [data1, data2, data3, ...])    svc = MySvc(db)    results = svc.myRequest(req)    # [data1, data2, data3, ...]\n\nSometimes, we will meet some call chains, such as mock.connection.cursor().execute(...).\n# mock.call1().call2().call3()m = Mock()# get Mock for all calls except the last onec1 = m.call1.return_valuec2 = c1.call2.return_value# set Mock for last one callc2.call3.return_value = &quot;foo&quot;m.call1().call2().call3()   # &quot;foo&quot;\n\n\nBasically, we can change the code as following\nm = Mock()c1 = Mock()m.call1.return_value = c1c2 = Mock()c1.call2.return_value = c2c2.call3.return_value = &quot;foo&quot;\n\nside_effectside_effect &#x3D; Exception&gt;&gt; m = Mock()&gt;&gt; m.exception_side_effect = Mock(side_effect = ValueError)&gt;&gt; m.exception_side_effect()ValueError\n\nside_effect &#x3D; iterableIf we set iterable to side_effect, every time we call it, it will yield one element.\n&gt;&gt; m = Mock()&gt;&gt; m.iter = Mock(side_effect = [1, 2, 3])&gt;&gt; m.iter()1&gt;&gt; m.iter()2&gt;&gt; m.iter()3\n\nside_effect &#x3D; callabledef log(*args, **kwargs):    print(f&quot;args: &#123;args&#125;, kwargs: &#123;kwargs&#125;&quot;)&gt;&gt; m = Mock()&gt;&gt; m.func = Mock(side_effect = log)&gt;&gt; m.func()args: (), kwargs: &#123;&#125;&gt;&gt; m.func(1, two = 2)args: (1,), kwargs: &#123;&quot;two&quot;: 2&#125;\n\nWhen we set both return_value and side_effect, the Mock will only use side_effect!!\nspec &amp; spec_setspec can be either a list of string or an existing class &#x2F; instance. After we set spec, the mock can only have corresponding attributes and methods (just like we use dir to see what attributes and methods does one class support).\nclass Object:    def __init__(self):        self.one = 1        self.two = 2    def func(self):        pass# when we use existing class as spec, the mock hasn&#x27;t initedm = Mock(spec = Object)m.func()    # &lt;Mock name=&quot;mock.func()&quot;&gt;m.one       # error, cuz we don&#x27;t init the Objectm.__init__()m.one       # 1m.three = 3 # ok# when we use existing instance as spec, the mock has initedo = Object()m = Mock(spec = o)m.func()    # &lt;Mock name=&quot;mock.func()&quot;&gt;m.one       # 1# when we use list of string as specm = Mock(spec = [&quot;one&quot;, &quot;func&quot;])m.func()    # &lt;Mock name=&quot;mock.func()&quot;&gt;m.one       # &lt;Mock name=&quot;mock.one&quot;&gt;m.one()     # &lt;Mock name=&quot;mock.one()&quot;&gt;\n\nThe difference between spec and spec_set is, spec can add new stuff while spec_set can only read.\nm = Mock(spec = [&quot;one&quot;])m.onem.two = 2   # okmm = Mock(spec_set = [&quot;one&quot;])m.onem.two = 2   # error\n\nassertion &amp; call argsMock supports lots of assertions, such as assert_called, assert_called_once, assert_called_with, etc.\nm = Mock()m(1, 2)m.assert_called()           # Truem.assert_called_with(1, 2)  # True\n\nMock can also remember what args you used via call_args or call_args_list.\nm = Mock()m(1, 2)m.call_args         # call(1, 2)m.call_args_list    # [call(1, 2)]m(3, 4)m.call_args         # call(3, 4)m.call_args_list    # [call(1, 2), call(3, 4)]\n\nWhat’s the difference between these two?So you can simply think MagicMock &#x3D; Mock with pre-defined magic methods.\n&gt;&gt; len(Mock())Error, Mock doesn&#x27;t have __len__ method&gt;&gt; len(MagicMock())0\n\nSo if you want to test or use magic methods in your test, use MagicMock.\nIf you want to modify the magic methods or just for simplicity purpose, plz use Mock.\n","tags":["python","test","pytest"]},{"title":"DDIA cookbook - (9)Distributed Transactions and Consensus","url":"/2023/11/03/DDIA-cookbook-9-Distributed-Transactions-and-Consensus/","content":"IntroConsensus &rarr; get several nodes to agree on something.\nSome situations:\n\nLeader Election &rarr; The leadership position might become contested if some nodes can’t communicate with others due to a network fault. In this case, consensus is important to avoid a bad failover, resulting in a split brain situation in which two nodes both believe themselves to be the leader\nAtomic Commit &rarr; In a database that supports transactions spanning several nodes or partitions, we have the problem that a transaction may fail on some nodes but succeed on others, we have to get all nodes to agree on the outcome of the transaction: either they all abort&#x2F;roll back or they all commit\n\nConsensus Vs Data ConsistencyThe two are very similar and can even be interchanged in many occasions, but we can also experience subtle differences:\n\nData Consistency &rarr; more like final outcomes and goals, is the desired state of the system, but does not define how this state is achieved\nConsensus &rarr; more like a general algorithm or method to reach this state of consensus (like voting), and sometimes it contains more than data\n\nFor example, consensus algorithm can be used in leader election, it doesn’t include any data, it’s just a concept; but data consistency always appears in replication, which focus on that the data is the same in different nodes.\nThe Impossibility of ConsensusFLP result &rarr; there is no algorithm that is always able to reach consensus if there is a risk that a node may crash.\nIt’s correct, but it has a prerequisite: in asynchronous system model, which cannot use any clocks or timeouts! If the algorithm is allowed to use timeouts, or some other way of identifying suspected crashed nodes (even if the suspicion is sometimes wrong), then consensus becomes solvable.\n\nNote: the sync or async here is not about data consistency, it’s a system model, which represents whether the system has time bounds.\n\n\nTwo-Phase Commit (2PC)In single machine, the atomicity is achieved by storage engine.\n\nWhen the client asks the database node to commit the transaction, the database makes the transaction’s writes durable (typically in a write-ahead log) and then appends a commit record to the log on disk. If the database crashes in the middle of this process, the transaction is recovered from the log when the node restarts: if the commit record was successfully written to disk before the crash, the transaction is considered committed; if not, any writes from that transaction are rolled back.\n\nFor distributed systems, if some nodes commit the transaction but others abort it, then inconsistency occurs, because committed transaction cannot be revert. So a node must only commit once it is certain that all other nodes in the transaction are also going to commit.\nTwo Phases\nInstead of a single commit request, as with a single-node transaction, the commit&#x2F;abort process in 2PC is split into two phases (hence the name).\n\nCoordinator &rarr; 2PC uses a new component that does not normally appear in single-node transactions: a coordinator or transaction manager. The coordinator is often implemented as a library within the same application process that is requesting the transaction, but it can also be a separate process or service.\nParticipant &rarr; A distributed transaction begins with the application reading and writing data on multiple database nodes, as normal. We call these database nodes participants in the transaction.\n\nWhen the application is ready to commit, the coordinator begins phase 1: it sends a prepare request to each of the nodes, asking them whether they are able to commit. In pahse 2: coordinator keep track of ack response and make decision.\n\nIf all participants reply “yes,” indicating they are ready to commit, then the coordinator sends out a commit request in phase 2, and the commit actually takes place.\nIf any of the participants replies “no,” the coordinator sends an abort request to all nodes in phase 2.\n\nDetails\nWhen the application wants to begin a distributed transaction, it requests a transaction ID from the coordinator. This transaction ID is globally unique.\nThe application begins a single-node transaction on each of the participants, and attaches the globally unique transaction ID to the single-node transaction. All reads and writes are done in one of these single-node transactions. If anything goes wrong at this stage (for example, a node crashes or a request times out), the coordinator or any of the participants can abort.\nWhen the application is ready to commit, the coordinator sends a prepare request to all participants, tagged with the global transaction ID. If any of these requests fails or times out, the coordinator sends an abort request for that transaction ID to all participants.\nWhen a participant receives the prepare request, it makes sure that it can definitely commit the transaction under all circumstances. This includes writing all transaction data to disk and checking for any conflicts or constraint violations. By replying “yes” to the coordinator, the node promises to commit the transaction without error if requested.\nWhen the coordinator has received ack responses to all prepare requests, it makes a definitive decision on whether to commit or abort the transaction. The coordinator must write that decision to its transaction log on disk so that it knows which way it decided in case it subsequently crashes. This is called the commit point.\nOnce the coordinator’s decision has been written to disk, the commit or abort request is sent to all participants. If this request fails or times out, the coordinator must retry forever until it succeeds. There is no more going back: if the decision was to commit, that decision must be enforced, no matter how many retries it takes. If a participant has crashed in the meantime, the transaction will be committed when it recovers—since the participant voted “yes”, it cannot refuse to commit when it recovers.\n\nThus, the protocol contains two crucial “points of no return”, which ensure the atomicity of 2PC:\n\nOnce a participant votes “yes,” it promises that it will definitely be able to commit later (although the coordinator may still choose to abort)\nOnce the coordinator decides, that decision is irrevocable.\n\nCoordinator FailureIf the coordinator fails before sending the prepare requests, a participant can safely abort the transaction via timeout or other mechanism.\nIf the participant has received a prepare request and voted “yes,” it can no longer abort unilaterally—it must wait to hear back from the coordinator whether the transaction was committed or aborted. If the coordinator crashes or the network fails at this point, the participant can do nothing but wait. A participant’s transaction in this state is called in doubt or uncertain. In principle, the participants could communicate among themselves to find out how each participant voted and come to some agreement, but that is not part of the 2PC protocol.\n\nThe participant cannot timeout to abort by themselves after they voting, because the coordinator may already made final decision, but current participant doesn’t receive the ack due to network for example, then abortion will cause inconsistency.\n\n2PL Vs 2PC2PL is used to achieve serializable isolation, whereas 2PC is used to achieve atomic commit.\nThey both have 2 phases:\n\n2PL &rarr; get lock &#x2F; upgrade lock - relase lock\n2PC &rarr; prepare - commit\n\nThree-Phase Commit (3PC)Two-phase commit is called a blocking atomic commit protocol due to the fact that 2PC can become stuck waiting for the coordinator to recover.\n3PC can achieve nonblocking commit, but:\n\nassumes a network with bounded delay and nodes with bounded response times\nrequires a perfect failure detector, like a reliable mechanism for telling whether a node has crashed or not\n\nThese are hard to achieve, so 3PC is not common.\n\nDistributed Transactions in PracticeXA transactionsBecause the coordinator and participants may use different applications (heterogeneous technologies), so how to make sure the messages are understandable by all of them is important.\nXA is short for eXtended Architecture, it’s a standard for implementing two-phase commit across heterogeneous technologies. XA is not a network protocol—it is merely a C API for interfacing with a transaction coordinator.\nWith the help of XA, the system can use generic APIs to achieve communication, e.g. what does prepare request look like, what does ack response look like, how to use same callback in different parts, etc.\nHolding locks while in doubtDatabase transactions usually take a row-level exclusive lock on any rows they modify, to prevent dirty writes. In addition, if you want serializable isolation, a database using 2PL would also have to take a shared lock on any rows read by the transaction.\nAnd if the participants are in doubt state, they cannot abort by themselves, so they will constantly hold the lock. While those locks are held, no other transaction can modify those rows. Depending on the database, other transactions may even be blocked from reading those rows. Thus, other transactions cannot simply continue with their business.\nRecovering from coordinator failureIn practice, orphaned in-doubt transactions do occur—that is, transactions for which the coordinator cannot decide the outcome for whatever reason (e.g., because the transaction log has been lost or corrupted due to a software bug). These transactions cannot be resolved automatically, so they sit forever in the database, holding locks and blocking other transactions.\n\nEven rebooting your database servers will not fix this problem, since a correct implementation of 2PC must preserve the locks of an in-doubt transaction even across restarts (otherwise it would risk violating the atomicity guarantee).\n\nThe only way out is for an administrator to manually decide whether to commit or roll back the transactions. Many XA implementations have an emergency escape hatch called heuristic decisions: allowing a participant to unilaterally decide to abort or commit an in-doubt transaction without a definitive decision from the coordinator.\n\nThe heuristic decisions may violate atomicity rule!\n\nLimitations\nIf the coordinator is not replicated but runs only on a single machine, it is a single point of failure for the entire system.\nMany server-side applications are developed in a stateless model. But the coordinator’s logs become a crucial part of the durable system state—as important as the databases themselves, since the coordinator logs are required in order to recover in-doubt transactions after a crash. Such application servers are no longer stateless.\nSince XA needs to be compatible with a wide range of data systems, it is necessarily a lowest common denominator (cannot well-designed for certain language or technology for example).\n\n\nFault-Tolerant ConsensusIn this formalism, a consensus algorithm must satisfy the following properties:\n\nUniform agreement &rarr; No two nodes decide differently.\nIntegrity &rarr; No node decides more than once.\nValidity &rarr; If a node decides value v, then v was proposed by some node.\nTermination &rarr; Every node that does not crash eventually decides some value.\n\nTermination is a liveness property, whereas the other three are safety properties.\n\n\nliveness &rarr; something good eventually happens\nsafety &rarr; nothing bad happens\n\n\nThe system model of consensus assumes that when a node “crashes,” it suddenly disappears and never comes back. In this system model, any algorithm that has to wait for a node to recover is not going to be able to satisfy the termination property (like alive nodes need to wait crashed coordinator or coordinator needs to wait crashed participants to ack).\nThus, the termination property is subject to the assumption that fewer than half of the nodes (quorum) are crashed or unreachable. However, most implementations of consensus ensure that the safety properties—agreement, integrity, and validity—are always met, even if a majority of nodes fail or there is a severe network problem. Thus, a large-scale outage can stop the system from being able to process requests, but it cannot corrupt the consensus system by causing it to make invalid decisions.\nConsensus algorithms and total order broadcastIn practice, one transaction or action may contains multiple values. We need to make sure the sequence of values are the same in all nodes.\nThe total order broadcast requires messages to be delivered exactly once, in the same order, to all nodes. This is equivalent to performing several rounds of consensus: in each round, nodes propose the message that they want to send next, and then decide on the next message to be delivered in the total order.\nSo in a high level perspective, total order broadcast &#x3D;&#x3D; multiple rounds of single value consensus.\nconsensus([B, A, C]) == consensus([consensus(B), consensus(A), consensus(C)])\n\n\nDue to the agreement property of consensus, all nodes decide to deliver the same messages in the same order.\nDue to the integrity property, messages are not duplicated.\nDue to the validity property, messages are not corrupted and not fabricated out of thin air.\nDue to the termination property, messages are not lost.\n\nSingle-leader replication and consensusIf the leader is selected manually, it can works well and follows the first three rules, but does not satisfy the termination property because of the need of human intervention.\nFor automatic leader election and failover, it will promote a follower to be the new leader if the old leader fails. The protocols define an epoch number (called the ballot number in Paxos, and term number in Raft) and guarantee that within each epoch, the leader is unique. Every time the current leader is thought to be dead, a vote is started among the nodes to elect a new leader. This election is given an incremented epoch number, and thus epoch numbers are totally ordered and monotonically increasing. If there is a conflict between two different leaders in two different epochs, then the leader with the higher epoch number prevails.\nFor every decision that a leader wants to make, it must send the proposed value to the other nodes and wait for a quorum of nodes to respond in favor of the proposal.\nDifference with 2PC\n2PC requires all participants reply “yes”, while fault-tolerant consensus algorithm only requires quorum.\n2PC’s coordinator cannot be elected automatically, while fault-tolerant consensus algorithm can achieve leader election.\n\n\nMembership and Coordination ServicesProjects like ZooKeeper or etcd are often described as “coordination and configuration services”. They are designed to hold small amounts of data that can fit entirely in memory (although they still write to disk for durability)—so you wouldn’t want to store all of your application’s data here. That small amount of data is replicated across all the nodes using a fault-tolerant total order broadcast algorithm.\nZooKeeper has some features:\n\nLinearizable atomic operations\nTotal ordering of operations\nFailure detection\nChange notifications (new node join &#x2F; old node exit)\n\nAllocating work to nodesOne example in which the ZooKeeper works well is if you have several instances of a process or service, and one of them needs to be chosen as leader or primary. If the leader fails, one of the other nodes should take over. This is of course useful for single-leader databases, but it’s also useful for job schedulers and similar stateful systems.\nAnother example arises when you have some partitioned resource and need to decide which partition to assign to which node. As new nodes join the cluster, some of the partitions need to be moved from existing nodes to the new nodes in order to rebalance the load. As nodes are removed or fail, other nodes need to take over the failed nodes’ work.\nNormally, the kind of data managed by ZooKeeper is quite slow-changing. ZooKeeper is not intended for storing the runtime state of the application, which may change thousands or even millions of times per second.\nService discoveryService discovery &rarr; to find out which IP address you need to connect to in order to reach a particular service.\nMembership serviceMembership service &rarr; which nodes are currently active and live members of a cluster.\nDue to unbounded network delays it’s not possible to reliably detect whether another node has failed. However, if you couple failure detection with consensus, nodes can come to an agreement about which nodes should be considered alive or not.\n\nno matter the node is alive or crashed, if quorum thinks it is dead, then it’s dead.\n\n","tags":["System Design","DDIA"]},{"title":"Why and why not inline","url":"/2023/07/20/Why-and-why-not-inline/","content":"Why inlineIn C++, we can add inline keyword in front of function defination (inline only works on defination, you don’t need to use inline in statement).\nvoid this_is_inline_func();inline void this_is_inline_func() &#123;    std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;&#125;\n\nno inlineWhen we call a function, the process is\n\nfind function defination and its address\nload from memory to stack\nexecute\npop from stack\n\nvoid this_is_not_inline() &#123;    ...&#125;this_is_not_inline();   // 1this_is_not_inline();   // 2this_is_not_inline();   // 3\n\n0x0000 -&gt; defination of this_is_not_inline...0x0100 -&gt; call 1    // find address is 0x0000 -&gt; push 0x0000 into stack -&gt; execute -&gt; pop0x0104 -&gt; call 2    // same0x0108 -&gt; call 3    // same\n\ninlineAll of these steps will cost extra time. To avoid this cost, we can use inline. After we defining a function as inline, we may have multiple calls in code. When we compile the code, the compiler will change function calls to function defination, so that when execute the code, instead of wasting time finding defination and loading from memory to stack, it just executes the function logic.\nvoid this_is_inline() &#123;    std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;&#125;this_is_inline();   // 1this_is_inline();   // 2this_is_inline();   // 3\n\n0x0000 -&gt; defination of this_is_inline...0x0100 -&gt; std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;  // change call to defination0x0200 -&gt; std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;0x0300 -&gt; std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;\n\n\nWhy not inlineSounds great? But the problem is, we need to copy the defination after every calls. If the defination is very complicated, we will cost losts of memory. What’s more, if the function is complicated, the execution time &gt;&gt; load &amp; pop stack time, we can ignore the inline improvement.\n\nSuggestionOnly use inline for very simple function. Actually inline is just a recommendation rather than requirement. If the function contains loop, recursion, static, etc complex logic, the function will be treated as not-inline even if you add inline keyword.\nWhat’s more, in class, the methods defination will be treated as inline. So only define simple methods in class, for complex methods, leave statements inside class, then define them outside class.\nclass Object &#123;public:    Object() =default;    Object(const Object&amp; rhs) &#123; num = rhs.num; &#125;    int get_num() &#123; return num; &#125;   // define simple method inside class (auto inline)    void inline_function();    void complex_function();private:    int num;&#125;;// we can still define inline outside classinline void Object::inline_function() &#123;    ...&#125;// for complex method, plz define outside classvoid Object::complex_function() &#123;    ...&#125;\n\n\n#define vs inline#define replaces the pure text in pre-complie stage, inline replaces function call with function defination in complie stage.\n","tags":["c++"]},{"title":"Friend function inside template class","url":"/2023/08/09/Friend-function-inside-template-class/","content":"Assume we have a template class named Matrix, and we want to add a friend function called swap().\nMethod 1template&lt;typename T&gt;class Matrix &#123;    // ...    friend void swap(Matrix&lt;T&gt;&amp; a, Matrix&lt;T&gt;&amp; b) &#123;        // definition    &#125;&#125;;\n\nNotice, the swap() is not a template function! It’s just a normal function.\nWhy we need to define it inside the class?\n\nBecause when we create a Matrix&lt;int&gt;, it will also define a void swap(Matrix&lt;int&gt;&amp;, Matrix&lt;int&gt;&amp;) for system; for Matrix&lt;double&gt;, it’s the same. In other word, when we create certain type Matrix, the swap which supports that certain type will be automatically created for us. So that when we use swap(), it always make sure we can find the definition.\n\nCan we define it outside the class?\n\nYes, you can, but you need to make sure you write definitions for all possible types, like you need to implement a void swap(Matrix&lt;int&gt;&amp;, Matrix&lt;int&gt;), a void swap(Matrix&lt;double&gt;&amp;, Matrix&lt;double&gt;), etc for all possible typename T.\n\nMethod 2template&lt;typename T&gt;class Matrix;template&lt;typename T&gt;void swap(Matrix&lt;T&gt;&amp;, Matrix&lt;T&gt;&amp;);  // we need to know what is Matrix&lt;T&gt;, so declare Matrix beforetemplate&lt;typename T&gt;class Matrix &#123;    // ...    friend void swap&lt;&gt;(Matrix&amp; a, Matrix&amp; b);   // we need to know that is a template function, so declare before&#125;;template&lt;typename T&gt;void swap(Matrix&lt;T&gt;&amp; a, Matrix&lt;T&gt;&amp; b) &#123;    // definition&#125;\n\nNotice here the swap is a template function, so that we need to write it as swap&lt;&gt;, and we don’t need to explicitly denote Matrix type, cuz template funtion can deduce its type.\nCan we don’t write the declarition of template swap?\n\nNo. Inside class definition, we tell the class that we have a template friend function. If we don’t declare it before class definition, the class don’t know how many typenames it has, do it have default typename, etc.\n\nTricktemplate&lt;typename T&gt; void helper(T);template&lt;typename T&gt;class Obj &#123;    // ...    friend void helper&lt;char&gt;(char); // no matter what type Obj is, only helper with char type can get access to private members&#125;\n","tags":["c++"]},{"title":"#include <> Vs #include \"\" ","url":"/2023/07/16/cpp_include_difference/","content":"#include &lt;header&gt;This will let preprocessor find header files in pre-designated directories.\n\nThese directories are normally system-related, such as “&#x2F;usr&#x2F;include”, “&#x2F;x86&#x2F;include”, etc.\n\nLet’s use Linux as example. If we ls /usr, you will see bin, include and lib, and if we ls /usr/include, output will contain lots of system defined header files, such as /usr/include/cpp/vector and /usr/include/cpp/iostream. This is how we include these commonly used packages.\n// find header file named &quot;iostream&quot; from &quot;/usr/include&quot;#include &lt;iostream&gt;\n\n\n#include &quot;header&quot;This will search programmer-defined header files and typically includes same directory as the file containing the directive.\nmy_project| - include|   | - my_header.h| - my_project.cpp\n// my_project.cpp#include &quot;my_header.h&quot;\n\nLet’s assume the project tree looks like that, and when we #include &quot;&quot;, it will search header files under /my_project directory.\nIf the processor cannot find header file in current project directory, it will search header files in system path (the same as #include &lt;&gt;).\n\n#include &quot;header.h&quot; – cannot find locally –&gt; #include &lt;header.h&gt;\n\n\nAdd include pathAs we discussed before, #include &lt;&gt; will search pre-designated directories. What if we want the processor to search other directories?\nWe can add include paths via \n\n-I\nsystem environment variable\nCMake\n\nAfter adding include paths, the searching order is\n\n#include &lt;&gt;\ndir list\nsystem dir\n\n\n#include &quot;&quot;\nlocal\ndir list\nsystem dir\n\n\n\n-IWe can use -I flag in command line to add search paths.\ng++ -c test.cpp -o testg++ -c test.cpp -o test -I /path/to/certain/include/\n\nSystem environment variableThe system environment has a property called CPLUS_INCLUDE_PATH, we can set this to add search paths.\nexport CPLUS_INCLUDE_PATH=&quot;path/to/certain/include&quot;\n\nCMakeFor CMake, we can use include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...]) .\n","tags":["c++"]},{"title":"How to setup blog?","url":"/2023/07/14/how_to_setup_blog/","content":"GithubJust create a new repo, and the repo’s name follows rule “username.github.io”.\n\nNode.js &amp; HexoInstallJust donwload Node.js from offical website (maybe you also need npm :)). For Mac user, the simplest way is run command:\nbrew install node\n\nFor Hexo, we just need to run\nnpm install hexo-cli -g\n\nAfter installation, use commands to validate:\nnode -vnpm -vhexo -v\n\nInitIf everything is OK, run following commands:\nmkdir blog &amp;&amp; cd bloghexo init   # init the folder as blog reponpm install # install necessary node_modules\n\nThen you will find a file named blog/_config.yml, add these info in last rows:\n# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy:  type: git  repository: &lt;your github repo&gt;  branch: master\n\nDeployYou can add a new plug-in npm i hexo-deployer-git so that we can post blogs to git via hexo.\nhexo new post &quot;this is post name&quot;hexo g  # generatehexo s  # can view changes in localhosthexo d  # deploy to github\n\n\n:money:\nActually this step is optional, cause u can use “username.github.io” to browse your blog. However, if you want a fancy URI (and you are rich), you can follow the step.\n\nYou should buy a web URI, I got one from GoDaddy.\nAfter you got one, let’s say it’s “myfancyblog.com”, you should set the DNS so that when other people enter “myfancyblog.com” in browser, it can re-direct to “username.github.io”.\nOther people                  Your github repo&quot;myfancyblog.com&quot;   - DNS -&gt;  &quot;username.github.io&quot;\n\nIn DNS Management page, you should set two more DNS Records.\n\n\n\nType\nName\nData\n\n\n\nA\n@\nIP Address For username.github.io\n\n\nCNAME\nwww\nusername.github.io\n\n\nThe first one re-directs “myfancyblog.com” to “username.github.io”‘s IP, the second re-directs “www.myfancyblog.com“ to “username.github.io”.\nThen, you should go back to your blog repo, in blog/source create a new file CNAME, then put “myfancyblog.com” in this file. hexo g &amp;&amp; hexo d. You will see github.com will have a new CNAME file, and you can check “Setting -&gt; Pages”, it should have “myfancyblog.com” in “Custom domain” field.\n\nTipsIf you are curious about “why I changed some settings but the web page seems no change”, :(, well, remember to clear the browser cache.\n","tags":["blog","tools"]},{"title":"tmux cookbook","url":"/2023/07/17/tmux-cookbook/","content":"TmuxWhen we use command line tools (CLI), we will open a terminal, and input some commands. This process called “session”. But session is temporary, which means when we close the terminal, the session ends.\nHow can we keep the session even we close the page?\nUsing Tmux :)\nTmux will create a new terminal (you can think this is a sub-terminal), and we can run commands inside. When we close the terminal, it will not end the session, just return back to the main terminal, we can connect the sub-terminal again via tmux.\nWhen use tmux?This is a difficult question. For me, I will use tmux in 2 situations:\n\nI want to show off. You know what I mean, multiple panes in one screen, especially use one pane to run top command, it’s just like hack style.\nThe task will take a long running time. For instance, the machine learning stuff, you can run it in one session, then go back to working. After one million year, re-connect the session and see error information like “No Module Named xxx” (just don’t ask me why I know that)\n\ncookbook\n\n\nCommand\nFunctionality\n\n\n\ntmux new -s &lt;name&gt;\ncreate a named session\n\n\ntmux detach\nkeep the session and go back to main terminal\n\n\ntmux ls\nlist sessions\n\n\ntmux attach -t &lt;name&gt;\nre-connect to session\n\n\ntmux kill-session -t &lt;name&gt;\nend session\n\n\ntmux switch -t &lt;name&gt;\nswitch to session\n\n\ntmux split-window\nsplit up &amp; down\n\n\ntmux split-window -h\nsplit left &amp; right\n\n\ntmux select-pane -U&#x2F;D&#x2F;L&#x2F;R\nselect up&#x2F;down&#x2F;left&#x2F;right pane\n\n\ntmux swap-pane -U&#x2F;D\nchange pane’s size\n\n\nhot key\n\n\nhot key\nfunctionality\n\n\n\nctrl+d\nexit and kill session\n\n\nctrl+b d\ntmux detach\n\n\nctrl+b ?\nhelp\n\n\nctrl+b s\ncheck all sessions\n\n\nctrl+b $\nrename session\n\n\nctrl+b %\nsplit left &amp; right\n\n\nctrl+b “\nsplit up &amp; down\n\n\nctrl+b x\nkill session\n\n\nctrl+b &lt;arrow key&gt;\nselect pane\n\n\nctrl+b ctrl+&lt;arrow key&gt;\nresize pane\n\n\nctrl+b !\nmake panes into different sessions\n\n\nctrl+b :set &lt;command&gt;\nset properties, eg: :set mouse on to enable mouse control\n\n\n","tags":["tools","cookbook"]},{"title":"Unittest in python - Patch","url":"/2023/07/27/Unittest-in-python-Patch/","content":"After introduced mock in previous section, let’s talk about another powerful module – patch.\nIntropatch is a decorator &#x2F; context manager, and it can help you use some new stuff (default is Mock()) to replace target.\ndirectly use# demo.pydef func():    return 1\n\nimport demofrom unittest.mock import patchdef main():    mock_func = patch(&quot;demo.func&quot;)    mock_func.return_value = 10    mock_func.start()    demo.func()     # 10    mock_func.end()    demo.func()     # 1\n\ncontext manager# demo.pydef func():    return 1\n\nimport demofrom unittest.mock import patchdef main():    with patch(&quot;demo.func&quot;) as mock_func:        mock_func.return_value = 10        demo.func() # 10    demo.func()     # 1\n\ndecorator# demo.pydef func():    return 1\n\nimport demofrom unittest.mock import patch@patch(&quot;demo.func&quot;)def test_main(mock_func):    mock_func.return_value = 10    demo.func() # 10\n\nnotice 0Please notice, if we have multiple @patch for one function, the order is important: the inner decorator decorates front parameter.\n@patch(&quot;demo.func2&quot;)@patch(&quot;demo.func1&quot;)def test(mock_func1, mock_func2):    ...\n\nnotice 1Decorator can also be used in class. Remember patch is used for test, so\n\nonly function name starts with test_ will be treat as test function\nonly class derives from unittest.TestCase will be treat as test class\n\n@patch(&quot;demo.func&quot;)class MyTest(unittest.TestCase):    def test_1(self, mock_func):        ...    def test_2(self, mock_func):        ...        # patch is not working    def mytest_func(self):        ...\n\n\npatchunittest.mock.patch(target, new=DEFAULT, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, **kwargs) \n\ntarget: target object’s path, remember it must be a string looks like package.module.className. If the object is defined in the same file, please use __main__.className.\nnew: default is MagicMock(), it can be a value or a actual object.\nnew_callable: it is a callable to create object.\nspec &amp; spec_set: please refer Mock parts\n\ndef new_func():    return 10def main():    mock_func = patch(&quot;demo.func&quot;, new = new_func)    mock_func.start()    demo.func()     # new_func() -&gt; 10    mock_func.end()\n\npatch target pathIf we want to patch some function, the path is not where we define the function, is where we use it.\n# package2.m2.pyfrom package1.m1 import func1def func2():    func1()\n\n# test.py@patch(&quot;package2.m2.func1&quot;)\n\nnew vs return_valuedef main():    mock_func = patch(&quot;demo.func&quot;, return_value = 10)    mock_func.start()    demo.func() # 10    mock_func.end()def main():    mock_func = patch(&quot;demo.func&quot;, new = 10)    mock_func.start()    demo.func   # 10    mock_func.end()\n\nnew vs new_callablenew is an instance, new_callable is a callable to create instance.\nfoo = 10with patch(&quot;__main__.foo&quot;, new = 100):    foowith patch(&quot;__main__.foo&quot;, new_callable = lambda: 100):    foo\n\ndef return_100():    return 100def main():    mock_func = patch(&quot;demo.func&quot;, new = return_100)    mock_func.start()    demo.func() # 100    mock_func.end()# don&#x27;t recommend to assign a value to newdef main():    mock_func = patch(&quot;demo.func&quot;, new_callable = return_100)    mock_func.start()    demo.func   # 100    mock_func.end()\n\nCannot use ‘new’ and ‘new_callable’ together!\npatch(&quot;demo.func&quot;, new = xxx, new_callable = xxx)   # error\n\nhow to patch a whole class# util.pyclass Object:    def __init__(self, x, y):        self.x = x        self.y = y        def show(self):        print(f&quot;x = &#123;x&#125;, y = &#123;y&#125;&quot;)        return 0\n\n# keep this the same as __init__def constructor(self, x, y):    self = Mock(spec = Object)    self.x = 2 * x    self.y = 2 * y    self.show.return_value = 100    return self@patch(&quot;util.Object&quot;, new = constructor)def test_patch_with_new():    o = Object(10, 10)    res = o.show()      # x = 20, y = 20    print(res)          # 100    o.x = 1000    print(o.x)          # 1000\n\n\npatch.objectUsed to mock methods in one class.\nimport Object# only mock func inside Object class@patch.object(Object, &quot;func&quot;)def test_patch_object(mock_func):    mock_func.return_value = 100    o = Object()    o.func()    # 100\n\n\n\npatch.dictm = &#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;with patch.dict(m, &#123;&quot;a&quot;: 10, &quot;b&quot;: 20&#125;, clear=True):    m[&quot;a&quot;]  # 10\n","tags":["python","test","pytest"]},{"title":"What is .pyi file","url":"/2023/09/12/What-is-pyi-file/","content":"Sometimes in VSCode, we want to “jump to declaration”, then IDE redirect us to a file with suffix .pyi, and all it contains are some strange code like this:\nclass Object:    def __init__(self, name: str, age: _T) -&gt; None:        ...        def get_name(self) -&gt; str:        ...        def get_age(self) -&gt; _T:        ...        def __lt__(self, other: Object) -&gt; bool:        ...        def __add__(self, v: _T) -&gt; _T:        ...\n\nIt looks like .h file in C++, only declares the function signature, typedef, etc without any implementation.\nActually, a .pyi file is not required but recommended, the only purpose for .pyi file is: IDE can provide auto complete and programmer can read the APIs fast and don’t need to care about the implementation details.\n","tags":["python"]},{"title":"What is `typing.TYPE_CHECKING` and `from __future__ import annotation`","url":"/2025/09/17/What-is-typing-TYPE-CHECKING/","content":"Purposetyping.TYPE_CHECKING is a boolean flag, it’s True during static type checking(e.g. mypy), and it’s False at runtime.\n\nUse CaseIt is primarily used to guard imports or code blocks that are only necessary for type checking and should not be executed at runtime.\nCircular ImportCircular import means two modules import each other.\n# module_a.pyfrom module_b import function_bdef function_a():    function_b()\n# module_b.pyfrom module_a import function_adef function_b():    function_a()\n\nWhen type hints introduce circular dependencies between modules, TYPE_CHECKING can be used to conditionally import modules only during type checking, preventing runtime import errors.\n\nNotice: circular import error may occur for several reasons, e.g. function invocation or type annotation, typing.TYPE_CHECKING is only useful for type annotation.\n\nfrom typing import TYPE_CHECKINGif TYPE_CHECKING:    from my_module import MyType&quot;&quot;&quot;Use string literal for forward references. The interpreter just stores it as a string at runtime without resolving itimmediately.&quot;&quot;&quot;def function(data: &quot;MyType&quot;):    ...&quot;&quot;&quot;Error, it triggers interpreter to resolve the name immediately, which leads to circular import&quot;&quot;&quot;# def function(data: MyType):#     ...&quot;&quot;&quot;Error, function invocation requires to get access to the module, which leads to circular import&quot;&quot;&quot;# def function(data: &quot;MyType&quot;):#     other = MyType(data) # function invocation\n\nAvoid unnecessary import costIf the module is only used as a type annotation, typing.TYPE_CHECKING avoid importing it at runtime so that improve the efficiency.\nfrom typing import TYPE_CHECKINGif TYPE_CHECKING:    from my_module import MyType # only import module on type checking phase, runtime phase will skip it\n","tags":["python"]}]
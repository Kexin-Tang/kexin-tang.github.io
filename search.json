[{"title":"DDIA cookbook - (1)Reliable, Scalable, and Maintainable Application","url":"/2023/08/10/DDIA-cookbook-1-Reliable-Scalable-and-Maintainable-Application/","content":"IntroCPU is no longer the bottle neck. New problems are amount of data, complexity of data and the speed of changing. We call it data-intensive.\n\nStorage - Database\nSpeed - Cache\nSearch - Indexing\nUnkonwn size, continuous, asynchronous - Stream Processing\nAccumulated data - Batch Processing\n\nRight now, single tool is hard to meet requirements. And new tools are designed to optimize for variety of use cases, the boundary between category is blurred.\n\nReliabilityWhat is correct? It’s hard to define, but we can simply consider:\n\nThe App performs what user expected\nThe App can tolerate some mistakes or using it in unexpected ways\nThe App is good enough under certain load and data volume\nThe App prevents any abuse or unauthorized access\n\nThen we can define reliable means “continuing to work correctly, even bad things happend”.\nThe bad things are called faults, a reliable system should be fault-tolerant.\n\nfault vs failure\n\nfault - system deviates from original design\nfailure - system cannot work (crush)\n\nWe should design fault-tolerance mechanisms to prevent faults from causing failure\n\nHardware FaultsMorden hardware system will use RAID to add redundancy to reduce the fault rate.\nHardware faults are random and independent for most of the cases.\nSoftware ErrorsSoftware errors are sometimes correlated. And these bugs may hide for a long time until we trigger it.\n\nScalabilityScalability is used to describe a system’s ability to cope with increased load or changed resources.\nLoadRemember use case is always the key. Load can be:\n\nrequest per second\nread &#x2F; write ratio\nhit rate on cache\n…\n\nWhen we consider the load, the first thing is make the use case clear. There isn’t best solution, there is only suitable solution.\nPerformanceThere have two situations:\n\nIf load increases, and we keep the resource unchanged, how the performance changes?\nIf load increases, how many resources we need to change to keep the performance unchanged?\n\nTo solve these, we need to measure performance.\nThere are two key term: \n\nthroughput &rarr; the number of tasks we can process per second\nresponse time &rarr; the time between client sending request and receiving response\n\n\nlatency vs response time\n\nlatency &rarr; duration for a request waitting to be handled\nresponse time &rarr; user aspect, I send a request, how long it takes until I get response, it may include network delay, queuing delay, processing time, etc\n\n\nPercentileIf we run a request multiple times, the response time is not a fixed number, it has distribution. So average response time is p50 (50% percent).\nFor most of the response time, it looks good, so we always pay attention to tail latencies (high percentile), like p99 (90%) or p999 (99.9%). These response time is always very large and affect user’s experience.\nSLO SLAService Level Objectives &amp; Service Level Agreements are contracts that define the expected performance and avaliability of a service.\nFor example, some SLAs may define “p50 &lt; 50ms, p99 &lt; 100ms”.\nQueuing Delay &amp; HoLQueuing delay is one of the most significant reason for tail latency, because limited resource can only handle limited things in parallel.\nIf we have many requests, they will form a queue. Even the following 99% requests are fast, if the first 1% requests are slow, it will block the queue, and make the total execution time increasing. It’s called Head-of-Line block.\nApproaches for coping with loadScale up &rarr; vertical scale, means build more powerful machine\nScale out &rarr; horizontal scale, means distribute total load into several small machines\nElastic &rarr; autoscale, means this system can detect load changing, and automatically scale to keep performance\n\nMaintainability\nOperability - make it easy for operation team to keep the system running smoothly\nSimplicity - make new engineer can understand the system easily\nEvolvability - make it easy for adding new features\n\n","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (3)OLTP, OLAP and Columnar Store","url":"/2023/08/17/DDIA-cookbook-3-OLTP-OLAP-and-Columnar-Store/","content":"","tags":["System Design","DDIA"]},{"title":"DDIA cookbook - (2)Data Models and Query Languages","url":"/2023/08/10/DDIA-cookbook-2-Data-Models-and-Query-Languages/","content":"Data ModelA data model is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities.\nMorden applications are built by layering one data model on top of another. Each layer hides the complexity of the layers below it by providing a data model.\n\nRelational Vs Document ModelOne-to-Many\nFor relational model, is hard to represent One-to-Many relationship, like one person may have 0 to infinite work experience.\n\nRelational &rarr; create multiple table to store company info, school info, then use foreign key to JOIN several tables\nDocument &rarr; can use JSON-like structure, easy to read by human, and better locality (store these info in one place)\n\nMany-to-One &amp; Many-to-ManyWhen we store the region, we use ID rather than pure text. This is because ID has no meaning, it never needs to change. For example, if we want to update “Greater Seattle Area” to “Seattle”, we just need to modify the text in region_table.\nDocument model is good at One-to-Many because you can imagine it as a tree, but it’s not good at Many-to-X, because it looks like a graph.\nIf document model doesn’t support JOIN, then we need to use iteration to mock JOIN in application level. Even if it supports JOIN, we still need to use document reference (just like foreign key), which is similar to relational model.\nlocalityFor document database, it always store the whole document as a single object.\nFor read, it need to load the whole document from disk to memory, so if we need most of parts inside the document, it’s fine; otherwise, its performance is poor.\nFor write, it also need to rewrite the whole document from memory to disk, and only modifications that don’t change the total encoded size of a document can easily be performed in place; otherwise, system need to assign new space for new document.\nschema-on-read vs schema-on-writeDocument Database is not schemaless. Actually, it has implicit constrain, like when we write service code to read something from DB, we assume we can get some fields, so schema-on-read is a more accurate term.\n\n\n    schema-on-read\n    check when we READ\n    poor efficiency, cuz we cannot do any optimizations when we write it\n\n\n    schema-on-write\n    check when we WRITE\n    good efficiency cuz we can check the type then do optimization\n\n\n\nSummary\n\n\n\ndocument\nrelation\n\n\n\nrelation map\ntree, one-to-many\ncan use foreign key to achieve many-to-X\n\n\nJOIN\n:(\n:)\n\n\nflexibility\nflexible, can add fields easily\nschema, hard to change\n\n\nlocality\nif operate the whole doc, performance is good; but if only operate partial doc, performance is not good\nscatter in tables\n\n\n\nQuery LanguageDeclarative vs Imperative Language\n\n\n\nDeclarative\nImperative\n\n\n\nConcept\ndeclare the logic rather than actual execution\ndefine the execution plan\n\n\nExample\nSQL, CSS\nC++, Python, …\n\n\nAbstraction\nhigh\nlow\n\n\nParallel\ngood, cuz we let system do the optimization\npoor, cuz we already defined the steps\n\n\n\nWhat u want?\nHow to do that?\n\n\nHere are some advantages for declarative language:\n\nMore concise and easily use\nHide implementation details\nGood support for parallelism\n\nMapReduce QueryMapReduce is neither a declarative language nor a imperative language.\n\n\ndeclarative &rarr; we don’t need to specify how to iter or shuffle dataset\nimperative &rarr; we need to implement map and reduce functions\n\n\nIt requires the map and reduce are pure function, which means they only use input data, they cannot do anything else like query database.\nAnd they cannot have any side effects, which means no matter when we run the function for a given input, the output should be the same.\nWhat’s more, mapreduce is a very low-level model for distributed execution, so engineers can implement higher-level query language base it, like SQL can be implemented as a pipeline of mapreduce.\n\nGraph Data ModelSuitable for Many-to-Many relationships.\n\nvertice &#x2F; node\nedge &#x2F; relation\nattribute\n\nGraph can store both homogeneous and heterogeneous data. For example, node can represents people, city, animal, activity, etc.\n","tags":["System Design","DDIA"]},{"title":"Friend function inside template class","url":"/2023/08/09/Friend-function-inside-template-class/","content":"Assume we have a template class named Matrix, and we want to add a friend function called swap().\nMethod 1template&lt;typename T&gt;class Matrix &#123;    // ...    friend void swap(Matrix&lt;T&gt;&amp; a, Matrix&lt;T&gt;&amp; b) &#123;        // definition    &#125;&#125;;\n\nNotice, the swap() is not a template function! It’s just a normal function.\nWhy we need to define it inside the class?\n\nBecause when we create a Matrix&lt;int&gt;, it will also define a void swap(Matrix&lt;int&gt;&amp;, Matrix&lt;int&gt;&amp;) for system; for Matrix&lt;double&gt;, it’s the same. In other word, when we create certain type Matrix, the swap which supports that certain type will be automatically created for us. So that when we use swap(), it always make sure we can find the definition.\n\nCan we define it outside the class?\n\nYes, you can, but you need to make sure you write definitions for all possible types, like you need to implement a void swap(Matrix&lt;int&gt;&amp;, Matrix&lt;int&gt;), a void swap(Matrix&lt;double&gt;&amp;, Matrix&lt;double&gt;), etc for all possible typename T.\n\nMethod 2template&lt;typename T&gt;class Matrix;template&lt;typename T&gt;void swap(Matrix&lt;T&gt;&amp;, Matrix&lt;T&gt;&amp;);  // we need to know what is Matrix&lt;T&gt;, so declare Matrix beforetemplate&lt;typename T&gt;class Matrix &#123;    // ...    friend void swap&lt;&gt;(Matrix&amp; a, Matrix&amp; b);   // we need to know that is a template function, so declare before&#125;;template&lt;typename T&gt;void swap(Matrix&lt;T&gt;&amp; a, Matrix&lt;T&gt;&amp; b) &#123;    // definition&#125;\n\nNotice here the swap is a template function, so that we need to write it as swap&lt;&gt;, and we don’t need to explicitly denote Matrix type, cuz template funtion can deduce its type.\nCan we don’t write the declarition of template swap?\n\nNo. Inside class definition, we tell the class that we have a template friend function. If we don’t declare it before class definition, the class don’t know how many typenames it has, do it have default typename, etc.\n\nTricktemplate&lt;typename T&gt; void helper(T);template&lt;typename T&gt;class Obj &#123;    // ...    friend void helper&lt;char&gt;(char); // no matter what type Obj is, only helper with char type can get access to private members&#125;\n","tags":["c++"]},{"title":"Unittest in python - Patch","url":"/2023/07/27/Unittest-in-python-Patch/","content":"After introduced mock in previous section, let’s talk about another powerful module – patch.\nIntropatch is a decorator &#x2F; context manager, and it can help you use some new stuff (default is Mock()) to replace target.\ndirectly use# demo.pydef func():    return 1\n\nimport demofrom unittest.mock import patchdef main():    mock_func = patch(&quot;demo.func&quot;)    mock_func.return_value = 10    mock_func.start()    demo.func()     # 10    mock_func.end()    demo.func()     # 1\n\ncontext manager# demo.pydef func():    return 1\n\nimport demofrom unittest.mock import patchdef main():    with patch(&quot;demo.func&quot;) as mock_func:        mock_func.return_value = 10        demo.func() # 10    demo.func()     # 1\n\ndecorator# demo.pydef func():    return 1\n\nimport demofrom unittest.mock import patch@patch(&quot;demo.func&quot;)def test_main(mock_func):    mock_func.return_value = 10    demo.func() # 10\n\nnotice 0Please notice, if we have multiple @patch for one function, the order is important: the inner decorator decorates front parameter.\n@patch(&quot;demo.func2&quot;)@patch(&quot;demo.func1&quot;)def test(mock_func1, mock_func2):    ...\n\nnotice 1Decorator can also be used in class. Remember patch is used for test, so\n\nonly function name starts with test_ will be treat as test function\nonly class derives from unittest.TestCase will be treat as test class\n\n@patch(&quot;demo.func&quot;)class MyTest(unittest.TestCase):    def test_1(self, mock_func):        ...    def test_2(self, mock_func):        ...        # patch is not working    def mytest_func(self):        ...\n\n\npatchunittest.mock.patch(target, new=DEFAULT, spec=None, create=False, spec_set=None, autospec=None, new_callable=None, **kwargs) \n\ntarget: target object’s path, remember it must be a string looks like package.module.className. If the object is defined in the same file, please use __main__.className.\nnew: default is MagicMock(), it can be a value or a actual object.\nnew_callable: it is a callable to create object.\nspec &amp; spec_set: please refer Mock parts\n\ndef new_func():    return 10def main():    mock_func = patch(&quot;demo.func&quot;, new = new_func)    mock_func.start()    demo.func()     # new_func() -&gt; 10    mock_func.end()\n\npatch target pathIf we want to patch some function, the path is not where we define the function, is where we use it.\n# package2.m2.pyfrom package1.m1 import func1def func2():    func1()\n\n# test.py@patch(&quot;package2.m2.func1&quot;)\n\nnew vs return_valuedef main():    mock_func = patch(&quot;demo.func&quot;, return_value = 10)    mock_func.start()    demo.func() # 10    mock_func.end()def main():    mock_func = patch(&quot;demo.func&quot;, new = 10)    mock_func.start()    demo.func   # 10    mock_func.end()\n\nnew vs new_callablenew is an instance, new_callable is a callable to create instance.\nfoo = 10with patch(&quot;__main__.foo&quot;, new = 100):    foowith patch(&quot;__main__.foo&quot;, new_callable = lambda: 100):    foo\n\ndef return_100():    return 100def main():    mock_func = patch(&quot;demo.func&quot;, new = return_100)    mock_func.start()    demo.func() # 100    mock_func.end()# don&#x27;t recommend to assign a value to newdef main():    mock_func = patch(&quot;demo.func&quot;, new_callable = return_100)    mock_func.start()    demo.func   # 100    mock_func.end()\n\nCannot use ‘new’ and ‘new_callable’ together!\npatch(&quot;demo.func&quot;, new = xxx, new_callable = xxx)   # error\n\nhow to patch a whole class# util.pyclass Object:    def __init__(self, x, y):        self.x = x        self.y = y        def show(self):        print(f&quot;x = &#123;x&#125;, y = &#123;y&#125;&quot;)        return 0\n\n# keep this the same as __init__def constructor(self, x, y):    self = Mock(spec = Object)    self.x = 2 * x    self.y = 2 * y    self.show.return_value = 100    return self@patch(&quot;util.Object&quot;, new = constructor)def test_patch_with_new():    o = Object(10, 10)    res = o.show()      # x = 20, y = 20    print(res)          # 100    o.x = 1000    print(o.x)          # 1000\n\n\npatch.objectUsed to mock methods in one class.\nimport Object# only mock func inside Object class@patch.object(Object, &quot;func&quot;)def test_patch_object(mock_func):    mock_func.return_value = 100    o = Object()    o.func()    # 100\n\n\n\npatch.dictm = &#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;with patch.dict(m, &#123;&quot;a&quot;: 10, &quot;b&quot;: 20&#125;, clear=True):    m[&quot;a&quot;]  # 10\n","tags":["python","test","pytest"]},{"title":"DDIA cookbook - (3)B-Tree and LSM-Tree","url":"/2023/08/17/DDIA-cookbook-3-B-Tree-and-LSM-Tree/","content":"LogHere, we define log as an append-only sequence of records.\n\nIndexIndex is an additional data structure, which doesn’t affect the contents of database, but affect the operation performance.\nIndex can speed up the read, but slow down the write cuz we need to maintain the index.\nHash IndexKey-Value StoreHash index is commonly used in Key-Value Storage. We can keep an in-memory hash map where every key is mapped to a offset in the data file. And we also store the k-v in log file which locates in disk. Every time we write a new k-v pair, we append the k-v in log file (notice log file in disk), and modify the index in memory. \nHowever, it may run out of disk space. A good way to solve this problem is Compaction.\nCompaction\nWe can store the index information in the segment, when the segment reach its size limitation, we make subsequent write in new segment. Then we can perform compaction process for these frozen segments. If same key appears many times in these segment, we just keep the newest value. It will generate the new compacted segments in new files and delete old segments to save space.\nThe whole process can happen in background thread, so it will not affect the service.\nTo find a value for a key, we just check the most recent segment, if the key is not present, then second-most-recent and so on.\nConsiderations\nDeleting Records &rarr; we need to keep the delete operation in logs (sometimes use special mark called tombstone)\nto mark the pervious operations for this key are useless, so if there is no new record for this key, this key shouldn’t appear in compacted segment.\nCrash Recovery &rarr; when database is restarted, in-memory hashmap is erased. We can iter all segment k-v info to rebuild the hashmap, but it’s costy. We can choose to store the k-v info and snapshots of the in-memory hashmap on disk, so that we just load the snapshots to rebuild hashmap.\nConcurrency Control &rarr; as writes are appended to the log in a strictly sequential order, a common implementation choice is to have only one writer thread. Data file segments are append-only and otherwise immutable, so they can be read concurrently by multiple threads.\n\nlog-structured vs update-in-placelog-structured &gt; update-in-place\n\nappend (sequential access) is always more efficient than random access\nconcurrency control and crash recovery are simpler &rarr; thanks for immutable log (or say it’s append-only)\ncompaction can reduce fragment problem\n\nlog-structured &lt; update-in-place\n\nkey must in memory\nkey is good for point searching but is bad for range searching\n\nSSTable &amp; LSM-TreeIf we let the key are sorted in segment, we call it Sorted String Table or SSTable.\nWhy SSTable is useful?\n\nMerging&#x2F;Compacting segments is simple and efficient. It use merge sort algorithm to achieve high efficiency. If one key appears in multiply segments, just use the most up-to-date segment value.\n\n\n\nSparse index. We don’t need to keep all keys in memory, instead, just keep sparse index.\nFor example, create key for “A”, and key for “C”, then key “B” must between these two.\n\n\nCompression. Since read requests need to scan over several key-value pairs in the requested range, it’s possible to group those records into a block and compress it before writing it to disk.\n\nConstruct and maintain SSTable\nWhen write comes in, add it to a in-memory data structure (red-black tree, AVL tree, etc). This in-memory tree is called memtable.\nThis data structure can insert unordered data, and dump ordered data, for simplicity, just imagine binary search tree, we can insert data in any order, then read them via pre-order traversal to get ordered output.\n\n\nWhen the memtable reachs its threshold, dump it into disk as a new SSTable (the data structure ensures when dump, it must be ordered). After SSTable is being written in disk, writes can continue to a new memtable.\nWhen read comes in, it check memtable first, then the most up-to-date SSTable, and so on.\nFrom time to time, a background process is running for compacting.\n\nThe only problem is: if crash happens, the memtable will lose all fresh data. To deal with it, we can add a log file in disk for memtable, if crash happens, just recover it from log file; if memtable dumps to disk, then delete the log file cuz it’s useless.\nMaking LSM-TreeLog-Structured Merge Tree is based on SSTable and memtable priciple. It will compact SSTable according to level or size.\n\nOptimization\nBloom Filter to aviod not exist keys.\nsize-tiered and level-tiered compaction.\n\n\nBloom Filter &rarr; it can judege that an element must not exist or possible exist\nFor a given input x, apply multiple hash functions to map its output in different place (you can imagine we have a vector&lt;bool&gt;), e.g. hash1(x), hash2(x), hash3(x). Then when we have a new input y, if hash1(y), hash2(y) and hash3(y) all have value (true in vector), which means y is possible exist; if any of these output don’t have value (false in vector), which means y must miss.\n\nThe basic idea of LSM Tree is: keeping a cascade of ordered SSTables that are merged in the background.\nBecause the data is sorted and sparse index can narrow the possible range, range query is also efficient, cuz you can use like binary search to boost query speed.\nB-TreeLSM-Tree vs B-TreeOther Index","tags":["System Design","DDIA"]},{"title":"tmux cookbook","url":"/2023/07/17/tmux-cookbook/","content":"TmuxWhen we use command line tools (CLI), we will open a terminal, and input some commands. This process called “session”. But session is temporary, which means when we close the terminal, the session ends.\nHow can we keep the session even we close the page?\nUsing Tmux :)\nTmux will create a new terminal (you can think this is a sub-terminal), and we can run commands inside. When we close the terminal, it will not end the session, just return back to the main terminal, we can connect the sub-terminal again via tmux.\nWhen use tmux?This is a difficult question. For me, I will use tmux in 2 situations:\n\nI want to show off. You know what I mean, multiple panes in one screen, especially use one pane to run top command, it’s just like hack style.\nThe task will take a long running time. For instance, the machine learning stuff, you can run it in one session, then go back to working. After one million year, re-connect the session and see error information like “No Module Named xxx” (just don’t ask me why I know that)\n\ncookbook\n\n\nCommand\nFunctionality\n\n\n\ntmux new -s &lt;name&gt;\ncreate a named session\n\n\ntmux detach\nkeep the session and go back to main terminal\n\n\ntmux ls\nlist sessions\n\n\ntmux attach -t &lt;name&gt;\nre-connect to session\n\n\ntmux kill-session -t &lt;name&gt;\nend session\n\n\ntmux switch -t &lt;name&gt;\nswitch to session\n\n\ntmux split-window\nsplit up &amp; down\n\n\ntmux split-window -h\nsplit left &amp; right\n\n\ntmux select-pane -U&#x2F;D&#x2F;L&#x2F;R\nselect up&#x2F;down&#x2F;left&#x2F;right pane\n\n\ntmux swap-pane -U&#x2F;D\nchange pane’s size\n\n\nhot key\n\n\nhot key\nfunctionality\n\n\n\nctrl+d\nexit and kill session\n\n\nctrl+b d\ntmux detach\n\n\nctrl+b ?\nhelp\n\n\nctrl+b s\ncheck all sessions\n\n\nctrl+b $\nrename session\n\n\nctrl+b %\nsplit left &amp; right\n\n\nctrl+b “\nsplit up &amp; down\n\n\nctrl+b x\nkill session\n\n\nctrl+b &lt;arrow key&gt;\nselect pane\n\n\nctrl+b ctrl+&lt;arrow key&gt;\nresize pane\n\n\nctrl+b !\nmake panes into different sessions\n\n\nctrl+b :set &lt;command&gt;\nset properties, eg: :set mouse on to enable mouse control\n\n\n","tags":["tools","cookbook"]},{"title":"Why and why not inline","url":"/2023/07/20/Why-and-why-not-inline/","content":"Why inlineIn C++, we can add inline keyword in front of function defination (inline only works on defination, you don’t need to use inline in statement).\nvoid this_is_inline_func();inline void this_is_inline_func() &#123;    std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;&#125;\n\nno inlineWhen we call a function, the process is\n\nfind function defination and its address\nload from memory to stack\nexecute\npop from stack\n\nvoid this_is_not_inline() &#123;    ...&#125;this_is_not_inline();   // 1this_is_not_inline();   // 2this_is_not_inline();   // 3\n\n0x0000 -&gt; defination of this_is_not_inline...0x0100 -&gt; call 1    // find address is 0x0000 -&gt; push 0x0000 into stack -&gt; execute -&gt; pop0x0104 -&gt; call 2    // same0x0108 -&gt; call 3    // same\n\ninlineAll of these steps will cost extra time. To avoid this cost, we can use inline. After we defining a function as inline, we may have multiple calls in code. When we compile the code, the compiler will change function calls to function defination, so that when execute the code, instead of wasting time finding defination and loading from memory to stack, it just executes the function logic.\nvoid this_is_inline() &#123;    std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;&#125;this_is_inline();   // 1this_is_inline();   // 2this_is_inline();   // 3\n\n0x0000 -&gt; defination of this_is_inline...0x0100 -&gt; std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;  // change call to defination0x0200 -&gt; std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;0x0300 -&gt; std::cout &lt;&lt; &quot;this is inline func&quot; &lt;&lt; std::endl;\n\n\nWhy not inlineSounds great? But the problem is, we need to copy the defination after every calls. If the defination is very complicated, we will cost losts of memory. What’s more, if the function is complicated, the execution time &gt;&gt; load &amp; pop stack time, we can ignore the inline improvement.\n\nSuggestionOnly use inline for very simple function. Actually inline is just a recommendation rather than requirement. If the function contains loop, recursion, static, etc complex logic, the function will be treated as not-inline even if you add inline keyword.\nWhat’s more, in class, the methods defination will be treated as inline. So only define simple methods in class, for complex methods, leave statements inside class, then define them outside class.\nclass Object &#123;public:    Object() =default;    Object(const Object&amp; rhs) &#123; num = rhs.num; &#125;    int get_num() &#123; return num; &#125;   // define simple method inside class (auto inline)    void inline_function();    void complex_function();private:    int num;&#125;;// we can still define inline outside classinline void Object::inline_function() &#123;    ...&#125;// for complex method, plz define outside classvoid Object::complex_function() &#123;    ...&#125;\n\n\n#define vs inline#define replaces the pure text in pre-complie stage, inline replaces function call with function defination in complie stage.\n","tags":["c++"]},{"title":"#include <> Vs #include \"\" ","url":"/2023/07/16/cpp_include_difference/","content":"#include &lt;header&gt;This will let preprocessor find header files in pre-designated directories.\n\nThese directories are normally system-related, such as “&#x2F;usr&#x2F;include”, “&#x2F;x86&#x2F;include”, etc.\n\nLet’s use Linux as example. If we ls /usr, you will see bin, include and lib, and if we ls /usr/include, output will contain lots of system defined header files, such as /usr/include/cpp/vector and /usr/include/cpp/iostream. This is how we include these commonly used packages.\n// find header file named &quot;iostream&quot; from &quot;/usr/include&quot;#include &lt;iostream&gt;\n\n\n#include &quot;header&quot;This will search programmer-defined header files and typically includes same directory as the file containing the directive.\nmy_project| - include|   | - my_header.h| - my_project.cpp\n// my_project.cpp#include &quot;my_header.h&quot;\n\nLet’s assume the project tree looks like that, and when we #include &quot;&quot;, it will search header files under /my_project directory.\nIf the processor cannot find header file in current project directory, it will search header files in system path (the same as #include &lt;&gt;).\n\n#include &quot;header.h&quot; – cannot find locally –&gt; #include &lt;header.h&gt;\n\n\nAdd include pathAs we discussed before, #include &lt;&gt; will search pre-designated directories. What if we want the processor to search other directories?\nWe can add include paths via \n\n-I\nsystem environment variable\nCMake\n\nAfter adding include paths, the searching order is\n\n#include &lt;&gt;\ndir list\nsystem dir\n\n\n#include &quot;&quot;\nlocal\ndir list\nsystem dir\n\n\n\n-IWe can use -I flag in command line to add search paths.\ng++ -c test.cpp -o testg++ -c test.cpp -o test -I /path/to/certain/include/\n\nSystem environment variableThe system environment has a property called CPLUS_INCLUDE_PATH, we can set this to add search paths.\nexport CPLUS_INCLUDE_PATH=&quot;path/to/certain/include&quot;\n\nCMakeFor CMake, we can use include_directories([AFTER|BEFORE] [SYSTEM] dir1 [dir2 ...]) .\n","tags":["c++"]},{"title":"Unittest in python - Mock","url":"/2023/07/27/Unittest-in-python-Mock/","content":"IntroMock is a very useful package for unittest in python. It can replace some classes or functions and change their behaviors, it can also use some built-in methods to help you assert whether pytest calls certain part of your code.\n\nMock() &amp; MagicMock()\nFor simplicity, let’s use Mock for example. In most cases, Mock and MagicMock are the same :)\n\nMock is a class that create all attributes and methods as you access them and store details of how they have been used.\nWhat’s more, you can set anything to a Mock, it will treat them as new Mock (sub Mock).\n# set an undefined method to a Mockm = Mock()              # &lt;Mock name=&quot;mock&quot;&gt;m.undefined_function()  # &lt;Mock name=&quot;mock.undefined_function()&quot;&gt;# use mock as a argumentclass Object:    def func(self, args):        args.do_something()o = Object()m = Mock()o.func(m)m.do_something()    # &lt;Mock name=&quot;mock.do_something()&quot;&gt;\n\nreturn_valueBy setting some methods or functions as Mock, then setting return_value can change original logic: I don’t care about what you write in the function, just return what I want!\nclass Object:    def __init__(self, x):        self.x = x        def func(self):        return self.xobj = Object(1)# method 1obj.func = Mock(return_value = 1024)# # method 2# obj.func = Mock()# obj.func.return_value = 1024obj.func()  # return 1024 rather than 1\n\nThis is always useful in unittest, like:\n\nI don’t want to send a real request via network, just let the requester &#x2F; dispatcher return what I want;\nI don’t want to access a real DB, just tell me what data you have;\n\nclass MySvc:    def __init__(self, db):        self.db = db        ...    def myRequest(self, req):        ...        results = self.db.fetch(req)        return resultsdef test_db(req):    db = MyDB()    db.fetch = Mock(return_value = [data1, data2, data3, ...])    svc = MySvc(db)    results = svc.myRequest(req)    # [data1, data2, data3, ...]\n\nSometimes, we will meet some call chains, such as mock.connection.cursor().execute(...).\n# mock.call1().call2().call3()m = Mock()# get Mock for all calls except the last onec1 = m.call1.return_valuec2 = c1.call2.return_value# set Mock for last one callc2.call3.return_value = &quot;foo&quot;m.call1().call2().call3()   # &quot;foo&quot;\n\n\nBasically, we can change the code as following\nm = Mock()c1 = Mock()m.call1.return_value = c1c2 = Mock()c1.call2.return_value = c2c2.call3.return_value = &quot;foo&quot;\n\nside_effectside_effect &#x3D; Exception&gt;&gt; m = Mock()&gt;&gt; m.exception_side_effect = Mock(side_effect = ValueError)&gt;&gt; m.exception_side_effect()ValueError\n\nside_effect &#x3D; iterableIf we set iterable to side_effect, every time we call it, it will yield one element.\n&gt;&gt; m = Mock()&gt;&gt; m.iter = Mock(side_effect = [1, 2, 3])&gt;&gt; m.iter()1&gt;&gt; m.iter()2&gt;&gt; m.iter()3\n\nside_effect &#x3D; callabledef log(*args, **kwargs):    print(f&quot;args: &#123;args&#125;, kwargs: &#123;kwargs&#125;&quot;)&gt;&gt; m = Mock()&gt;&gt; m.func = Mock(side_effect = log)&gt;&gt; m.func()args: (), kwargs: &#123;&#125;&gt;&gt; m.func(1, two = 2)args: (1,), kwargs: &#123;&quot;two&quot;: 2&#125;\n\nWhen we set both return_value and side_effect, the Mock will only use side_effect!!\nspec &amp; spec_setspec can be either a list of string or an existing class &#x2F; instance. After we set spec, the mock can only have corresponding attributes and methods (just like we use dir to see what attributes and methods does one class support).\nclass Object:    def __init__(self):        self.one = 1        self.two = 2    def func(self):        pass# when we use existing class as spec, the mock hasn&#x27;t initedm = Mock(spec = Object)m.func()    # &lt;Mock name=&quot;mock.func()&quot;&gt;m.one       # error, cuz we don&#x27;t init the Objectm.__init__()m.one       # 1m.three = 3 # ok# when we use existing instance as spec, the mock has initedo = Object()m = Mock(spec = o)m.func()    # &lt;Mock name=&quot;mock.func()&quot;&gt;m.one       # 1# when we use list of string as specm = Mock(spec = [&quot;one&quot;, &quot;func&quot;])m.func()    # &lt;Mock name=&quot;mock.func()&quot;&gt;m.one       # &lt;Mock name=&quot;mock.one&quot;&gt;m.one()     # &lt;Mock name=&quot;mock.one()&quot;&gt;\n\nThe difference between spec and spec_set is, spec can add new stuff while spec_set can only read.\nm = Mock(spec = [&quot;one&quot;])m.onem.two = 2   # okmm = Mock(spec_set = [&quot;one&quot;])m.onem.two = 2   # error\n\nassertion &amp; call argsMock supports lots of assertions, such as assert_called, assert_called_once, assert_called_with, etc.\nm = Mock()m(1, 2)m.assert_called()           # Truem.assert_called_with(1, 2)  # True\n\nMock can also remember what args you used via call_args or call_args_list.\nm = Mock()m(1, 2)m.call_args         # call(1, 2)m.call_args_list    # [call(1, 2)]m(3, 4)m.call_args         # call(3, 4)m.call_args_list    # [call(1, 2), call(3, 4)]\n\nWhat’s the difference between these two?So you can simply think MagicMock &#x3D; Mock with pre-defined magic methods.\n&gt;&gt; len(Mock())Error, Mock doesn&#x27;t have __len__ method&gt;&gt; len(MagicMock())0\n\nSo if you want to test or use magic methods in your test, use MagicMock.\nIf you want to modify the magic methods or just for simplicity purpose, plz use Mock.\n","tags":["python","test","pytest"]},{"title":"How to setup blog?","url":"/2023/07/14/how_to_setup_blog/","content":"GithubJust create a new repo, and the repo’s name follows rule “username.github.io”.\n\nNode.js &amp; HexoInstallJust donwload Node.js from offical website (maybe you also need npm :)). For Mac user, the simplest way is run command:\nbrew install node\n\nFor Hexo, we just need to run\nnpm install hexo-cli -g\n\nAfter installation, use commands to validate:\nnode -vnpm -vhexo -v\n\nInitIf everything is OK, run following commands:\nmkdir blog &amp;&amp; cd bloghexo init   # init the folder as blog reponpm install # install necessary node_modules\n\nThen you will find a file named blog/_config.yml, add these info in last rows:\n# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy:  type: git  repository: &lt;your github repo&gt;  branch: master\n\nDeployYou can add a new plug-in npm i hexo-deployer-git so that we can post blogs to git via hexo.\nhexo new post &quot;this is post name&quot;hexo g  # generatehexo s  # can view changes in localhosthexo d  # deploy to github\n\n\n:money:\nActually this step is optional, cause u can use “username.github.io” to browse your blog. However, if you want a fancy URI (and you are rich), you can follow the step.\n\nYou should buy a web URI, I got one from GoDaddy.\nAfter you got one, let’s say it’s “myfancyblog.com”, you should set the DNS so that when other people enter “myfancyblog.com” in browser, it can re-direct to “username.github.io”.\nOther people                  Your github repo&quot;myfancyblog.com&quot;   - DNS -&gt;  &quot;username.github.io&quot;\n\nIn DNS Management page, you should set two more DNS Records.\n\n\n\nType\nName\nData\n\n\n\nA\n@\nIP Address For username.github.io\n\n\nCNAME\nwww\nusername.github.io\n\n\nThe first one re-directs “myfancyblog.com” to “username.github.io”‘s IP, the second re-directs “www.myfancyblog.com“ to “username.github.io”.\nThen, you should go back to your blog repo, in blog/source create a new file CNAME, then put “myfancyblog.com” in this file. hexo g &amp;&amp; hexo d. You will see github.com will have a new CNAME file, and you can check “Setting -&gt; Pages”, it should have “myfancyblog.com” in “Custom domain” field.\n\nTipsIf you are curious about “why I changed some settings but the web page seems no change”, :(, well, remember to clear the browser cache.\n","tags":["tools","blog"]}]